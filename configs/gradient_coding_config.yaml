# Copyright (c) Anish Acharya.
# Licensed under the MIT License
{
  "seed": 1,
  "data_config":
  {
    "data_set": "mnist",
    "shape":
    [
        28,
        28
    ],

    "val_frac": 0,                    # Fraction of Train Data used for Validation
    "num_labels": 10,                 # Num of Labels in Dataset
    "num_channels": 1,                # Number of channels # in case of CV experiments

    "data_sampling_strategy": "iid",  # iid / non_iid
    "num_shards": 80,                 # For non-iid distribution
    "train_batch_size": 32,                 # Mini Batch Size
    "test_batch_size": 2048,

    "feature_attack_config":
      {
        "noise_model": null, #
        "frac_adv": 0.2,     # Fraction of corrupt samples
        "sev": 5,            # severity of attack
        "target_label": 8,   # backdoor Attack
      },
  },

  "training_config":
  {
    "num_clients": 1,            # Number of parallel batches in distributed setting 1 = mini batch SGD
    "client_fraction": 1,         # partial device participation - For FL
    "global_epochs": 10,          # epochs
    "local_epochs": 1,            # local SGD # For FL

    "eval_freq": 128,             # Specify number of steps between train/test/val evaluation

    "optimizer_config":
      {
        "client_optimizer_config":
          {
            "optimizer": "Adam",
            "loss": "ce",

            "loss_sampling": null,     # importance sampling on loss value: None, 'top_loss', 'rand_loss'
            "initial_loss_sampling_fraction": 0.95,

            "lr0": 0.01,
            "momentum": 0.9,
            "reg": 0.0001,
            "nesterov": true,
            "amsgrad": false
          },

        "client_lrs_config":
          {
            "lrs": 'step',
            "milestones": [1,5,10],
            "step_size": 1,
            "gamma": 0.9
          },

        "server_optimizer_config":
          {
            "optimizer": "SGD",
            "lr0": 1
          }
      },

    "learner_config":
      {
        "net": "small_cnn", # Options: log_reg
        "mlp_config": { "h1": 30, "h2": 30 }
      },

    "aggregation_config":
      {
        "gar": "mean",
        "geo_med_config": {"alg": 'vardi', 'eps': 0.00001, 'max_iter': 100},
        "trimmed_mean_config":{"proportion": 0.3},
        "krum_config": {"krum_frac": 0.3},
        "norm_clip_config": { "alpha": 0.5},

        "grad_attack_config":
          {
            "attack_model": null,
            "attack_mode": "un_coordinated",
            "frac_adv": 0.4,
            "rand_additive_attack_conf":
              {
                "noise_dist": "gaussian",
                "mean_shift": 0, "attack_std": 10,   # Gaussian noise
                "noise_range": [ -1, 0 ],             # Uniform noise
              },
            "sign_flip_conf": {"flip_prob": 0.7, "flip_scale": 5},
            "attack_n_std": 1
          },

        "gradient_compression_config":
          {
            "rule": 'top',                     # None, 'full', 'top', 'rand', 'Q'
            "sampling_fraction": 0.1,         # fraction to be sampled
            "memory_algo": 'ef',               # memory in gradients - invoked for gradient compression rules
          },

        "jacobian_compression_config":
          {
            "rule": null,                     # None, 'active_norm_sampling', 'random_sampling'
            "axis": "n",                      # n = client/sample/batch selection ; dim = dimension selection
            "sampling_fraction": 0.9,         # fraction to be sampled
            "memory_algo": 'ef',              # memory in Jacobian - invoked for jacobian compression rules
          }
      }
  }
}