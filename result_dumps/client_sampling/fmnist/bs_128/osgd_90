[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 128,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 256,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.9,
                        "lr0": 0.02,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            85.28999999999999,
            15.420000000000002,
            13.519999999999996,
            12.150000000000006,
            11.150000000000006,
            11.400000000000006,
            10.370000000000005,
            10.090000000000003,
            9.900000000000006,
            10.420000000000002,
            10.14,
            10.680000000000007,
            9.299999999999997,
            9.75,
            9.549999999999997,
            8.819999999999993,
            9.079999999999998,
            9.329999999999998,
            9.180000000000007,
            8.790000000000006,
            8.530000000000001,
            8.239999999999995,
            8.340000000000003,
            8.079999999999998,
            8.379999999999995,
            8.290000000000006,
            8.450000000000003,
            8.200000000000003,
            8.489999999999995,
            8.319999999999993,
            8.090000000000003,
            8.39,
            8.579999999999998,
            8.079999999999998,
            8.219999999999999,
            8.200000000000003,
            7.989999999999995,
            7.989999999999995,
            8.030000000000001,
            7.8700000000000045,
            7.799999999999997,
            8.230000000000004,
            8.239999999999995,
            8.239999999999995,
            8.060000000000002,
            7.939999999999998,
            7.980000000000004,
            7.799999999999997,
            8.14,
            8.040000000000006,
            8.180000000000007,
            8.060000000000002,
            8.189999999999998,
            8.090000000000003,
            7.859999999999999,
            8.129999999999995,
            7.8700000000000045,
            7.969999999999999,
            7.989999999999995,
            7.859999999999999,
            7.8799999999999955,
            7.859999999999999,
            7.780000000000001,
            7.829999999999998,
            7.900000000000006,
            7.689999999999998,
            7.950000000000003,
            7.859999999999999,
            7.819999999999993,
            7.700000000000003,
            7.950000000000003,
            7.6200000000000045,
            7.890000000000001,
            7.890000000000001,
            7.829999999999998,
            8.060000000000002,
            7.980000000000004,
            7.930000000000007,
            8.189999999999998,
            7.950000000000003,
            7.989999999999995,
            8.209999999999994,
            7.760000000000005,
            7.959999999999994,
            8.079999999999998,
            8.0,
            7.8799999999999955,
            7.680000000000007,
            7.920000000000002,
            7.75,
            7.909999999999997,
            7.760000000000005
        ],
        "test_loss": [],
        "test_acc": [
            14.71,
            84.58,
            86.48,
            87.85,
            88.85,
            88.6,
            89.63,
            89.91,
            90.1,
            89.58,
            89.86,
            89.32,
            90.7,
            90.25,
            90.45,
            91.18,
            90.92,
            90.67,
            90.82,
            91.21,
            91.47,
            91.76,
            91.66,
            91.92,
            91.62,
            91.71,
            91.55,
            91.8,
            91.51,
            91.68,
            91.91,
            91.61,
            91.42,
            91.92,
            91.78,
            91.8,
            92.01,
            92.01,
            91.97,
            92.13,
            92.2,
            91.77,
            91.76,
            91.76,
            91.94,
            92.06,
            92.02,
            92.2,
            91.86,
            91.96,
            91.82,
            91.94,
            91.81,
            91.91,
            92.14,
            91.87,
            92.13,
            92.03,
            92.01,
            92.14,
            92.12,
            92.14,
            92.22,
            92.17,
            92.1,
            92.31,
            92.05,
            92.14,
            92.18,
            92.3,
            92.05,
            92.38,
            92.11,
            92.11,
            92.17,
            91.94,
            92.02,
            92.07,
            91.81,
            92.05,
            92.01,
            91.79,
            92.24,
            92.04,
            91.92,
            92.0,
            92.12,
            92.32,
            92.08,
            92.25,
            92.09,
            92.24
        ],
        "train_error": [
            84.92333333333333,
            14.596666666666664,
            12.188333333333333,
            10.546666666666667,
            9.965000000000003,
            9.489999999999995,
            8.538333333333327,
            8.215000000000003,
            7.533333333333331,
            7.75,
            7.316666666666663,
            7.931666666666672,
            6.183333333333337,
            6.280000000000001,
            6.461666666666673,
            5.38333333333334,
            5.260000000000005,
            5.525000000000006,
            5.079999999999998,
            4.273333333333326,
            3.653333333333336,
            3.248333333333335,
            3.326666666666668,
            3.114999999999995,
            2.8866666666666703,
            2.8616666666666646,
            2.8799999999999955,
            2.5916666666666686,
            2.3900000000000006,
            2.894999999999996,
            2.123333333333335,
            2.1416666666666657,
            2.5400000000000063,
            2.180000000000007,
            2.066666666666663,
            1.9099999999999966,
            1.5649999999999977,
            1.3633333333333297,
            1.336666666666673,
            1.1383333333333354,
            1.0633333333333326,
            1.0133333333333354,
            1.2349999999999994,
            0.9050000000000011,
            0.9099999999999966,
            0.818333333333328,
            0.8149999999999977,
            0.7666666666666657,
            0.9416666666666629,
            0.8383333333333383,
            0.7683333333333309,
            0.6633333333333269,
            0.8133333333333326,
            0.7316666666666691,
            0.6099999999999994,
            0.5316666666666663,
            0.4300000000000068,
            0.3883333333333354,
            0.42166666666666686,
            0.43166666666667197,
            0.3716666666666697,
            0.37999999999999545,
            0.34499999999999886,
            0.3516666666666737,
            0.32500000000000284,
            0.3083333333333371,
            0.32833333333333314,
            0.30666666666667197,
            0.2750000000000057,
            0.2816666666666663,
            0.26833333333333087,
            0.23833333333332973,
            0.23333333333333428,
            0.3166666666666629,
            0.19666666666667254,
            0.23166666666666913,
            0.24500000000000455,
            0.19333333333332803,
            0.26166666666667027,
            0.21333333333333826,
            0.18333333333333712,
            0.17499999999999716,
            0.19499999999999318,
            0.18666666666666742,
            0.19333333333332803,
            0.201666666666668,
            0.15500000000000114,
            0.1566666666666663,
            0.18999999999999773,
            0.19166666666666288,
            0.1566666666666663,
            0.15000000000000568
        ],
        "train_loss": [
            2.2880488341805267,
            0.40150366049966835,
            0.3321477697093858,
            0.2911396345604203,
            0.2737923458631613,
            0.26161178730444107,
            0.23291108240959232,
            0.22206232693594402,
            0.20695515944441753,
            0.21017250250270372,
            0.20002366356186266,
            0.21548650410574383,
            0.1695407737197398,
            0.17006991374721406,
            0.1742813377968792,
            0.14974901887939682,
            0.1491687740884356,
            0.14938539513615148,
            0.14001603068700477,
            0.11312474143594059,
            0.1012052697484999,
            0.094227845591904,
            0.09139748211147816,
            0.08668180388698318,
            0.08266819903114711,
            0.08086092454363415,
            0.0791620223093897,
            0.0717677023750283,
            0.06652217568047265,
            0.07967856939810553,
            0.061223360747575506,
            0.06167868497386289,
            0.07005065621168756,
            0.06023651065189701,
            0.05712886942006441,
            0.05376581782931839,
            0.04833783629709787,
            0.04166532987788288,
            0.040080955855723126,
            0.03545288723121002,
            0.03364922749057317,
            0.03351945511853771,
            0.036831479000328765,
            0.030356574710259942,
            0.03041400327714585,
            0.02741907979361713,
            0.02677859233092588,
            0.02701864055971474,
            0.02913270613252084,
            0.027011317951576925,
            0.025401499096566298,
            0.024315887936520012,
            0.02670521163858219,
            0.024590934908736362,
            0.02092182058205546,
            0.020587522688427014,
            0.017583101891032828,
            0.016523033644118383,
            0.01748085730989128,
            0.017325858852125085,
            0.015835386825534804,
            0.015631932722055104,
            0.015456826301978659,
            0.01526191535352199,
            0.0147797490891093,
            0.014058143961360492,
            0.014499637221834108,
            0.013525083942313009,
            0.013685456882697592,
            0.013084116624171799,
            0.013041468757911644,
            0.01287101781534861,
            0.012361770224715792,
            0.013643533211332489,
            0.011812983525059084,
            0.011685090331630761,
            0.011835178340733575,
            0.010770712787015383,
            0.011866159068404642,
            0.01103982353781058,
            0.011014226272251449,
            0.010779013497822447,
            0.010729713387775428,
            0.0105451056031264,
            0.010744863533541989,
            0.010744938932444607,
            0.010062058785630426,
            0.009929688778201511,
            0.010264346999094398,
            0.010216953443375223,
            0.01004601145676498,
            0.00994239754524074
        ],
        "train_acc": [
            15.076666666666666,
            85.40333333333334,
            87.81166666666667,
            89.45333333333333,
            90.035,
            90.51,
            91.46166666666667,
            91.785,
            92.46666666666667,
            92.25,
            92.68333333333334,
            92.06833333333333,
            93.81666666666666,
            93.72,
            93.53833333333333,
            94.61666666666666,
            94.74,
            94.475,
            94.92,
            95.72666666666667,
            96.34666666666666,
            96.75166666666667,
            96.67333333333333,
            96.885,
            97.11333333333333,
            97.13833333333334,
            97.12,
            97.40833333333333,
            97.61,
            97.105,
            97.87666666666667,
            97.85833333333333,
            97.46,
            97.82,
            97.93333333333334,
            98.09,
            98.435,
            98.63666666666667,
            98.66333333333333,
            98.86166666666666,
            98.93666666666667,
            98.98666666666666,
            98.765,
            99.095,
            99.09,
            99.18166666666667,
            99.185,
            99.23333333333333,
            99.05833333333334,
            99.16166666666666,
            99.23166666666667,
            99.33666666666667,
            99.18666666666667,
            99.26833333333333,
            99.39,
            99.46833333333333,
            99.57,
            99.61166666666666,
            99.57833333333333,
            99.56833333333333,
            99.62833333333333,
            99.62,
            99.655,
            99.64833333333333,
            99.675,
            99.69166666666666,
            99.67166666666667,
            99.69333333333333,
            99.725,
            99.71833333333333,
            99.73166666666667,
            99.76166666666667,
            99.76666666666667,
            99.68333333333334,
            99.80333333333333,
            99.76833333333333,
            99.755,
            99.80666666666667,
            99.73833333333333,
            99.78666666666666,
            99.81666666666666,
            99.825,
            99.805,
            99.81333333333333,
            99.80666666666667,
            99.79833333333333,
            99.845,
            99.84333333333333,
            99.81,
            99.80833333333334,
            99.84333333333333,
            99.85
        ],
        "best_test_acc": 92.38,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            1.0137858390808105,
            1.0074846744537354,
            1.0149052143096924,
            0.9915149211883545,
            1.0274698734283447,
            0.9885921478271484,
            1.0243651866912842,
            0.987349271774292,
            1.0529944896697998,
            1.0210206508636475,
            1.0170869827270508,
            0.9783401489257812,
            0.9943044185638428,
            1.0981061458587646,
            1.0084445476531982,
            1.01080322265625,
            1.0376968383789062,
            1.021491289138794,
            1.0468344688415527,
            1.077021837234497,
            1.0525741577148438,
            0.9756660461425781,
            0.9840216636657715,
            1.0023682117462158,
            0.9869449138641357,
            1.0149450302124023,
            1.004847764968872,
            0.9994280338287354,
            1.0770878791809082,
            1.0334339141845703,
            1.0089566707611084,
            1.0536749362945557,
            1.0339016914367676,
            1.0564069747924805,
            1.0013887882232666,
            1.039424180984497,
            1.035576343536377,
            0.9834558963775635,
            1.0116519927978516,
            0.9901318550109863,
            0.9940531253814697,
            0.9939801692962646,
            0.9901027679443359,
            1.0234198570251465,
            1.010164499282837,
            0.9862966537475586,
            1.0123000144958496,
            0.9763181209564209,
            0.9951882362365723,
            1.017608880996704
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 50.764931440353394,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 23450,
        "num_opt_steps": 23450,
        "num_grad_steps": 23449
    }
]