[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 128,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 256,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.8,
                        "lr0": 0.02,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            84.59,
            15.269999999999996,
            13.459999999999994,
            11.980000000000004,
            11.219999999999999,
            11.010000000000005,
            10.599999999999994,
            10.11,
            9.780000000000001,
            10.36,
            10.010000000000005,
            10.769999999999996,
            9.420000000000002,
            9.769999999999996,
            9.549999999999997,
            9.340000000000003,
            9.079999999999998,
            8.790000000000006,
            9.409999999999997,
            8.540000000000006,
            8.230000000000004,
            8.25,
            8.409999999999997,
            8.340000000000003,
            8.530000000000001,
            8.290000000000006,
            8.11,
            8.409999999999997,
            8.450000000000003,
            8.64,
            8.420000000000002,
            8.340000000000003,
            8.260000000000005,
            8.61,
            8.180000000000007,
            8.459999999999994,
            8.530000000000001,
            8.290000000000006,
            8.14,
            8.019999999999996,
            8.129999999999995,
            8.150000000000006,
            8.040000000000006,
            8.14,
            8.180000000000007,
            8.239999999999995,
            8.079999999999998,
            7.930000000000007,
            8.049999999999997,
            7.930000000000007,
            8.060000000000002,
            8.319999999999993,
            8.189999999999998,
            8.200000000000003,
            7.780000000000001,
            8.120000000000005,
            8.25,
            7.959999999999994,
            8.030000000000001,
            8.0,
            8.0,
            7.959999999999994,
            7.810000000000002,
            7.950000000000003,
            8.010000000000005,
            7.950000000000003,
            8.069999999999993,
            8.019999999999996,
            8.019999999999996,
            7.859999999999999,
            7.989999999999995,
            7.909999999999997,
            8.060000000000002,
            8.040000000000006,
            7.819999999999993,
            8.069999999999993,
            7.930000000000007,
            8.0,
            7.939999999999998,
            8.040000000000006,
            7.760000000000005,
            7.950000000000003,
            7.75,
            7.849999999999994,
            7.930000000000007,
            7.900000000000006,
            7.900000000000006,
            7.969999999999999,
            7.969999999999999,
            7.950000000000003,
            8.079999999999998,
            8.11
        ],
        "test_loss": [],
        "test_acc": [
            15.41,
            84.73,
            86.54,
            88.02,
            88.78,
            88.99,
            89.4,
            89.89,
            90.22,
            89.64,
            89.99,
            89.23,
            90.58,
            90.23,
            90.45,
            90.66,
            90.92,
            91.21,
            90.59,
            91.46,
            91.77,
            91.75,
            91.59,
            91.66,
            91.47,
            91.71,
            91.89,
            91.59,
            91.55,
            91.36,
            91.58,
            91.66,
            91.74,
            91.39,
            91.82,
            91.54,
            91.47,
            91.71,
            91.86,
            91.98,
            91.87,
            91.85,
            91.96,
            91.86,
            91.82,
            91.76,
            91.92,
            92.07,
            91.95,
            92.07,
            91.94,
            91.68,
            91.81,
            91.8,
            92.22,
            91.88,
            91.75,
            92.04,
            91.97,
            92.0,
            92.0,
            92.04,
            92.19,
            92.05,
            91.99,
            92.05,
            91.93,
            91.98,
            91.98,
            92.14,
            92.01,
            92.09,
            91.94,
            91.96,
            92.18,
            91.93,
            92.07,
            92.0,
            92.06,
            91.96,
            92.24,
            92.05,
            92.25,
            92.15,
            92.07,
            92.1,
            92.1,
            92.03,
            92.03,
            92.05,
            91.92,
            91.89
        ],
        "train_error": [
            84.47333333333333,
            14.516666666666666,
            12.071666666666673,
            10.385000000000005,
            10.088333333333338,
            9.194999999999993,
            8.656666666666666,
            8.263333333333335,
            7.465000000000003,
            7.708333333333329,
            7.159999999999997,
            7.983333333333334,
            6.296666666666667,
            6.693333333333328,
            6.263333333333335,
            5.578333333333333,
            5.349999999999994,
            5.055000000000007,
            5.078333333333333,
            3.941666666666663,
            3.5400000000000063,
            3.2533333333333303,
            3.194999999999993,
            3.2383333333333297,
            2.8216666666666725,
            2.6883333333333326,
            2.7616666666666703,
            2.4833333333333343,
            2.268333333333331,
            2.6316666666666606,
            2.173333333333332,
            2.11666666666666,
            2.1766666666666623,
            2.1966666666666725,
            1.7150000000000034,
            1.7466666666666697,
            1.9950000000000045,
            1.3433333333333337,
            1.1316666666666606,
            1.028333333333336,
            0.9466666666666725,
            0.9766666666666737,
            1.00833333333334,
            0.8533333333333388,
            0.7866666666666617,
            0.7533333333333303,
            0.8683333333333394,
            0.6616666666666617,
            0.7600000000000051,
            0.7733333333333263,
            0.6283333333333303,
            0.7249999999999943,
            0.5949999999999989,
            0.7999999999999972,
            0.5550000000000068,
            0.548333333333332,
            0.4099999999999966,
            0.3883333333333354,
            0.3366666666666731,
            0.30666666666667197,
            0.3083333333333371,
            0.326666666666668,
            0.2950000000000017,
            0.25499999999999545,
            0.2916666666666714,
            0.269999999999996,
            0.26833333333333087,
            0.2183333333333337,
            0.22333333333332916,
            0.26166666666667027,
            0.20999999999999375,
            0.18999999999999773,
            0.20333333333333314,
            0.18999999999999773,
            0.17166666666666686,
            0.1766666666666623,
            0.16833333333333655,
            0.173333333333332,
            0.20000000000000284,
            0.18999999999999773,
            0.15833333333333144,
            0.14833333333332632,
            0.1666666666666714,
            0.1599999999999966,
            0.1599999999999966,
            0.16500000000000625,
            0.12999999999999545,
            0.16500000000000625,
            0.1599999999999966,
            0.1666666666666714,
            0.1316666666666606,
            0.15500000000000114
        ],
        "train_loss": [
            2.287779511673364,
            0.3995794137594288,
            0.3283933430655933,
            0.28521673521126256,
            0.2767539177812747,
            0.2522346833621515,
            0.23485021615651117,
            0.22469597935740118,
            0.20352182011487388,
            0.2097432336001508,
            0.19562402663073306,
            0.21406355150727066,
            0.17045465050571001,
            0.17901868309611196,
            0.1671560720673629,
            0.14976134375214323,
            0.14872188923328417,
            0.134542030629827,
            0.1379858535458284,
            0.1067831164468199,
            0.09899011286082807,
            0.09123062548924611,
            0.08803644194118758,
            0.0891189027482322,
            0.08052910288084926,
            0.07637704998207118,
            0.0772459028280779,
            0.07045870576538384,
            0.06531960572769392,
            0.07233675715447997,
            0.06342064707216297,
            0.061219016324355405,
            0.06094230836960298,
            0.060335234542295876,
            0.0501425863364771,
            0.05011909563285011,
            0.05394532868483745,
            0.04103234570934129,
            0.03601905204721097,
            0.03268008723632613,
            0.03079411367288054,
            0.03166349094484184,
            0.03155551638517743,
            0.027895121272208532,
            0.026912612427494674,
            0.0252168261101529,
            0.02692280457253808,
            0.023385205955457077,
            0.02435735961013257,
            0.024261995105009312,
            0.0219482742681869,
            0.024027192305876757,
            0.021405531872889953,
            0.024592085232112263,
            0.019344123290863626,
            0.019671351240296512,
            0.016076923980971356,
            0.015132466853379822,
            0.014750895165860145,
            0.014257852372073972,
            0.014074055975410286,
            0.013735376967629517,
            0.013348321404570202,
            0.01284809979418519,
            0.013063497112583377,
            0.013012568281689433,
            0.012798901209468716,
            0.011839643781031691,
            0.011712654043353404,
            0.012260491147573823,
            0.011335948089223061,
            0.010783862576746484,
            0.01060165835694392,
            0.01108861003102842,
            0.01005743247003102,
            0.009966706113168982,
            0.009814133138846614,
            0.009286178323849321,
            0.010128224226358189,
            0.009846026217862805,
            0.009172267909261034,
            0.009617501918200665,
            0.00942710986900042,
            0.00911271215048132,
            0.009446513749458499,
            0.009017783829243358,
            0.008750708007227891,
            0.008988727955693708,
            0.00920493854507645,
            0.00887761633572127,
            0.008532375312481782,
            0.008751935907391343
        ],
        "train_acc": [
            15.526666666666667,
            85.48333333333333,
            87.92833333333333,
            89.615,
            89.91166666666666,
            90.805,
            91.34333333333333,
            91.73666666666666,
            92.535,
            92.29166666666667,
            92.84,
            92.01666666666667,
            93.70333333333333,
            93.30666666666667,
            93.73666666666666,
            94.42166666666667,
            94.65,
            94.945,
            94.92166666666667,
            96.05833333333334,
            96.46,
            96.74666666666667,
            96.805,
            96.76166666666667,
            97.17833333333333,
            97.31166666666667,
            97.23833333333333,
            97.51666666666667,
            97.73166666666667,
            97.36833333333334,
            97.82666666666667,
            97.88333333333334,
            97.82333333333334,
            97.80333333333333,
            98.285,
            98.25333333333333,
            98.005,
            98.65666666666667,
            98.86833333333334,
            98.97166666666666,
            99.05333333333333,
            99.02333333333333,
            98.99166666666666,
            99.14666666666666,
            99.21333333333334,
            99.24666666666667,
            99.13166666666666,
            99.33833333333334,
            99.24,
            99.22666666666667,
            99.37166666666667,
            99.275,
            99.405,
            99.2,
            99.445,
            99.45166666666667,
            99.59,
            99.61166666666666,
            99.66333333333333,
            99.69333333333333,
            99.69166666666666,
            99.67333333333333,
            99.705,
            99.745,
            99.70833333333333,
            99.73,
            99.73166666666667,
            99.78166666666667,
            99.77666666666667,
            99.73833333333333,
            99.79,
            99.81,
            99.79666666666667,
            99.81,
            99.82833333333333,
            99.82333333333334,
            99.83166666666666,
            99.82666666666667,
            99.8,
            99.81,
            99.84166666666667,
            99.85166666666667,
            99.83333333333333,
            99.84,
            99.84,
            99.835,
            99.87,
            99.835,
            99.84,
            99.83333333333333,
            99.86833333333334,
            99.845
        ],
        "best_test_acc": 92.25,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.98274827003479,
            0.9965002536773682,
            0.9987919330596924,
            1.0086302757263184,
            1.0378170013427734,
            1.011843204498291,
            1.0162882804870605,
            0.9802021980285645,
            0.9685804843902588,
            0.9756171703338623,
            0.9859039783477783,
            0.9815576076507568,
            0.988194465637207,
            1.000335693359375,
            0.9962921142578125,
            0.9986979961395264,
            0.9942269325256348,
            1.0110433101654053,
            1.0114665031433105,
            0.9905447959899902,
            1.0160276889801025,
            1.0527064800262451,
            1.014009952545166,
            0.9707472324371338,
            1.0065557956695557,
            1.0566189289093018,
            1.056203842163086,
            1.1550383567810059,
            1.076709270477295,
            0.9993300437927246,
            1.0500764846801758,
            1.0250885486602783,
            1.0217046737670898,
            1.0011608600616455,
            1.0443034172058105,
            0.9813828468322754,
            1.000640869140625,
            0.9582452774047852,
            0.9624917507171631,
            0.932302713394165,
            0.9337928295135498,
            0.9611225128173828,
            0.9363851547241211,
            1.081775188446045,
            1.0443921089172363,
            0.9742369651794434,
            0.9823465347290039,
            0.9839160442352295,
            1.0205023288726807,
            0.9980490207672119
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 50.23314619064331,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 23450,
        "num_opt_steps": 23450,
        "num_grad_steps": 23449
    }
]