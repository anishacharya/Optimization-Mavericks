[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 32,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 1024,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.95,
                        "lr0": 0.01,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            88.21000000000001,
            15.120000000000005,
            12.379999999999995,
            11.329999999999998,
            11.590000000000003,
            14.340000000000003,
            11.060000000000002,
            10.909999999999997,
            10.060000000000002,
            10.980000000000004,
            10.099999999999994,
            10.290000000000006,
            9.36,
            9.920000000000002,
            9.290000000000006,
            9.790000000000006,
            9.989999999999995,
            9.36,
            10.439999999999998,
            8.939999999999998,
            8.659999999999997,
            8.730000000000004,
            8.599999999999994,
            8.590000000000003,
            8.560000000000002,
            8.650000000000006,
            8.620000000000005,
            8.769999999999996,
            8.920000000000002,
            8.64,
            8.86,
            9.099999999999994,
            8.36,
            8.620000000000005,
            9.030000000000001,
            8.980000000000004,
            8.579999999999998,
            8.569999999999993,
            8.790000000000006,
            8.450000000000003,
            8.420000000000002,
            8.61,
            8.579999999999998,
            8.489999999999995,
            8.5,
            8.36,
            8.319999999999993,
            8.549999999999997,
            8.39,
            8.409999999999997,
            8.450000000000003,
            8.510000000000005,
            8.739999999999995,
            8.420000000000002,
            8.36,
            8.439999999999998,
            8.310000000000002,
            8.14,
            8.11,
            8.319999999999993,
            8.36,
            8.25,
            8.239999999999995,
            8.549999999999997,
            8.11,
            8.260000000000005,
            8.340000000000003,
            8.400000000000006,
            8.170000000000002,
            8.340000000000003,
            8.170000000000002,
            8.200000000000003,
            8.129999999999995,
            8.040000000000006,
            8.400000000000006,
            8.260000000000005,
            8.090000000000003,
            8.260000000000005,
            8.319999999999993,
            8.299999999999997,
            8.280000000000001,
            8.439999999999998,
            8.11,
            8.269999999999996,
            8.36,
            8.060000000000002,
            8.14,
            8.079999999999998,
            8.170000000000002,
            8.379999999999995,
            8.079999999999998,
            8.209999999999994
        ],
        "test_loss": [],
        "test_acc": [
            11.79,
            84.88,
            87.62,
            88.67,
            88.41,
            85.66,
            88.94,
            89.09,
            89.94,
            89.02,
            89.9,
            89.71,
            90.64,
            90.08,
            90.71,
            90.21,
            90.01,
            90.64,
            89.56,
            91.06,
            91.34,
            91.27,
            91.4,
            91.41,
            91.44,
            91.35,
            91.38,
            91.23,
            91.08,
            91.36,
            91.14,
            90.9,
            91.64,
            91.38,
            90.97,
            91.02,
            91.42,
            91.43,
            91.21,
            91.55,
            91.58,
            91.39,
            91.42,
            91.51,
            91.5,
            91.64,
            91.68,
            91.45,
            91.61,
            91.59,
            91.55,
            91.49,
            91.26,
            91.58,
            91.64,
            91.56,
            91.69,
            91.86,
            91.89,
            91.68,
            91.64,
            91.75,
            91.76,
            91.45,
            91.89,
            91.74,
            91.66,
            91.6,
            91.83,
            91.66,
            91.83,
            91.8,
            91.87,
            91.96,
            91.6,
            91.74,
            91.91,
            91.74,
            91.68,
            91.7,
            91.72,
            91.56,
            91.89,
            91.73,
            91.64,
            91.94,
            91.86,
            91.92,
            91.83,
            91.62,
            91.92,
            91.79
        ],
        "train_error": [
            87.81666666666666,
            14.188333333333333,
            11.321666666666673,
            9.89333333333333,
            10.36,
            12.314999999999998,
            8.75333333333333,
            8.685000000000002,
            7.278333333333336,
            8.090000000000003,
            7.23833333333333,
            7.079999999999998,
            6.111666666666665,
            6.233333333333334,
            5.790000000000006,
            5.859999999999999,
            5.398333333333326,
            5.180000000000007,
            5.954999999999998,
            3.844999999999999,
            3.239999999999995,
            3.0900000000000034,
            2.74166666666666,
            2.63333333333334,
            2.3333333333333286,
            2.231666666666669,
            2.2950000000000017,
            2.1400000000000006,
            2.105000000000004,
            1.9566666666666634,
            2.3400000000000034,
            2.0400000000000063,
            1.8166666666666629,
            1.6800000000000068,
            1.7549999999999955,
            1.806666666666672,
            1.5783333333333331,
            1.0183333333333309,
            0.7549999999999955,
            0.7033333333333331,
            0.7083333333333286,
            0.6949999999999932,
            0.730000000000004,
            0.568333333333328,
            0.43166666666667197,
            0.5116666666666703,
            0.40500000000000114,
            0.4366666666666674,
            0.5333333333333314,
            0.355000000000004,
            0.32500000000000284,
            0.326666666666668,
            0.37000000000000455,
            0.33166666666666345,
            0.3433333333333337,
            0.1983333333333377,
            0.19666666666667254,
            0.15833333333333144,
            0.1566666666666663,
            0.14833333333332632,
            0.13833333333333542,
            0.12666666666666515,
            0.09666666666666401,
            0.12666666666666515,
            0.09166666666666856,
            0.0799999999999983,
            0.09999999999999432,
            0.11333333333332973,
            0.10999999999999943,
            0.09333333333333371,
            0.09999999999999432,
            0.07833333333333314,
            0.09833333333332916,
            0.09000000000000341,
            0.09000000000000341,
            0.06999999999999318,
            0.08499999999999375,
            0.06499999999999773,
            0.05666666666667197,
            0.041666666666671404,
            0.07500000000000284,
            0.05500000000000682,
            0.05333333333332746,
            0.060000000000002274,
            0.043333333333336554,
            0.06499999999999773,
            0.05666666666667197,
            0.07500000000000284,
            0.046666666666666856,
            0.06333333333333258,
            0.05333333333332746,
            0.05333333333332746
        ],
        "train_loss": [
            2.2996753634134928,
            0.4027208018541336,
            0.30643623553315796,
            0.27199478305578234,
            0.275912350209554,
            0.3231240223010381,
            0.23385071314076583,
            0.23622058596809706,
            0.20134476612607638,
            0.21493242353300254,
            0.1951236975699663,
            0.18586481451888878,
            0.16450124756743512,
            0.16575334607660772,
            0.15630383687019347,
            0.15672338238321246,
            0.14547083709935346,
            0.14083169753501812,
            0.16000244627352803,
            0.1016079207400481,
            0.08768967257921273,
            0.08782274559053282,
            0.07597365188629678,
            0.07257212000166377,
            0.06758186633810401,
            0.06409032483923559,
            0.06420709591607253,
            0.06147494533155114,
            0.056471791800049444,
            0.05417568847145885,
            0.06348321669491318,
            0.05587482926730687,
            0.05056225026709338,
            0.047679476611378294,
            0.04795353437124286,
            0.04843778654998168,
            0.04470897251714487,
            0.031319620287480456,
            0.026179250283003785,
            0.023161721929484822,
            0.02259174605391454,
            0.022213835706957615,
            0.02203262339194383,
            0.019378815972203544,
            0.01742002941336638,
            0.017361267398726583,
            0.015249942809603333,
            0.01609417006989485,
            0.01737226037142876,
            0.015097253286916142,
            0.013010494744967098,
            0.013982986094849183,
            0.013621346666335013,
            0.01290602200788356,
            0.012463352387053844,
            0.01065867986753583,
            0.009661472470516855,
            0.008586045076636947,
            0.008347166291464236,
            0.008402422877445739,
            0.008061039776187924,
            0.007497844584862468,
            0.006987914684457549,
            0.0077692304063200325,
            0.006988305094691653,
            0.006684300254633612,
            0.0069570114550009145,
            0.00671648167684131,
            0.006740541798252768,
            0.006695073277355793,
            0.006632691862335196,
            0.0064128281166310145,
            0.0066489042902913445,
            0.006297603144853686,
            0.006185850707442538,
            0.005606759715140409,
            0.005616578011083887,
            0.005789108924726801,
            0.005437362719399486,
            0.005359902335849862,
            0.005347823914216133,
            0.005172172723863817,
            0.005112726740531555,
            0.005175111168600657,
            0.004905811893869153,
            0.005161173312380076,
            0.005123772496233262,
            0.0053444237815352,
            0.005031042127890396,
            0.005240677778720662,
            0.005049051897761698,
            0.004678805175344557
        ],
        "train_acc": [
            12.183333333333334,
            85.81166666666667,
            88.67833333333333,
            90.10666666666667,
            89.64,
            87.685,
            91.24666666666667,
            91.315,
            92.72166666666666,
            91.91,
            92.76166666666667,
            92.92,
            93.88833333333334,
            93.76666666666667,
            94.21,
            94.14,
            94.60166666666667,
            94.82,
            94.045,
            96.155,
            96.76,
            96.91,
            97.25833333333334,
            97.36666666666666,
            97.66666666666667,
            97.76833333333333,
            97.705,
            97.86,
            97.895,
            98.04333333333334,
            97.66,
            97.96,
            98.18333333333334,
            98.32,
            98.245,
            98.19333333333333,
            98.42166666666667,
            98.98166666666667,
            99.245,
            99.29666666666667,
            99.29166666666667,
            99.305,
            99.27,
            99.43166666666667,
            99.56833333333333,
            99.48833333333333,
            99.595,
            99.56333333333333,
            99.46666666666667,
            99.645,
            99.675,
            99.67333333333333,
            99.63,
            99.66833333333334,
            99.65666666666667,
            99.80166666666666,
            99.80333333333333,
            99.84166666666667,
            99.84333333333333,
            99.85166666666667,
            99.86166666666666,
            99.87333333333333,
            99.90333333333334,
            99.87333333333333,
            99.90833333333333,
            99.92,
            99.9,
            99.88666666666667,
            99.89,
            99.90666666666667,
            99.9,
            99.92166666666667,
            99.90166666666667,
            99.91,
            99.91,
            99.93,
            99.915,
            99.935,
            99.94333333333333,
            99.95833333333333,
            99.925,
            99.945,
            99.94666666666667,
            99.94,
            99.95666666666666,
            99.935,
            99.94333333333333,
            99.925,
            99.95333333333333,
            99.93666666666667,
            99.94666666666667,
            99.94666666666667
        ],
        "best_test_acc": 91.96,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            3.6364362239837646,
            3.635303020477295,
            3.632194995880127,
            3.6399500370025635,
            3.5711770057678223,
            3.7222037315368652,
            3.610454797744751,
            3.655879497528076,
            3.7120978832244873,
            3.605370283126831,
            3.618574619293213,
            3.7724621295928955,
            3.8312597274780273,
            3.6101763248443604,
            3.6043145656585693,
            3.5957207679748535,
            3.923253297805786,
            3.9974586963653564,
            3.8068642616271973,
            3.8055787086486816,
            3.8068342208862305,
            3.8114025592803955,
            3.7940356731414795,
            3.5911834239959717,
            3.564007043838501,
            3.7535934448242188,
            3.998326063156128,
            3.610480785369873,
            3.6173434257507324,
            3.618856191635132,
            3.8617141246795654,
            3.5882232189178467,
            3.553588390350342,
            3.5257627964019775,
            3.512159585952759,
            3.5198442935943604,
            3.5186288356781006,
            3.521233320236206,
            3.545860528945923,
            3.564384698867798,
            3.5628879070281982,
            3.4530134201049805,
            3.51375675201416,
            3.531752109527588,
            3.5737192630767822,
            3.51741623878479,
            3.5031445026397705,
            3.5419609546661377,
            3.647507429122925,
            3.663722515106201
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 182.3730742931366,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 93750,
        "num_opt_steps": 93750,
        "num_grad_steps": 93749
    }
]