[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 32,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 1024,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.85,
                        "lr0": 0.01,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            88.06,
            14.409999999999997,
            12.650000000000006,
            11.530000000000001,
            12.310000000000002,
            12.510000000000005,
            10.450000000000003,
            12.120000000000005,
            10.459999999999994,
            10.329999999999998,
            10.180000000000007,
            10.219999999999999,
            9.829999999999998,
            10.200000000000003,
            9.379999999999995,
            10.069999999999993,
            9.829999999999998,
            9.730000000000004,
            9.680000000000007,
            9.090000000000003,
            8.980000000000004,
            9.159999999999997,
            8.739999999999995,
            8.590000000000003,
            8.849999999999994,
            8.219999999999999,
            8.540000000000006,
            8.560000000000002,
            8.75,
            8.519999999999996,
            8.670000000000002,
            8.670000000000002,
            8.819999999999993,
            8.430000000000007,
            8.930000000000007,
            8.680000000000007,
            8.459999999999994,
            8.39,
            8.370000000000005,
            8.310000000000002,
            8.329999999999998,
            8.170000000000002,
            7.989999999999995,
            8.129999999999995,
            8.25,
            8.340000000000003,
            8.239999999999995,
            8.150000000000006,
            8.159999999999997,
            8.36,
            8.090000000000003,
            8.299999999999997,
            8.159999999999997,
            8.099999999999994,
            8.329999999999998,
            8.299999999999997,
            7.989999999999995,
            8.019999999999996,
            8.120000000000005,
            8.150000000000006,
            8.099999999999994,
            8.260000000000005,
            7.859999999999999,
            7.920000000000002,
            8.180000000000007,
            7.920000000000002,
            8.219999999999999,
            8.040000000000006,
            8.129999999999995,
            8.219999999999999,
            8.200000000000003,
            7.909999999999997,
            7.739999999999995,
            8.129999999999995,
            8.0,
            8.14,
            7.980000000000004,
            8.019999999999996,
            8.019999999999996,
            7.939999999999998,
            7.900000000000006,
            8.049999999999997,
            8.219999999999999,
            8.129999999999995,
            7.890000000000001,
            7.939999999999998,
            7.959999999999994,
            8.159999999999997,
            8.019999999999996,
            8.129999999999995,
            8.030000000000001,
            8.060000000000002
        ],
        "test_loss": [],
        "test_acc": [
            11.94,
            85.59,
            87.35,
            88.47,
            87.69,
            87.49,
            89.55,
            87.88,
            89.54,
            89.67,
            89.82,
            89.78,
            90.17,
            89.8,
            90.62,
            89.93,
            90.17,
            90.27,
            90.32,
            90.91,
            91.02,
            90.84,
            91.26,
            91.41,
            91.15,
            91.78,
            91.46,
            91.44,
            91.25,
            91.48,
            91.33,
            91.33,
            91.18,
            91.57,
            91.07,
            91.32,
            91.54,
            91.61,
            91.63,
            91.69,
            91.67,
            91.83,
            92.01,
            91.87,
            91.75,
            91.66,
            91.76,
            91.85,
            91.84,
            91.64,
            91.91,
            91.7,
            91.84,
            91.9,
            91.67,
            91.7,
            92.01,
            91.98,
            91.88,
            91.85,
            91.9,
            91.74,
            92.14,
            92.08,
            91.82,
            92.08,
            91.78,
            91.96,
            91.87,
            91.78,
            91.8,
            92.09,
            92.26,
            91.87,
            92.0,
            91.86,
            92.02,
            91.98,
            91.98,
            92.06,
            92.1,
            91.95,
            91.78,
            91.87,
            92.11,
            92.06,
            92.04,
            91.84,
            91.98,
            91.87,
            91.97,
            91.94
        ],
        "train_error": [
            87.77833333333334,
            13.821666666666673,
            11.593333333333334,
            9.944999999999993,
            10.703333333333333,
            10.61666666666666,
            8.478333333333339,
            9.928333333333327,
            7.86666666666666,
            7.4283333333333275,
            6.924999999999997,
            6.853333333333339,
            6.438333333333333,
            6.301666666666662,
            5.733333333333334,
            6.288333333333327,
            5.849999999999994,
            5.209999999999994,
            5.8700000000000045,
            4.0816666666666634,
            3.4950000000000045,
            3.38333333333334,
            2.9666666666666686,
            3.018333333333331,
            2.5233333333333263,
            2.3816666666666606,
            2.433333333333337,
            2.1200000000000045,
            2.2049999999999983,
            1.923333333333332,
            1.9266666666666623,
            1.9650000000000034,
            1.894999999999996,
            1.5699999999999932,
            1.6299999999999955,
            1.6749999999999972,
            2.2333333333333343,
            1.1116666666666646,
            0.8816666666666606,
            0.8499999999999943,
            0.701666666666668,
            0.576666666666668,
            0.5466666666666669,
            0.5366666666666617,
            0.6783333333333275,
            0.5183333333333309,
            0.46333333333333826,
            0.41166666666666174,
            0.47833333333333883,
            0.403333333333336,
            0.42499999999999716,
            0.35999999999999943,
            0.326666666666668,
            0.3299999999999983,
            0.3333333333333286,
            0.24166666666666003,
            0.23999999999999488,
            0.20000000000000284,
            0.13833333333333542,
            0.13333333333333997,
            0.13666666666667027,
            0.18666666666666742,
            0.125,
            0.12999999999999545,
            0.18166666666667197,
            0.1316666666666606,
            0.11666666666666003,
            0.1316666666666606,
            0.08833333333333826,
            0.09499999999999886,
            0.10500000000000398,
            0.10833333333333428,
            0.09999999999999432,
            0.0799999999999983,
            0.07500000000000284,
            0.07500000000000284,
            0.06833333333332803,
            0.06333333333333258,
            0.07833333333333314,
            0.07166666666667254,
            0.06833333333332803,
            0.05500000000000682,
            0.06999999999999318,
            0.05666666666667197,
            0.05333333333332746,
            0.06499999999999773,
            0.06999999999999318,
            0.060000000000002274,
            0.06333333333333258,
            0.05666666666667197,
            0.05500000000000682,
            0.05333333333332746
        ],
        "train_loss": [
            2.299844200897217,
            0.38685214050014816,
            0.3153828251381715,
            0.27161260518034297,
            0.285765684958299,
            0.2774550135393937,
            0.2255808069686095,
            0.2676069101775686,
            0.21379195217589536,
            0.19665651502261558,
            0.18447349713742733,
            0.1811799568216006,
            0.1746588223690788,
            0.16956338325689235,
            0.15096857534870506,
            0.1689021371088922,
            0.15526280786792437,
            0.13851321412598094,
            0.15447728188435236,
            0.10740291104254623,
            0.09431725185482452,
            0.09491871876542766,
            0.08056115660263846,
            0.08342522197042902,
            0.07152634171688309,
            0.06810512978124122,
            0.06671703165713698,
            0.06194397326558829,
            0.059135725789237766,
            0.056145659626026946,
            0.053070738696233216,
            0.05452942958956895,
            0.053419150811821844,
            0.044926340032508595,
            0.0473395347956568,
            0.044617104986760144,
            0.058373884661553896,
            0.03364813882127249,
            0.028626875247612284,
            0.02560491013083568,
            0.022916761677281464,
            0.021017538589953134,
            0.019461851078826777,
            0.019518395744584267,
            0.02039936110165824,
            0.01871828145101123,
            0.016738967152417173,
            0.015835540856962326,
            0.016346231177834854,
            0.015095952739397763,
            0.015293333525693743,
            0.014193657701898095,
            0.01375819008971157,
            0.013077452634637787,
            0.012702411102008773,
            0.011072589425676658,
            0.010129058250386394,
            0.009226743779934866,
            0.008180706429827963,
            0.00804301543016918,
            0.007929808666837441,
            0.008296411862237922,
            0.007602538206789177,
            0.007723470677268536,
            0.007880279262654465,
            0.0071546183451173416,
            0.007164960188620413,
            0.006803388464159798,
            0.006717014562977905,
            0.006408685357469464,
            0.006817176047051908,
            0.006457477444655767,
            0.006392062984813432,
            0.005947064888800378,
            0.005817061817583453,
            0.0055061728423179985,
            0.0055882809991294686,
            0.005493665291121821,
            0.005336865589918065,
            0.005356296785302402,
            0.005254893318919494,
            0.00522722065581717,
            0.005433479160419059,
            0.005059069819276192,
            0.00495667937071897,
            0.005183662264780166,
            0.005090729782474712,
            0.0048925436613935745,
            0.005280563302208126,
            0.004881083467351467,
            0.004837289886770001,
            0.004745675071537941
        ],
        "train_acc": [
            12.221666666666666,
            86.17833333333333,
            88.40666666666667,
            90.055,
            89.29666666666667,
            89.38333333333334,
            91.52166666666666,
            90.07166666666667,
            92.13333333333334,
            92.57166666666667,
            93.075,
            93.14666666666666,
            93.56166666666667,
            93.69833333333334,
            94.26666666666667,
            93.71166666666667,
            94.15,
            94.79,
            94.13,
            95.91833333333334,
            96.505,
            96.61666666666666,
            97.03333333333333,
            96.98166666666667,
            97.47666666666667,
            97.61833333333334,
            97.56666666666666,
            97.88,
            97.795,
            98.07666666666667,
            98.07333333333334,
            98.035,
            98.105,
            98.43,
            98.37,
            98.325,
            97.76666666666667,
            98.88833333333334,
            99.11833333333334,
            99.15,
            99.29833333333333,
            99.42333333333333,
            99.45333333333333,
            99.46333333333334,
            99.32166666666667,
            99.48166666666667,
            99.53666666666666,
            99.58833333333334,
            99.52166666666666,
            99.59666666666666,
            99.575,
            99.64,
            99.67333333333333,
            99.67,
            99.66666666666667,
            99.75833333333334,
            99.76,
            99.8,
            99.86166666666666,
            99.86666666666666,
            99.86333333333333,
            99.81333333333333,
            99.875,
            99.87,
            99.81833333333333,
            99.86833333333334,
            99.88333333333334,
            99.86833333333334,
            99.91166666666666,
            99.905,
            99.895,
            99.89166666666667,
            99.9,
            99.92,
            99.925,
            99.925,
            99.93166666666667,
            99.93666666666667,
            99.92166666666667,
            99.92833333333333,
            99.93166666666667,
            99.945,
            99.93,
            99.94333333333333,
            99.94666666666667,
            99.935,
            99.93,
            99.94,
            99.93666666666667,
            99.94333333333333,
            99.945,
            99.94666666666667
        ],
        "best_test_acc": 92.26,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            3.5469274520874023,
            3.7117867469787598,
            3.6864655017852783,
            3.670562505722046,
            3.6956522464752197,
            3.697831153869629,
            3.6662344932556152,
            3.6609625816345215,
            3.6811132431030273,
            3.6711316108703613,
            3.6678829193115234,
            3.6721103191375732,
            3.6831166744232178,
            3.668654203414917,
            3.663803815841675,
            3.662632703781128,
            3.6645474433898926,
            3.6643922328948975,
            3.661482810974121,
            3.7613847255706787,
            3.6689224243164062,
            3.6492514610290527,
            3.661808729171753,
            3.6411008834838867,
            3.6525156497955322,
            3.655681610107422,
            3.6579694747924805,
            3.658550977706909,
            3.641054391860962,
            3.6531059741973877,
            3.6457550525665283,
            3.646711826324463,
            3.6463403701782227,
            3.6525654792785645,
            3.646888494491577,
            3.6243767738342285,
            3.6484413146972656,
            3.651397228240967,
            3.6387484073638916,
            3.648773670196533,
            3.6437339782714844,
            3.645918369293213,
            3.6424472332000732,
            3.6446797847747803,
            3.651323080062866,
            3.654970169067383,
            3.656764268875122,
            3.648228883743286,
            3.653555154800415,
            3.6431026458740234
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 182.93335914611816,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 93750,
        "num_opt_steps": 93750,
        "num_grad_steps": 93749
    }
]