[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 32,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 1024,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": null,
                        "initial_loss_sampling_fraction": 1,
                        "lr0": 0.01,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            88.03,
            14.810000000000002,
            12.430000000000007,
            11.269999999999996,
            11.019999999999996,
            11.790000000000006,
            10.459999999999994,
            11.659999999999997,
            9.430000000000007,
            10.25,
            10.030000000000001,
            9.64,
            9.790000000000006,
            9.420000000000002,
            9.599999999999994,
            9.680000000000007,
            9.89,
            9.260000000000005,
            9.769999999999996,
            8.980000000000004,
            8.560000000000002,
            8.980000000000004,
            8.560000000000002,
            8.290000000000006,
            8.329999999999998,
            8.400000000000006,
            8.5,
            8.829999999999998,
            8.209999999999994,
            8.540000000000006,
            9.069999999999993,
            9.129999999999995,
            8.579999999999998,
            8.530000000000001,
            8.260000000000005,
            8.420000000000002,
            8.379999999999995,
            8.120000000000005,
            8.730000000000004,
            8.239999999999995,
            8.030000000000001,
            8.349999999999994,
            8.010000000000005,
            8.120000000000005,
            8.189999999999998,
            8.319999999999993,
            8.14,
            8.230000000000004,
            8.040000000000006,
            8.14,
            8.150000000000006,
            8.049999999999997,
            8.120000000000005,
            8.180000000000007,
            7.950000000000003,
            7.849999999999994,
            8.150000000000006,
            8.189999999999998,
            8.060000000000002,
            8.170000000000002,
            8.180000000000007,
            7.980000000000004,
            8.099999999999994,
            8.209999999999994,
            8.099999999999994,
            8.090000000000003,
            8.14,
            8.150000000000006,
            7.980000000000004,
            8.069999999999993,
            7.859999999999999,
            7.930000000000007,
            7.920000000000002,
            8.11,
            7.859999999999999,
            8.069999999999993,
            8.170000000000002,
            8.230000000000004,
            8.11,
            8.090000000000003,
            8.099999999999994,
            8.189999999999998,
            8.040000000000006,
            8.030000000000001,
            8.0,
            7.829999999999998,
            8.069999999999993,
            8.010000000000005,
            8.099999999999994,
            8.040000000000006,
            7.849999999999994,
            8.129999999999995
        ],
        "test_loss": [],
        "test_acc": [
            11.97,
            85.19,
            87.57,
            88.73,
            88.98,
            88.21,
            89.54,
            88.34,
            90.57,
            89.75,
            89.97,
            90.36,
            90.21,
            90.58,
            90.4,
            90.32,
            90.11,
            90.74,
            90.23,
            91.02,
            91.44,
            91.02,
            91.44,
            91.71,
            91.67,
            91.6,
            91.5,
            91.17,
            91.79,
            91.46,
            90.93,
            90.87,
            91.42,
            91.47,
            91.74,
            91.58,
            91.62,
            91.88,
            91.27,
            91.76,
            91.97,
            91.65,
            91.99,
            91.88,
            91.81,
            91.68,
            91.86,
            91.77,
            91.96,
            91.86,
            91.85,
            91.95,
            91.88,
            91.82,
            92.05,
            92.15,
            91.85,
            91.81,
            91.94,
            91.83,
            91.82,
            92.02,
            91.9,
            91.79,
            91.9,
            91.91,
            91.86,
            91.85,
            92.02,
            91.93,
            92.14,
            92.07,
            92.08,
            91.89,
            92.14,
            91.93,
            91.83,
            91.77,
            91.89,
            91.91,
            91.9,
            91.81,
            91.96,
            91.97,
            92.0,
            92.17,
            91.93,
            91.99,
            91.9,
            91.96,
            92.15,
            91.87
        ],
        "train_error": [
            87.805,
            14.069999999999993,
            11.444999999999993,
            9.811666666666667,
            9.553333333333327,
            9.825000000000003,
            8.150000000000006,
            9.543333333333337,
            7.198333333333338,
            7.266666666666666,
            7.209999999999994,
            6.901666666666671,
            6.204999999999998,
            5.986666666666665,
            5.780000000000001,
            5.676666666666662,
            5.776666666666671,
            5.1683333333333366,
            5.734999999999999,
            3.7750000000000057,
            3.538333333333327,
            3.413333333333327,
            2.7533333333333303,
            2.693333333333328,
            2.6016666666666737,
            2.6133333333333297,
            2.4116666666666617,
            2.403333333333336,
            2.1316666666666606,
            1.8499999999999943,
            2.1616666666666617,
            2.663333333333327,
            1.9266666666666623,
            1.8250000000000028,
            1.5883333333333383,
            1.3816666666666606,
            1.7083333333333286,
            1.0550000000000068,
            0.9833333333333343,
            0.7666666666666657,
            0.6833333333333371,
            0.6700000000000017,
            0.6666666666666714,
            0.5166666666666657,
            0.6133333333333297,
            0.5999999999999943,
            0.5333333333333314,
            0.4350000000000023,
            0.49500000000000455,
            0.471666666666664,
            0.40500000000000114,
            0.33833333333333826,
            0.3100000000000023,
            0.6299999999999955,
            0.37333333333333485,
            0.2183333333333337,
            0.22666666666667368,
            0.20666666666666345,
            0.1666666666666714,
            0.18999999999999773,
            0.18166666666667197,
            0.2049999999999983,
            0.18000000000000682,
            0.11499999999999488,
            0.14499999999999602,
            0.15500000000000114,
            0.13666666666667027,
            0.14333333333333087,
            0.13833333333333542,
            0.13500000000000512,
            0.1183333333333394,
            0.10500000000000398,
            0.1316666666666606,
            0.10166666666667368,
            0.08666666666667311,
            0.08499999999999375,
            0.09333333333333371,
            0.08666666666667311,
            0.09333333333333371,
            0.07666666666666799,
            0.07666666666666799,
            0.07666666666666799,
            0.0833333333333286,
            0.061666666666667425,
            0.06499999999999773,
            0.08833333333333826,
            0.06833333333332803,
            0.07500000000000284,
            0.08499999999999375,
            0.04000000000000625,
            0.06833333333332803,
            0.05666666666667197
        ],
        "train_loss": [
            2.2998557703653972,
            0.394464304959774,
            0.30904907878835997,
            0.26820985578497253,
            0.2553990956544876,
            0.2600832015057405,
            0.22099359585046768,
            0.2530678195128838,
            0.19791887443959713,
            0.19371738132536412,
            0.1936170750270287,
            0.18012004518285393,
            0.1696585585569342,
            0.16244609704713026,
            0.15547540124530593,
            0.15437035246516267,
            0.1520423773959279,
            0.1389380207568407,
            0.1560438557602465,
            0.10252020150336126,
            0.09415948127092173,
            0.09363314016660054,
            0.07586717953073482,
            0.07613116377666593,
            0.07121979901694382,
            0.07308213474514584,
            0.06815579862544933,
            0.06581876145995533,
            0.059344196033167346,
            0.054304186161452286,
            0.060570996231306344,
            0.06870129230717818,
            0.05402476675249636,
            0.05075535091695686,
            0.04611117068810078,
            0.041308258116788545,
            0.04845144336537147,
            0.032167751178785696,
            0.031994676849257664,
            0.02442016151446927,
            0.02313997890581377,
            0.022348625148646533,
            0.02159713933863677,
            0.019000994323539393,
            0.020762734348280354,
            0.02016531866537407,
            0.01912029342627696,
            0.016898913487852163,
            0.017507537414393544,
            0.01628761957207656,
            0.015430470328563631,
            0.014395758742309408,
            0.013134848733198791,
            0.01947023893634323,
            0.013373888010763524,
            0.011394936391649147,
            0.010746959380295205,
            0.009668161672972686,
            0.009413838923339305,
            0.009235689934467276,
            0.009298328518495933,
            0.009122212397517674,
            0.008979002468776889,
            0.008198923426831607,
            0.008098201620592348,
            0.00815977299768565,
            0.007516152154735028,
            0.0074810263523443915,
            0.008052803129664,
            0.007918165726154499,
            0.007323729701394101,
            0.007328643580907858,
            0.007386454413134198,
            0.0067387975078483575,
            0.006564735582406865,
            0.006609719381557079,
            0.006466310785500294,
            0.006232378394589371,
            0.0063613180981881064,
            0.005996493613034545,
            0.005797162901311337,
            0.005890059296470524,
            0.006046571855261572,
            0.005751356725368533,
            0.00569291189913735,
            0.006022416706568401,
            0.005801283152571704,
            0.0057322238811155935,
            0.005745737608569713,
            0.005189381399901079,
            0.00555755608565402,
            0.005586124601075911
        ],
        "train_acc": [
            12.195,
            85.93,
            88.555,
            90.18833333333333,
            90.44666666666667,
            90.175,
            91.85,
            90.45666666666666,
            92.80166666666666,
            92.73333333333333,
            92.79,
            93.09833333333333,
            93.795,
            94.01333333333334,
            94.22,
            94.32333333333334,
            94.22333333333333,
            94.83166666666666,
            94.265,
            96.225,
            96.46166666666667,
            96.58666666666667,
            97.24666666666667,
            97.30666666666667,
            97.39833333333333,
            97.38666666666667,
            97.58833333333334,
            97.59666666666666,
            97.86833333333334,
            98.15,
            97.83833333333334,
            97.33666666666667,
            98.07333333333334,
            98.175,
            98.41166666666666,
            98.61833333333334,
            98.29166666666667,
            98.945,
            99.01666666666667,
            99.23333333333333,
            99.31666666666666,
            99.33,
            99.33333333333333,
            99.48333333333333,
            99.38666666666667,
            99.4,
            99.46666666666667,
            99.565,
            99.505,
            99.52833333333334,
            99.595,
            99.66166666666666,
            99.69,
            99.37,
            99.62666666666667,
            99.78166666666667,
            99.77333333333333,
            99.79333333333334,
            99.83333333333333,
            99.81,
            99.81833333333333,
            99.795,
            99.82,
            99.885,
            99.855,
            99.845,
            99.86333333333333,
            99.85666666666667,
            99.86166666666666,
            99.865,
            99.88166666666666,
            99.895,
            99.86833333333334,
            99.89833333333333,
            99.91333333333333,
            99.915,
            99.90666666666667,
            99.91333333333333,
            99.90666666666667,
            99.92333333333333,
            99.92333333333333,
            99.92333333333333,
            99.91666666666667,
            99.93833333333333,
            99.935,
            99.91166666666666,
            99.93166666666667,
            99.925,
            99.915,
            99.96,
            99.93166666666667,
            99.94333333333333
        ],
        "best_test_acc": 92.17,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            3.439424753189087,
            3.460012197494507,
            3.4172964096069336,
            3.3555169105529785,
            3.4064245223999023,
            3.3981986045837402,
            3.3677234649658203,
            3.3944919109344482,
            3.353095769882202,
            3.352762222290039,
            3.2690446376800537,
            3.2486045360565186,
            3.3086509704589844,
            3.3128066062927246,
            3.247775077819824,
            3.230907917022705,
            3.1503334045410156,
            3.1683695316314697,
            3.1799185276031494,
            3.255159378051758,
            3.2380263805389404,
            3.239537477493286,
            3.3269407749176025,
            3.236039876937866,
            3.2782678604125977,
            3.3229074478149414,
            3.3458847999572754,
            3.237287759780884,
            3.2318453788757324,
            3.2341151237487793,
            3.257652521133423,
            3.252044439315796,
            3.2699177265167236,
            3.2601728439331055,
            3.2747864723205566,
            3.219710350036621,
            3.235912561416626,
            3.216732978820801,
            3.2247626781463623,
            3.251418352127075,
            3.2432668209075928,
            3.2279257774353027,
            3.196810483932495,
            3.2143282890319824,
            3.2354395389556885,
            3.2282497882843018,
            3.254988670349121,
            3.2725799083709717,
            3.281491756439209,
            3.2465057373046875
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 163.8720679283142,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 93750,
        "num_opt_steps": 93750,
        "num_grad_steps": 93749
    }
]