[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 32,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 1024,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.2,
                        "lr0": 0.01,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            88.56,
            21.689999999999998,
            18.810000000000002,
            18.430000000000007,
            18.17,
            19.370000000000005,
            18.200000000000003,
            16.569999999999993,
            15.189999999999998,
            14.11,
            14.519999999999996,
            15.319999999999993,
            15.159999999999997,
            17.519999999999996,
            15.079999999999998,
            14.349999999999994,
            15.040000000000006,
            14.5,
            14.700000000000003,
            12.5,
            11.579999999999998,
            11.659999999999997,
            10.969999999999999,
            10.989999999999995,
            10.569999999999993,
            10.920000000000002,
            11.079999999999998,
            11.230000000000004,
            10.89,
            10.969999999999999,
            11.39,
            11.540000000000006,
            10.769999999999996,
            10.730000000000004,
            10.739999999999995,
            10.920000000000002,
            11.14,
            9.870000000000005,
            10.019999999999996,
            9.959999999999994,
            9.989999999999995,
            9.629999999999995,
            9.450000000000003,
            10.0,
            9.560000000000002,
            9.670000000000002,
            9.340000000000003,
            9.840000000000003,
            9.670000000000002,
            9.780000000000001,
            9.780000000000001,
            9.64,
            9.849999999999994,
            10.040000000000006,
            9.730000000000004,
            9.700000000000003,
            9.64,
            9.219999999999999,
            9.439999999999998,
            9.349999999999994,
            9.230000000000004,
            9.400000000000006,
            9.239999999999995,
            9.530000000000001,
            9.629999999999995,
            9.310000000000002,
            9.280000000000001,
            9.310000000000002,
            9.25,
            9.450000000000003,
            9.469999999999999,
            9.370000000000005,
            9.36,
            9.590000000000003,
            9.120000000000005,
            8.930000000000007,
            8.810000000000002,
            8.950000000000003,
            9.060000000000002,
            9.069999999999993,
            8.969999999999999,
            9.230000000000004,
            9.11,
            9.040000000000006,
            9.0,
            9.5,
            9.299999999999997,
            9.260000000000005,
            9.239999999999995,
            9.319999999999993,
            9.209999999999994,
            9.11
        ],
        "test_loss": [],
        "test_acc": [
            11.44,
            78.31,
            81.19,
            81.57,
            81.83,
            80.63,
            81.8,
            83.43,
            84.81,
            85.89,
            85.48,
            84.68,
            84.84,
            82.48,
            84.92,
            85.65,
            84.96,
            85.5,
            85.3,
            87.5,
            88.42,
            88.34,
            89.03,
            89.01,
            89.43,
            89.08,
            88.92,
            88.77,
            89.11,
            89.03,
            88.61,
            88.46,
            89.23,
            89.27,
            89.26,
            89.08,
            88.86,
            90.13,
            89.98,
            90.04,
            90.01,
            90.37,
            90.55,
            90.0,
            90.44,
            90.33,
            90.66,
            90.16,
            90.33,
            90.22,
            90.22,
            90.36,
            90.15,
            89.96,
            90.27,
            90.3,
            90.36,
            90.78,
            90.56,
            90.65,
            90.77,
            90.6,
            90.76,
            90.47,
            90.37,
            90.69,
            90.72,
            90.69,
            90.75,
            90.55,
            90.53,
            90.63,
            90.64,
            90.41,
            90.88,
            91.07,
            91.19,
            91.05,
            90.94,
            90.93,
            91.03,
            90.77,
            90.89,
            90.96,
            91.0,
            90.5,
            90.7,
            90.74,
            90.76,
            90.68,
            90.79,
            90.89
        ],
        "train_error": [
            88.53833333333333,
            20.784999999999997,
            17.935000000000002,
            16.98166666666667,
            16.961666666666673,
            17.71666666666667,
            16.656666666666666,
            15.489999999999995,
            14.064999999999998,
            12.88333333333334,
            12.553333333333327,
            13.656666666666666,
            13.361666666666665,
            15.578333333333333,
            12.853333333333339,
            11.88166666666666,
            13.588333333333338,
            12.111666666666665,
            12.715000000000003,
            9.678333333333327,
            8.754999999999995,
            8.15166666666667,
            7.598333333333329,
            7.37833333333333,
            6.736666666666665,
            6.694999999999993,
            6.723333333333329,
            6.718333333333334,
            6.313333333333333,
            6.4466666666666725,
            7.0,
            6.530000000000001,
            5.640000000000001,
            5.473333333333329,
            5.4466666666666725,
            5.323333333333338,
            6.010000000000005,
            3.998333333333335,
            3.7633333333333354,
            3.396666666666661,
            3.0900000000000034,
            2.8416666666666686,
            2.6700000000000017,
            2.319999999999993,
            2.3616666666666646,
            2.344999999999999,
            1.961666666666673,
            1.9966666666666697,
            1.875,
            1.931666666666672,
            1.9099999999999966,
            1.6650000000000063,
            1.8933333333333309,
            1.7033333333333331,
            1.6783333333333275,
            1.3499999999999943,
            1.0100000000000051,
            0.7933333333333366,
            0.7600000000000051,
            0.7433333333333394,
            0.605000000000004,
            0.5983333333333292,
            0.47833333333333883,
            0.548333333333332,
            0.44666666666667254,
            0.48166666666666913,
            0.4683333333333337,
            0.40833333333333144,
            0.36666666666666003,
            0.42166666666666686,
            0.3983333333333263,
            0.31833333333332803,
            0.3850000000000051,
            0.32500000000000284,
            0.23666666666666458,
            0.201666666666668,
            0.18000000000000682,
            0.19166666666666288,
            0.19666666666667254,
            0.15833333333333144,
            0.16166666666666174,
            0.1766666666666623,
            0.1700000000000017,
            0.14833333333332632,
            0.15166666666667084,
            0.15833333333333144,
            0.18833333333333258,
            0.15000000000000568,
            0.14000000000000057,
            0.12999999999999545,
            0.15166666666667084,
            0.14666666666666117
        ],
        "train_loss": [
            2.3031558011372883,
            0.5938430721441905,
            0.5383678540865581,
            0.5464491797288259,
            0.4577247741540273,
            0.43683848456541696,
            0.4702099198500315,
            0.4171823434352875,
            0.3795694358587265,
            0.36026914755503336,
            0.3444647360086441,
            0.38792002397378283,
            0.3639024950583776,
            0.3974558979988098,
            0.34212435330152513,
            0.31112312426964445,
            0.3565076818943024,
            0.33700765569607416,
            0.36271318333148955,
            0.2600229867517948,
            0.23429272081653277,
            0.22854437890251478,
            0.20365245887438457,
            0.2008104625026385,
            0.17814855984399716,
            0.19051977957487107,
            0.1808840233484904,
            0.17782756023208302,
            0.16760922202269235,
            0.1695090080310901,
            0.17926131580074628,
            0.16901572920779387,
            0.14731072737723588,
            0.1421228726868828,
            0.14104862480039398,
            0.14035644968847433,
            0.1562982894440492,
            0.10811734766885638,
            0.09947981283565362,
            0.08687199391908944,
            0.08191311915144324,
            0.07489858379562696,
            0.07132355072423816,
            0.0617645374767327,
            0.06147513441834599,
            0.0627290556785961,
            0.055165165289569024,
            0.05433222376367388,
            0.04980529452411769,
            0.05236810446033875,
            0.052724063341707615,
            0.04571334166643598,
            0.050065060051297766,
            0.04633194716311991,
            0.04406493560041611,
            0.038506023719177274,
            0.028778122251729172,
            0.023968964878151987,
            0.02237093963638569,
            0.02190520557749672,
            0.019622310156549794,
            0.018503092235295723,
            0.016544571718339528,
            0.017304055802042907,
            0.01536746282891836,
            0.014996106316649821,
            0.01469430105061862,
            0.013420617663731295,
            0.012755261565754336,
            0.013165784546705254,
            0.013052990799477629,
            0.012097174367275632,
            0.012319348609993177,
            0.011593507124425256,
            0.009835909289902581,
            0.008694815387144141,
            0.008327048029195672,
            0.007650904252342904,
            0.007871534676205131,
            0.0074857443492943885,
            0.007013700148827047,
            0.007038536843786763,
            0.007300428956590137,
            0.0066449547272684865,
            0.006739754941304758,
            0.006885323777116234,
            0.007360278936942632,
            0.00612810713146561,
            0.006225425081149782,
            0.006059498342734999,
            0.006339079592667717,
            0.006287508881979071
        ],
        "train_acc": [
            11.461666666666666,
            79.215,
            82.065,
            83.01833333333333,
            83.03833333333333,
            82.28333333333333,
            83.34333333333333,
            84.51,
            85.935,
            87.11666666666666,
            87.44666666666667,
            86.34333333333333,
            86.63833333333334,
            84.42166666666667,
            87.14666666666666,
            88.11833333333334,
            86.41166666666666,
            87.88833333333334,
            87.285,
            90.32166666666667,
            91.245,
            91.84833333333333,
            92.40166666666667,
            92.62166666666667,
            93.26333333333334,
            93.305,
            93.27666666666667,
            93.28166666666667,
            93.68666666666667,
            93.55333333333333,
            93.0,
            93.47,
            94.36,
            94.52666666666667,
            94.55333333333333,
            94.67666666666666,
            93.99,
            96.00166666666667,
            96.23666666666666,
            96.60333333333334,
            96.91,
            97.15833333333333,
            97.33,
            97.68,
            97.63833333333334,
            97.655,
            98.03833333333333,
            98.00333333333333,
            98.125,
            98.06833333333333,
            98.09,
            98.335,
            98.10666666666667,
            98.29666666666667,
            98.32166666666667,
            98.65,
            98.99,
            99.20666666666666,
            99.24,
            99.25666666666666,
            99.395,
            99.40166666666667,
            99.52166666666666,
            99.45166666666667,
            99.55333333333333,
            99.51833333333333,
            99.53166666666667,
            99.59166666666667,
            99.63333333333334,
            99.57833333333333,
            99.60166666666667,
            99.68166666666667,
            99.615,
            99.675,
            99.76333333333334,
            99.79833333333333,
            99.82,
            99.80833333333334,
            99.80333333333333,
            99.84166666666667,
            99.83833333333334,
            99.82333333333334,
            99.83,
            99.85166666666667,
            99.84833333333333,
            99.84166666666667,
            99.81166666666667,
            99.85,
            99.86,
            99.87,
            99.84833333333333,
            99.85333333333334
        ],
        "best_test_acc": 91.19,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            3.859153985977173,
            4.0948333740234375,
            3.814138412475586,
            3.5822525024414062,
            3.4204537868499756,
            3.445162534713745,
            3.5408499240875244,
            3.6280484199523926,
            3.4853482246398926,
            3.3923161029815674,
            3.3100669384002686,
            3.2897167205810547,
            3.2940168380737305,
            3.3845415115356445,
            3.365654706954956,
            3.3451428413391113,
            3.3683056831359863,
            3.3621480464935303,
            3.4280507564544678,
            3.4284510612487793,
            3.4114840030670166,
            3.4318485260009766,
            3.4541869163513184,
            3.4469690322875977,
            3.3773722648620605,
            3.3935742378234863,
            3.362849712371826,
            3.3677804470062256,
            3.398372173309326,
            3.365480422973633,
            3.357689142227173,
            3.3532068729400635,
            3.363677501678467,
            3.387601613998413,
            3.374211549758911,
            3.341763496398926,
            3.3721506595611572,
            3.3540329933166504,
            3.4499118328094482,
            3.372105360031128,
            3.346297025680542,
            3.3309884071350098,
            3.3756356239318848,
            3.395158052444458,
            3.401080369949341,
            3.4959917068481445,
            3.4670915603637695,
            3.4232184886932373,
            3.5693089962005615,
            3.7967748641967773
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 172.17646622657776,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 93750,
        "num_opt_steps": 93750,
        "num_grad_steps": 93749
    }
]