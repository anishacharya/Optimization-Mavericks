[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 32,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 1024,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.3,
                        "lr0": 0.01,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            89.37,
            16.930000000000007,
            14.939999999999998,
            14.079999999999998,
            14.230000000000004,
            15.049999999999997,
            13.219999999999999,
            14.659999999999997,
            13.950000000000003,
            12.549999999999997,
            12.61,
            12.430000000000007,
            13.060000000000002,
            12.719999999999999,
            12.329999999999998,
            12.489999999999995,
            12.36,
            12.61,
            12.36,
            11.019999999999996,
            10.810000000000002,
            10.969999999999999,
            10.39,
            10.260000000000005,
            10.150000000000006,
            10.11,
            9.920000000000002,
            10.200000000000003,
            10.069999999999993,
            10.200000000000003,
            10.329999999999998,
            10.189999999999998,
            9.840000000000003,
            9.730000000000004,
            9.950000000000003,
            10.11,
            10.079999999999998,
            9.75,
            9.739999999999995,
            9.510000000000005,
            9.730000000000004,
            9.489999999999995,
            9.340000000000003,
            9.209999999999994,
            9.709999999999994,
            9.5,
            9.25,
            9.680000000000007,
            9.340000000000003,
            9.549999999999997,
            9.340000000000003,
            9.239999999999995,
            9.260000000000005,
            9.200000000000003,
            9.349999999999994,
            9.319999999999993,
            9.239999999999995,
            8.959999999999994,
            8.89,
            8.840000000000003,
            9.090000000000003,
            9.010000000000005,
            9.11,
            9.040000000000006,
            9.319999999999993,
            9.090000000000003,
            9.11,
            9.090000000000003,
            8.980000000000004,
            9.11,
            9.060000000000002,
            8.900000000000006,
            9.040000000000006,
            9.060000000000002,
            9.0,
            8.950000000000003,
            9.049999999999997,
            8.75,
            8.969999999999999,
            8.760000000000005,
            9.049999999999997,
            8.939999999999998,
            8.799999999999997,
            8.86,
            8.870000000000005,
            8.849999999999994,
            8.909999999999997,
            8.89,
            9.060000000000002,
            8.879999999999995,
            8.769999999999996,
            8.769999999999996
        ],
        "test_loss": [],
        "test_acc": [
            10.63,
            83.07,
            85.06,
            85.92,
            85.77,
            84.95,
            86.78,
            85.34,
            86.05,
            87.45,
            87.39,
            87.57,
            86.94,
            87.28,
            87.67,
            87.51,
            87.64,
            87.39,
            87.64,
            88.98,
            89.19,
            89.03,
            89.61,
            89.74,
            89.85,
            89.89,
            90.08,
            89.8,
            89.93,
            89.8,
            89.67,
            89.81,
            90.16,
            90.27,
            90.05,
            89.89,
            89.92,
            90.25,
            90.26,
            90.49,
            90.27,
            90.51,
            90.66,
            90.79,
            90.29,
            90.5,
            90.75,
            90.32,
            90.66,
            90.45,
            90.66,
            90.76,
            90.74,
            90.8,
            90.65,
            90.68,
            90.76,
            91.04,
            91.11,
            91.16,
            90.91,
            90.99,
            90.89,
            90.96,
            90.68,
            90.91,
            90.89,
            90.91,
            91.02,
            90.89,
            90.94,
            91.1,
            90.96,
            90.94,
            91.0,
            91.05,
            90.95,
            91.25,
            91.03,
            91.24,
            90.95,
            91.06,
            91.2,
            91.14,
            91.13,
            91.15,
            91.09,
            91.11,
            90.94,
            91.12,
            91.23,
            91.23
        ],
        "train_error": [
            89.38166666666666,
            16.21333333333334,
            13.694999999999993,
            12.450000000000003,
            12.900000000000006,
            13.071666666666673,
            11.248333333333335,
            12.838333333333338,
            11.831666666666663,
            10.50333333333333,
            10.398333333333326,
            10.056666666666672,
            10.61833333333334,
            10.458333333333329,
            10.200000000000003,
            9.980000000000004,
            9.38166666666666,
            9.650000000000006,
            9.486666666666665,
            7.086666666666673,
            6.704999999999998,
            6.353333333333339,
            5.486666666666665,
            5.670000000000002,
            5.066666666666663,
            4.898333333333326,
            4.584999999999994,
            4.381666666666661,
            4.230000000000004,
            4.364999999999995,
            4.248333333333335,
            4.213333333333338,
            3.9083333333333314,
            3.893333333333331,
            3.8216666666666725,
            3.7166666666666686,
            3.0833333333333286,
            2.489999999999995,
            2.2066666666666634,
            1.7466666666666697,
            1.6883333333333326,
            1.6599999999999966,
            1.4449999999999932,
            1.2716666666666612,
            1.4300000000000068,
            1.2650000000000006,
            1.1650000000000063,
            1.1433333333333309,
            0.971666666666664,
            0.951666666666668,
            0.9599999999999937,
            1.0116666666666703,
            0.903333333333336,
            0.7766666666666708,
            0.8299999999999983,
            0.6116666666666646,
            0.5750000000000028,
            0.41833333333333655,
            0.42833333333332746,
            0.42499999999999716,
            0.3366666666666731,
            0.3400000000000034,
            0.32166666666667254,
            0.25833333333333997,
            0.29999999999999716,
            0.29000000000000625,
            0.2633333333333354,
            0.269999999999996,
            0.2433333333333394,
            0.2466666666666697,
            0.21999999999999886,
            0.19166666666666288,
            0.23166666666666913,
            0.17166666666666686,
            0.14166666666666572,
            0.14499999999999602,
            0.15166666666667084,
            0.14000000000000057,
            0.12666666666666515,
            0.11166666666666458,
            0.11666666666666003,
            0.10333333333333883,
            0.09999999999999432,
            0.10500000000000398,
            0.09499999999999886,
            0.12333333333333485,
            0.09333333333333371,
            0.11666666666666003,
            0.11333333333332973,
            0.10833333333333428,
            0.12666666666666515,
            0.10333333333333883
        ],
        "train_loss": [
            2.3034638478597005,
            0.43979097501039505,
            0.36091366998751956,
            0.35858676882187523,
            0.3556892304937045,
            0.33242554868658386,
            0.3102943396250407,
            0.338549136642615,
            0.32283319394191107,
            0.2736930856009324,
            0.27387009992798167,
            0.2755744794030984,
            0.2793453487416108,
            0.2750770576238632,
            0.26966250506639483,
            0.2664080852260192,
            0.2505244607369105,
            0.25977848331133524,
            0.2575603310545286,
            0.18876246749957404,
            0.1786201676266889,
            0.16762379383345444,
            0.14773338934481145,
            0.14886380017424622,
            0.13108954348588983,
            0.12925684905871748,
            0.12259837443518141,
            0.11586212253682315,
            0.10955371584060292,
            0.11412243163920939,
            0.11148761260062456,
            0.10923528316033383,
            0.10330107822896292,
            0.09906726854157945,
            0.10222652534494797,
            0.09932866408390303,
            0.0839517178597084,
            0.06605649185266035,
            0.06142559643927962,
            0.04958933230130739,
            0.04696918748030439,
            0.0454585419079056,
            0.040821958719325875,
            0.036248869329636606,
            0.03846359705588936,
            0.03625099102052142,
            0.03306086051327487,
            0.031911444149848346,
            0.028295402209449094,
            0.02899005310224408,
            0.027568641798070167,
            0.028863465180120937,
            0.026150049931400767,
            0.023384149828692292,
            0.02388840746491066,
            0.019963124225161544,
            0.01735981181553555,
            0.014472210712774176,
            0.013788882694393155,
            0.013032683811328025,
            0.012588943235052526,
            0.011989186684210533,
            0.011462575566074277,
            0.010065362296894394,
            0.011004588579745178,
            0.00991546389064612,
            0.009891270278575635,
            0.009589540522643802,
            0.009276014573664481,
            0.00976628862610111,
            0.008608218062825987,
            0.008329227259751243,
            0.008889166014383287,
            0.0076255311810442435,
            0.00727620593829112,
            0.006671540299178726,
            0.006402296292737931,
            0.006620250230613601,
            0.006282473171798241,
            0.0057340876384050716,
            0.00613336288007096,
            0.005625318442939412,
            0.005633970037694962,
            0.005849945958602863,
            0.005366631811611539,
            0.005511643126438154,
            0.0053756923128165605,
            0.005350198169799963,
            0.005625505593331672,
            0.005333936878446669,
            0.005574176224018508,
            0.005012987804497667
        ],
        "train_acc": [
            10.618333333333334,
            83.78666666666666,
            86.305,
            87.55,
            87.1,
            86.92833333333333,
            88.75166666666667,
            87.16166666666666,
            88.16833333333334,
            89.49666666666667,
            89.60166666666667,
            89.94333333333333,
            89.38166666666666,
            89.54166666666667,
            89.8,
            90.02,
            90.61833333333334,
            90.35,
            90.51333333333334,
            92.91333333333333,
            93.295,
            93.64666666666666,
            94.51333333333334,
            94.33,
            94.93333333333334,
            95.10166666666667,
            95.415,
            95.61833333333334,
            95.77,
            95.635,
            95.75166666666667,
            95.78666666666666,
            96.09166666666667,
            96.10666666666667,
            96.17833333333333,
            96.28333333333333,
            96.91666666666667,
            97.51,
            97.79333333333334,
            98.25333333333333,
            98.31166666666667,
            98.34,
            98.555,
            98.72833333333334,
            98.57,
            98.735,
            98.835,
            98.85666666666667,
            99.02833333333334,
            99.04833333333333,
            99.04,
            98.98833333333333,
            99.09666666666666,
            99.22333333333333,
            99.17,
            99.38833333333334,
            99.425,
            99.58166666666666,
            99.57166666666667,
            99.575,
            99.66333333333333,
            99.66,
            99.67833333333333,
            99.74166666666666,
            99.7,
            99.71,
            99.73666666666666,
            99.73,
            99.75666666666666,
            99.75333333333333,
            99.78,
            99.80833333333334,
            99.76833333333333,
            99.82833333333333,
            99.85833333333333,
            99.855,
            99.84833333333333,
            99.86,
            99.87333333333333,
            99.88833333333334,
            99.88333333333334,
            99.89666666666666,
            99.9,
            99.895,
            99.905,
            99.87666666666667,
            99.90666666666667,
            99.88333333333334,
            99.88666666666667,
            99.89166666666667,
            99.87333333333333,
            99.89666666666666
        ],
        "best_test_acc": 91.25,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            3.6728641986846924,
            3.6908538341522217,
            3.660045862197876,
            3.811096429824829,
            3.764025926589966,
            3.627300500869751,
            3.634011745452881,
            3.7464449405670166,
            3.644516706466675,
            3.5468292236328125,
            3.552522897720337,
            3.7591331005096436,
            4.058385610580444,
            4.087914705276489,
            4.0690858364105225,
            4.059544801712036,
            4.065662384033203,
            3.73309063911438,
            3.5642945766448975,
            3.5527472496032715,
            3.6720151901245117,
            3.9340779781341553,
            3.8684329986572266,
            3.6097517013549805,
            3.5754029750823975,
            3.593843460083008,
            3.5808589458465576,
            3.7113451957702637,
            3.561183452606201,
            3.7263295650482178,
            3.6222360134124756,
            3.538269281387329,
            3.581247091293335,
            3.524559497833252,
            3.3237738609313965,
            3.3417699337005615,
            3.3428449630737305,
            3.6308324337005615,
            4.194245338439941,
            4.1920082569122314,
            4.153379440307617,
            3.347790241241455,
            3.349045991897583,
            3.3297951221466064,
            3.3958332538604736,
            3.6620030403137207,
            3.6748344898223877,
            3.657782793045044,
            3.670966863632202,
            3.6656439304351807
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 184.33247447013855,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 93750,
        "num_opt_steps": 93750,
        "num_grad_steps": 93749
    }
]