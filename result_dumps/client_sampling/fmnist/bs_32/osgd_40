[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 32,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 1024,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.4,
                        "lr0": 0.01,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            88.73,
            14.879999999999995,
            14.079999999999998,
            12.989999999999995,
            14.049999999999997,
            14.14,
            12.329999999999998,
            12.980000000000004,
            12.150000000000006,
            11.39,
            11.680000000000007,
            11.459999999999994,
            11.540000000000006,
            11.189999999999998,
            11.450000000000003,
            11.25,
            11.340000000000003,
            11.730000000000004,
            11.310000000000002,
            10.010000000000005,
            9.939999999999998,
            10.159999999999997,
            9.459999999999994,
            9.680000000000007,
            10.049999999999997,
            9.769999999999996,
            10.030000000000001,
            9.329999999999998,
            9.560000000000002,
            9.5,
            9.989999999999995,
            9.510000000000005,
            10.25,
            9.799999999999997,
            9.689999999999998,
            9.590000000000003,
            9.989999999999995,
            9.209999999999994,
            9.159999999999997,
            9.540000000000006,
            9.14,
            9.079999999999998,
            9.310000000000002,
            8.829999999999998,
            9.409999999999997,
            9.079999999999998,
            8.959999999999994,
            9.150000000000006,
            9.120000000000005,
            8.769999999999996,
            9.069999999999993,
            9.219999999999999,
            9.159999999999997,
            9.299999999999997,
            9.150000000000006,
            9.010000000000005,
            8.930000000000007,
            9.040000000000006,
            8.86,
            8.810000000000002,
            9.030000000000001,
            8.930000000000007,
            8.969999999999999,
            8.849999999999994,
            9.079999999999998,
            9.159999999999997,
            8.939999999999998,
            9.090000000000003,
            8.870000000000005,
            8.840000000000003,
            8.939999999999998,
            9.200000000000003,
            8.780000000000001,
            8.980000000000004,
            8.89,
            8.650000000000006,
            8.870000000000005,
            8.879999999999995,
            9.010000000000005,
            8.920000000000002,
            8.709999999999994,
            8.819999999999993,
            8.650000000000006,
            8.739999999999995,
            8.849999999999994,
            8.930000000000007,
            8.920000000000002,
            8.579999999999998,
            8.969999999999999,
            8.769999999999996,
            8.709999999999994,
            8.89
        ],
        "test_loss": [],
        "test_acc": [
            11.27,
            85.12,
            85.92,
            87.01,
            85.95,
            85.86,
            87.67,
            87.02,
            87.85,
            88.61,
            88.32,
            88.54,
            88.46,
            88.81,
            88.55,
            88.75,
            88.66,
            88.27,
            88.69,
            89.99,
            90.06,
            89.84,
            90.54,
            90.32,
            89.95,
            90.23,
            89.97,
            90.67,
            90.44,
            90.5,
            90.01,
            90.49,
            89.75,
            90.2,
            90.31,
            90.41,
            90.01,
            90.79,
            90.84,
            90.46,
            90.86,
            90.92,
            90.69,
            91.17,
            90.59,
            90.92,
            91.04,
            90.85,
            90.88,
            91.23,
            90.93,
            90.78,
            90.84,
            90.7,
            90.85,
            90.99,
            91.07,
            90.96,
            91.14,
            91.19,
            90.97,
            91.07,
            91.03,
            91.15,
            90.92,
            90.84,
            91.06,
            90.91,
            91.13,
            91.16,
            91.06,
            90.8,
            91.22,
            91.02,
            91.11,
            91.35,
            91.13,
            91.12,
            90.99,
            91.08,
            91.29,
            91.18,
            91.35,
            91.26,
            91.15,
            91.07,
            91.08,
            91.42,
            91.03,
            91.23,
            91.29,
            91.11
        ],
        "train_error": [
            88.72,
            13.858333333333334,
            12.788333333333327,
            11.391666666666666,
            12.316666666666663,
            11.986666666666665,
            10.344999999999999,
            11.191666666666663,
            9.38333333333334,
            8.998333333333335,
            8.870000000000005,
            9.13333333333334,
            8.59833333333333,
            8.433333333333337,
            8.536666666666662,
            8.161666666666662,
            7.8216666666666725,
            8.019999999999996,
            8.298333333333332,
            5.701666666666668,
            5.144999999999996,
            5.138333333333335,
            4.336666666666673,
            4.368333333333339,
            3.953333333333333,
            3.9083333333333314,
            3.8900000000000006,
            3.3633333333333297,
            3.078333333333333,
            3.078333333333333,
            3.469999999999999,
            3.058333333333337,
            3.5849999999999937,
            3.0916666666666686,
            2.798333333333332,
            2.5900000000000034,
            2.6650000000000063,
            1.7800000000000011,
            1.5250000000000057,
            1.7450000000000045,
            1.2633333333333354,
            1.2099999999999937,
            1.096666666666664,
            0.9666666666666686,
            0.9683333333333337,
            0.9266666666666623,
            0.806666666666672,
            0.7283333333333388,
            0.806666666666672,
            0.7199999999999989,
            0.7233333333333292,
            0.7249999999999943,
            0.61666666666666,
            0.5816666666666634,
            0.556666666666672,
            0.4749999999999943,
            0.3516666666666737,
            0.28666666666666174,
            0.3016666666666623,
            0.24833333333333485,
            0.23666666666666458,
            0.25,
            0.23333333333333428,
            0.20000000000000284,
            0.20999999999999375,
            0.2466666666666697,
            0.19499999999999318,
            0.18999999999999773,
            0.19166666666666288,
            0.18666666666666742,
            0.19499999999999318,
            0.18000000000000682,
            0.20999999999999375,
            0.14333333333333087,
            0.12666666666666515,
            0.12999999999999545,
            0.09666666666666401,
            0.10833333333333428,
            0.12999999999999545,
            0.09666666666666401,
            0.08833333333333826,
            0.10333333333333883,
            0.09666666666666401,
            0.1216666666666697,
            0.08499999999999375,
            0.08833333333333826,
            0.0799999999999983,
            0.09166666666666856,
            0.07833333333333314,
            0.0799999999999983,
            0.09333333333333371,
            0.10166666666667368
        ],
        "train_loss": [
            2.3033766393025714,
            0.38434186754028005,
            0.34285714713136356,
            0.31061700519919394,
            0.32329955716530484,
            0.31383002121249837,
            0.2783282485703627,
            0.3018868283689022,
            0.2517371018876632,
            0.24239553644955159,
            0.23921901487608752,
            0.24297721670170624,
            0.23730064946711063,
            0.22395081300089756,
            0.22805771416525045,
            0.2178328084588051,
            0.2086498240441084,
            0.21288743267108998,
            0.23409225310832263,
            0.15091553954308232,
            0.1363175899428005,
            0.13677132032314937,
            0.11717838504997392,
            0.11581640388065328,
            0.10492082524007808,
            0.10386552002988755,
            0.10518361583215495,
            0.09100751689105915,
            0.08344104258952041,
            0.08336403634709616,
            0.09309743932311734,
            0.08231785019248103,
            0.09464827878922225,
            0.08226852288177858,
            0.07335405270609384,
            0.06984490713900887,
            0.07145284144935819,
            0.050454855126988454,
            0.04540652237782876,
            0.04607210353813134,
            0.03649715090359484,
            0.034108376578458895,
            0.03195824408618112,
            0.02838709573689848,
            0.02724839883154879,
            0.028084023134284264,
            0.0240147281042339,
            0.022586620219703764,
            0.02290213775944879,
            0.02277803284211089,
            0.02122667834784564,
            0.021595478316867714,
            0.018784253377465452,
            0.01826872127505485,
            0.01690009016796054,
            0.015584620397201798,
            0.01301088613222843,
            0.011353616856000736,
            0.011184214783540423,
            0.010354441619737675,
            0.009629806699502903,
            0.009251886586663023,
            0.008818817181944421,
            0.008691616749053598,
            0.008495138762640757,
            0.009333101696282393,
            0.007928406684573383,
            0.007721071274657516,
            0.0076429829186912684,
            0.007336693932007044,
            0.007660008588704629,
            0.007484832478634174,
            0.007498156612977346,
            0.007027281138429377,
            0.006268648040448655,
            0.006236044179072875,
            0.005644630708668955,
            0.00556763036307475,
            0.0056448745509918696,
            0.005179875327141356,
            0.005521153175317765,
            0.005144094597517142,
            0.005446112693063757,
            0.005540181091089168,
            0.004827298348470474,
            0.0050441108207021895,
            0.004896032748757716,
            0.005063573107416354,
            0.004750967236587045,
            0.004804001503849213,
            0.004969305767764005,
            0.005177718219994494
        ],
        "train_acc": [
            11.28,
            86.14166666666667,
            87.21166666666667,
            88.60833333333333,
            87.68333333333334,
            88.01333333333334,
            89.655,
            88.80833333333334,
            90.61666666666666,
            91.00166666666667,
            91.13,
            90.86666666666666,
            91.40166666666667,
            91.56666666666666,
            91.46333333333334,
            91.83833333333334,
            92.17833333333333,
            91.98,
            91.70166666666667,
            94.29833333333333,
            94.855,
            94.86166666666666,
            95.66333333333333,
            95.63166666666666,
            96.04666666666667,
            96.09166666666667,
            96.11,
            96.63666666666667,
            96.92166666666667,
            96.92166666666667,
            96.53,
            96.94166666666666,
            96.415,
            96.90833333333333,
            97.20166666666667,
            97.41,
            97.335,
            98.22,
            98.475,
            98.255,
            98.73666666666666,
            98.79,
            98.90333333333334,
            99.03333333333333,
            99.03166666666667,
            99.07333333333334,
            99.19333333333333,
            99.27166666666666,
            99.19333333333333,
            99.28,
            99.27666666666667,
            99.275,
            99.38333333333334,
            99.41833333333334,
            99.44333333333333,
            99.525,
            99.64833333333333,
            99.71333333333334,
            99.69833333333334,
            99.75166666666667,
            99.76333333333334,
            99.75,
            99.76666666666667,
            99.8,
            99.79,
            99.75333333333333,
            99.805,
            99.81,
            99.80833333333334,
            99.81333333333333,
            99.805,
            99.82,
            99.79,
            99.85666666666667,
            99.87333333333333,
            99.87,
            99.90333333333334,
            99.89166666666667,
            99.87,
            99.90333333333334,
            99.91166666666666,
            99.89666666666666,
            99.90333333333334,
            99.87833333333333,
            99.915,
            99.91166666666666,
            99.92,
            99.90833333333333,
            99.92166666666667,
            99.92,
            99.90666666666667,
            99.89833333333333
        ],
        "best_test_acc": 91.42,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            3.548159122467041,
            3.465839385986328,
            3.484070062637329,
            3.4850215911865234,
            3.482168436050415,
            3.479182720184326,
            3.4935591220855713,
            3.430138111114502,
            3.4074113368988037,
            3.3490865230560303,
            3.3580453395843506,
            3.350289821624756,
            3.3301210403442383,
            3.350729465484619,
            3.3680288791656494,
            3.357604742050171,
            3.4322521686553955,
            3.3673717975616455,
            3.3420796394348145,
            3.361811399459839,
            3.3563802242279053,
            3.3525519371032715,
            3.364746332168579,
            3.3246450424194336,
            3.449864149093628,
            3.406092405319214,
            3.339555025100708,
            3.378798007965088,
            3.38913893699646,
            3.3210883140563965,
            3.336510419845581,
            3.3310317993164062,
            3.3483195304870605,
            3.3318119049072266,
            3.3995554447174072,
            3.3041915893554688,
            3.3367228507995605,
            3.3434221744537354,
            3.4243483543395996,
            3.4447474479675293,
            3.321383476257324,
            3.3514750003814697,
            3.3102943897247314,
            3.328902244567871,
            3.3290700912475586,
            3.324669122695923,
            3.3711676597595215,
            3.3410661220550537,
            3.3398478031158447,
            3.3252811431884766
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 168.86964964866638,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 93750,
        "num_opt_steps": 93750,
        "num_grad_steps": 93749
    }
]