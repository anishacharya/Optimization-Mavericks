[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 512,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 64,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.8,
                        "lr0": 0.04,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            82.1,
            18.799999999999997,
            15.060000000000002,
            12.930000000000007,
            12.730000000000004,
            11.840000000000003,
            11.340000000000003,
            10.650000000000006,
            10.680000000000007,
            10.370000000000005,
            9.989999999999995,
            10.200000000000003,
            10.180000000000007,
            10.090000000000003,
            9.5,
            9.39,
            8.819999999999993,
            9.060000000000002,
            9.170000000000002,
            8.489999999999995,
            8.61,
            8.579999999999998,
            8.620000000000005,
            8.340000000000003,
            8.579999999999998,
            8.209999999999994,
            8.629999999999995,
            8.260000000000005,
            8.409999999999997,
            8.409999999999997,
            8.319999999999993,
            9.010000000000005,
            8.430000000000007,
            8.170000000000002,
            8.61,
            8.420000000000002,
            8.540000000000006,
            8.280000000000001,
            8.159999999999997,
            8.040000000000006,
            7.980000000000004,
            8.209999999999994,
            8.39,
            8.069999999999993,
            8.170000000000002,
            8.25,
            8.060000000000002,
            8.280000000000001,
            8.269999999999996,
            7.989999999999995,
            7.959999999999994,
            7.969999999999999,
            8.340000000000003,
            7.890000000000001,
            8.200000000000003,
            8.069999999999993,
            8.040000000000006,
            8.049999999999997,
            7.890000000000001,
            7.900000000000006,
            7.969999999999999,
            7.950000000000003,
            7.930000000000007,
            7.829999999999998,
            7.939999999999998,
            7.890000000000001,
            7.930000000000007,
            7.760000000000005,
            7.819999999999993,
            7.700000000000003,
            8.099999999999994,
            7.849999999999994,
            8.069999999999993,
            7.75,
            7.840000000000003,
            7.900000000000006,
            7.8799999999999955,
            7.840000000000003,
            8.0,
            7.819999999999993,
            7.769999999999996,
            8.090000000000003,
            7.680000000000007,
            8.010000000000005,
            7.739999999999995,
            8.079999999999998,
            7.700000000000003,
            8.090000000000003,
            7.900000000000006,
            7.769999999999996,
            7.890000000000001,
            7.680000000000007,
            7.799999999999997
        ],
        "test_loss": [],
        "test_acc": [
            17.9,
            81.2,
            84.94,
            87.07,
            87.27,
            88.16,
            88.66,
            89.35,
            89.32,
            89.63,
            90.01,
            89.8,
            89.82,
            89.91,
            90.5,
            90.61,
            91.18,
            90.94,
            90.83,
            91.51,
            91.39,
            91.42,
            91.38,
            91.66,
            91.42,
            91.79,
            91.37,
            91.74,
            91.59,
            91.59,
            91.68,
            90.99,
            91.57,
            91.83,
            91.39,
            91.58,
            91.46,
            91.72,
            91.84,
            91.96,
            92.02,
            91.79,
            91.61,
            91.93,
            91.83,
            91.75,
            91.94,
            91.72,
            91.73,
            92.01,
            92.04,
            92.03,
            91.66,
            92.11,
            91.8,
            91.93,
            91.96,
            91.95,
            92.11,
            92.1,
            92.03,
            92.05,
            92.07,
            92.17,
            92.06,
            92.11,
            92.07,
            92.24,
            92.18,
            92.3,
            91.9,
            92.15,
            91.93,
            92.25,
            92.16,
            92.1,
            92.12,
            92.16,
            92.0,
            92.18,
            92.23,
            91.91,
            92.32,
            91.99,
            92.26,
            91.92,
            92.3,
            91.91,
            92.1,
            92.23,
            92.11,
            92.32,
            92.2
        ],
        "train_error": [
            82.19333333333333,
            18.263333333333335,
            14.230000000000004,
            12.058333333333337,
            11.338333333333338,
            10.706666666666663,
            9.730000000000004,
            9.27666666666667,
            8.833333333333329,
            8.411666666666662,
            8.15166666666667,
            7.923333333333332,
            7.73833333333333,
            7.471666666666664,
            7.036666666666662,
            6.769999999999996,
            6.310000000000002,
            5.968333333333334,
            5.978333333333339,
            5.420000000000002,
            5.333333333333329,
            4.961666666666673,
            5.00333333333333,
            4.728333333333339,
            4.74666666666667,
            4.459999999999994,
            4.685000000000002,
            4.228333333333339,
            4.068333333333328,
            4.103333333333339,
            3.921666666666667,
            4.375,
            3.5799999999999983,
            3.596666666666664,
            3.7249999999999943,
            3.3599999999999994,
            3.61666666666666,
            3.2816666666666663,
            2.969999999999999,
            2.674999999999997,
            2.780000000000001,
            2.6016666666666737,
            2.519999999999996,
            2.451666666666668,
            2.4866666666666646,
            2.3700000000000045,
            2.193333333333328,
            2.2249999999999943,
            2.3316666666666634,
            2.3883333333333354,
            2.230000000000004,
            2.00833333333334,
            1.9883333333333297,
            2.028333333333336,
            2.068333333333328,
            1.8716666666666697,
            1.8299999999999983,
            1.6483333333333263,
            1.6133333333333297,
            1.6550000000000011,
            1.5633333333333326,
            1.701666666666668,
            1.5100000000000051,
            1.5900000000000034,
            1.5049999999999955,
            1.431666666666672,
            1.3766666666666652,
            1.3799999999999955,
            1.4016666666666708,
            1.3333333333333286,
            1.3283333333333331,
            1.4016666666666708,
            1.4350000000000023,
            1.3649999999999949,
            1.288333333333327,
            1.1800000000000068,
            1.2199999999999989,
            1.2133333333333383,
            1.1766666666666623,
            1.1650000000000063,
            1.1916666666666629,
            1.144999999999996,
            1.1149999999999949,
            1.1366666666666703,
            1.1566666666666663,
            1.1149999999999949,
            1.1200000000000045,
            1.0400000000000063,
            1.0750000000000028,
            1.0633333333333326,
            1.0300000000000011,
            1.038333333333327,
            1.0333333333333314
        ],
        "train_loss": [
            2.2747141223842813,
            0.48757106116262533,
            0.3897848025722019,
            0.3305811611777645,
            0.31322381354994694,
            0.2933208215034614,
            0.26851952227495485,
            0.2559793587710898,
            0.2422147792274669,
            0.22913054528377824,
            0.22443680073750222,
            0.21565003592078968,
            0.2110489812695374,
            0.20565821344064453,
            0.19174611315888873,
            0.1865539957406157,
            0.17298240864933548,
            0.168550077004958,
            0.16510918622804902,
            0.15043159889972815,
            0.14566187270111958,
            0.13810477405786514,
            0.13842353136357616,
            0.12962499450323944,
            0.1303307472775548,
            0.12166297903000298,
            0.12552489876999692,
            0.11684793454863257,
            0.11229475341358428,
            0.11342791922516741,
            0.10741757203714322,
            0.11658193316247503,
            0.10191462997157695,
            0.09967692328964249,
            0.10255474205744469,
            0.09553504842570272,
            0.09935655880530002,
            0.09117857508866464,
            0.08312044229547856,
            0.07786567089289932,
            0.07913738246060024,
            0.07430694804732073,
            0.07313556580851643,
            0.07142556348215726,
            0.07166880059797885,
            0.06853028771988416,
            0.06697326709153288,
            0.06631758859602072,
            0.0671940483468569,
            0.0678812764206175,
            0.06400043514194124,
            0.06131490291554039,
            0.06063018653983787,
            0.05926494265638166,
            0.06156402087565196,
            0.05590160127918599,
            0.05431224317368814,
            0.05152915096131422,
            0.05049786239988723,
            0.05054015453147181,
            0.04963339082265304,
            0.050844964034602806,
            0.04785459537564193,
            0.04795711083432375,
            0.04699520904065694,
            0.046435325201285085,
            0.04524448543976424,
            0.04460849466149585,
            0.04527162613694446,
            0.043921126052737236,
            0.04423075391895185,
            0.04424737182335328,
            0.04461941648653503,
            0.04244806686163706,
            0.04164606680051755,
            0.03934740464566117,
            0.04038748370830791,
            0.03929455319451074,
            0.03890642574277975,
            0.03897438948121616,
            0.03880027378514662,
            0.03828554437890396,
            0.037115733028721,
            0.03801126356662835,
            0.0382228002772998,
            0.03730975757589785,
            0.037626179124591715,
            0.037045467455508345,
            0.03641387776045476,
            0.03636742189084574,
            0.03612214017470004,
            0.035747611484790255,
            0.035861628287929596
        ],
        "train_acc": [
            17.80666666666667,
            81.73666666666666,
            85.77,
            87.94166666666666,
            88.66166666666666,
            89.29333333333334,
            90.27,
            90.72333333333333,
            91.16666666666667,
            91.58833333333334,
            91.84833333333333,
            92.07666666666667,
            92.26166666666667,
            92.52833333333334,
            92.96333333333334,
            93.23,
            93.69,
            94.03166666666667,
            94.02166666666666,
            94.58,
            94.66666666666667,
            95.03833333333333,
            94.99666666666667,
            95.27166666666666,
            95.25333333333333,
            95.54,
            95.315,
            95.77166666666666,
            95.93166666666667,
            95.89666666666666,
            96.07833333333333,
            95.625,
            96.42,
            96.40333333333334,
            96.275,
            96.64,
            96.38333333333334,
            96.71833333333333,
            97.03,
            97.325,
            97.22,
            97.39833333333333,
            97.48,
            97.54833333333333,
            97.51333333333334,
            97.63,
            97.80666666666667,
            97.775,
            97.66833333333334,
            97.61166666666666,
            97.77,
            97.99166666666666,
            98.01166666666667,
            97.97166666666666,
            97.93166666666667,
            98.12833333333333,
            98.17,
            98.35166666666667,
            98.38666666666667,
            98.345,
            98.43666666666667,
            98.29833333333333,
            98.49,
            98.41,
            98.495,
            98.56833333333333,
            98.62333333333333,
            98.62,
            98.59833333333333,
            98.66666666666667,
            98.67166666666667,
            98.59833333333333,
            98.565,
            98.635,
            98.71166666666667,
            98.82,
            98.78,
            98.78666666666666,
            98.82333333333334,
            98.835,
            98.80833333333334,
            98.855,
            98.885,
            98.86333333333333,
            98.84333333333333,
            98.885,
            98.88,
            98.96,
            98.925,
            98.93666666666667,
            98.97,
            98.96166666666667,
            98.96666666666667
        ],
        "best_test_acc": 92.32,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.359511137008667,
            0.35503578186035156,
            0.34003281593322754,
            0.35977697372436523,
            0.36076951026916504,
            0.3150613307952881,
            0.3140065670013428,
            0.325061559677124,
            0.31886744499206543,
            0.32038140296936035,
            0.3393979072570801,
            0.3334503173828125,
            0.35068702697753906,
            0.3382439613342285,
            0.3579840660095215,
            0.3257155418395996,
            0.3434760570526123,
            0.32535243034362793,
            0.31201958656311035,
            0.34178972244262695,
            0.3534834384918213,
            0.3322010040283203,
            0.3404216766357422,
            0.33815908432006836,
            0.3530099391937256,
            0.3400115966796875,
            0.36490941047668457,
            0.34105682373046875,
            0.31871819496154785,
            0.32463502883911133,
            0.32479071617126465,
            0.30077147483825684,
            0.3233497142791748,
            0.3343315124511719,
            0.3057680130004883,
            0.30397748947143555,
            0.30775022506713867,
            0.35001158714294434,
            0.3330228328704834,
            0.37214231491088867,
            0.3486924171447754,
            0.33930516242980957,
            0.3087344169616699,
            0.36258435249328613,
            0.3257575035095215,
            0.37130260467529297,
            0.3689305782318115,
            0.35933804512023926,
            0.329495906829834,
            0.32123231887817383
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 16.834516525268555,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 5900,
        "num_opt_steps": 5900,
        "num_grad_steps": 5899
    }
]