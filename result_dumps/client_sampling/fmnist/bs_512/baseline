[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 512,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 64,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": null,
                        "initial_loss_sampling_fraction": 0.7,
                        "lr0": 0.04,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            82.38,
            20.840000000000003,
            15.89,
            13.670000000000002,
            12.700000000000003,
            12.170000000000002,
            11.829999999999998,
            11.049999999999997,
            10.989999999999995,
            10.230000000000004,
            10.14,
            10.260000000000005,
            10.079999999999998,
            10.189999999999998,
            10.049999999999997,
            9.980000000000004,
            9.200000000000003,
            9.61,
            9.439999999999998,
            8.89,
            8.680000000000007,
            8.739999999999995,
            8.950000000000003,
            8.569999999999993,
            8.959999999999994,
            8.900000000000006,
            8.510000000000005,
            8.75,
            8.659999999999997,
            8.629999999999995,
            8.510000000000005,
            8.64,
            8.939999999999998,
            8.439999999999998,
            8.590000000000003,
            8.400000000000006,
            8.450000000000003,
            8.590000000000003,
            8.569999999999993,
            8.079999999999998,
            8.409999999999997,
            8.450000000000003,
            8.469999999999999,
            8.280000000000001,
            8.280000000000001,
            8.409999999999997,
            8.150000000000006,
            8.459999999999994,
            8.480000000000004,
            7.8700000000000045,
            8.560000000000002,
            8.180000000000007,
            8.280000000000001,
            8.469999999999999,
            8.170000000000002,
            8.36,
            8.379999999999995,
            8.170000000000002,
            8.310000000000002,
            8.25,
            8.25,
            8.170000000000002,
            8.319999999999993,
            8.180000000000007,
            8.329999999999998,
            8.299999999999997,
            8.120000000000005,
            8.209999999999994,
            8.189999999999998,
            8.219999999999999,
            8.14,
            8.099999999999994,
            8.310000000000002,
            8.049999999999997,
            8.209999999999994,
            8.25,
            8.310000000000002,
            8.189999999999998,
            8.14,
            8.14,
            8.11,
            8.040000000000006,
            8.170000000000002,
            8.11,
            8.090000000000003,
            7.939999999999998,
            8.129999999999995,
            8.040000000000006,
            8.129999999999995,
            8.099999999999994,
            8.329999999999998,
            8.099999999999994,
            8.209999999999994
        ],
        "test_loss": [],
        "test_acc": [
            17.62,
            79.16,
            84.11,
            86.33,
            87.3,
            87.83,
            88.17,
            88.95,
            89.01,
            89.77,
            89.86,
            89.74,
            89.92,
            89.81,
            89.95,
            90.02,
            90.8,
            90.39,
            90.56,
            91.11,
            91.32,
            91.26,
            91.05,
            91.43,
            91.04,
            91.1,
            91.49,
            91.25,
            91.34,
            91.37,
            91.49,
            91.36,
            91.06,
            91.56,
            91.41,
            91.6,
            91.55,
            91.41,
            91.43,
            91.92,
            91.59,
            91.55,
            91.53,
            91.72,
            91.72,
            91.59,
            91.85,
            91.54,
            91.52,
            92.13,
            91.44,
            91.82,
            91.72,
            91.53,
            91.83,
            91.64,
            91.62,
            91.83,
            91.69,
            91.75,
            91.75,
            91.83,
            91.68,
            91.82,
            91.67,
            91.7,
            91.88,
            91.79,
            91.81,
            91.78,
            91.86,
            91.9,
            91.69,
            91.95,
            91.79,
            91.75,
            91.69,
            91.81,
            91.86,
            91.86,
            91.89,
            91.96,
            91.83,
            91.89,
            91.91,
            92.06,
            91.87,
            91.96,
            91.87,
            91.9,
            91.67,
            91.9,
            91.79
        ],
        "train_error": [
            82.70166666666667,
            19.891666666666666,
            15.36,
            12.605000000000004,
            11.76833333333333,
            11.198333333333338,
            10.36833333333334,
            9.708333333333329,
            9.426666666666662,
            8.718333333333334,
            8.545000000000002,
            8.23166666666667,
            8.064999999999998,
            7.751666666666665,
            7.743333333333339,
            7.2933333333333366,
            6.801666666666662,
            6.646666666666661,
            6.606666666666669,
            5.920000000000002,
            5.756666666666661,
            5.4566666666666634,
            5.469999999999999,
            5.12166666666667,
            5.194999999999993,
            5.141666666666666,
            5.049999999999997,
            4.713333333333338,
            4.680000000000007,
            4.701666666666668,
            4.4950000000000045,
            4.9466666666666725,
            4.3033333333333275,
            4.276666666666671,
            4.318333333333328,
            4.00833333333334,
            4.084999999999994,
            3.7866666666666617,
            3.723333333333329,
            3.356666666666669,
            3.4583333333333286,
            3.4350000000000023,
            3.3349999999999937,
            3.2916666666666714,
            3.2533333333333303,
            3.1650000000000063,
            3.1099999999999994,
            2.9466666666666725,
            3.0,
            2.9683333333333337,
            2.913333333333327,
            2.9066666666666663,
            2.7750000000000057,
            2.7150000000000034,
            2.701666666666668,
            2.594999999999999,
            2.5833333333333286,
            2.3799999999999955,
            2.319999999999993,
            2.393333333333331,
            2.3816666666666606,
            2.4966666666666697,
            2.25833333333334,
            2.1683333333333366,
            2.223333333333329,
            2.239999999999995,
            2.2150000000000034,
            2.1766666666666623,
            2.1583333333333314,
            2.1883333333333326,
            2.0600000000000023,
            2.231666666666669,
            2.1316666666666606,
            2.0900000000000034,
            1.9833333333333343,
            1.9200000000000017,
            1.8983333333333263,
            1.9416666666666629,
            1.9066666666666663,
            1.8349999999999937,
            1.9283333333333275,
            1.9366666666666674,
            1.8533333333333388,
            1.8649999999999949,
            1.8516666666666737,
            1.8199999999999932,
            1.8349999999999937,
            1.7549999999999955,
            1.8599999999999994,
            1.798333333333332,
            1.7249999999999943,
            1.7849999999999966,
            1.7633333333333354
        ],
        "train_loss": [
            2.273405707488626,
            0.5163193393056675,
            0.4132762392193584,
            0.34693619533110476,
            0.32300335939152763,
            0.3065145384457152,
            0.283755441338329,
            0.2672802108829304,
            0.257421477618864,
            0.24017714380712832,
            0.23512233528545348,
            0.2249388799576436,
            0.22082853279376435,
            0.2144046715002949,
            0.21119000333345542,
            0.2031095610079119,
            0.18686843941272316,
            0.18461543902502223,
            0.18099317964860948,
            0.1651943979500714,
            0.15900476744114342,
            0.15295311499197603,
            0.15365713512745954,
            0.14566343176667973,
            0.14714511540734163,
            0.1415154643483081,
            0.13882945168573976,
            0.13249599737888676,
            0.13141813836360383,
            0.13022351921614955,
            0.12629084377470662,
            0.13447589768191515,
            0.12120780235124846,
            0.11927066781258179,
            0.11826421080504433,
            0.11379967251066435,
            0.11436186819258383,
            0.10777849435679994,
            0.1038556615427389,
            0.09758631844010393,
            0.09834093076445288,
            0.09620239061571784,
            0.09599709327695734,
            0.09505754627161107,
            0.09309535631436412,
            0.08998446728465921,
            0.0904975273977902,
            0.08627224978754076,
            0.08649843760718734,
            0.08594239702037836,
            0.08594796153069553,
            0.08319067778223652,
            0.08093708434726223,
            0.07907963338923657,
            0.07855983362612078,
            0.07678150262494209,
            0.07484669257271087,
            0.07158188386109926,
            0.07140055298805237,
            0.07139814518770929,
            0.07074154531425339,
            0.07121114568563841,
            0.06888617278408196,
            0.06676698150902481,
            0.06763550452888012,
            0.0678824317973044,
            0.06671618433448218,
            0.06526455980867653,
            0.06451258533713171,
            0.06599208115899967,
            0.06457150471791373,
            0.06532300798759116,
            0.06422504839503158,
            0.062281012692946496,
            0.061827980708015165,
            0.059960791209744194,
            0.05938901326035039,
            0.05944680747718124,
            0.05892461547785896,
            0.05818396955097126,
            0.05850718495578079,
            0.058697634581792155,
            0.057496463406389045,
            0.057898753875140416,
            0.057551834606013055,
            0.05624255891573631,
            0.05760986627853018,
            0.05582695967375727,
            0.05623363558266122,
            0.055259677218431134,
            0.0550008894307381,
            0.05593855072886257,
            0.05523535634501506
        ],
        "train_acc": [
            17.298333333333332,
            80.10833333333333,
            84.64,
            87.395,
            88.23166666666667,
            88.80166666666666,
            89.63166666666666,
            90.29166666666667,
            90.57333333333334,
            91.28166666666667,
            91.455,
            91.76833333333333,
            91.935,
            92.24833333333333,
            92.25666666666666,
            92.70666666666666,
            93.19833333333334,
            93.35333333333334,
            93.39333333333333,
            94.08,
            94.24333333333334,
            94.54333333333334,
            94.53,
            94.87833333333333,
            94.805,
            94.85833333333333,
            94.95,
            95.28666666666666,
            95.32,
            95.29833333333333,
            95.505,
            95.05333333333333,
            95.69666666666667,
            95.72333333333333,
            95.68166666666667,
            95.99166666666666,
            95.915,
            96.21333333333334,
            96.27666666666667,
            96.64333333333333,
            96.54166666666667,
            96.565,
            96.665,
            96.70833333333333,
            96.74666666666667,
            96.835,
            96.89,
            97.05333333333333,
            97.0,
            97.03166666666667,
            97.08666666666667,
            97.09333333333333,
            97.225,
            97.285,
            97.29833333333333,
            97.405,
            97.41666666666667,
            97.62,
            97.68,
            97.60666666666667,
            97.61833333333334,
            97.50333333333333,
            97.74166666666666,
            97.83166666666666,
            97.77666666666667,
            97.76,
            97.785,
            97.82333333333334,
            97.84166666666667,
            97.81166666666667,
            97.94,
            97.76833333333333,
            97.86833333333334,
            97.91,
            98.01666666666667,
            98.08,
            98.10166666666667,
            98.05833333333334,
            98.09333333333333,
            98.165,
            98.07166666666667,
            98.06333333333333,
            98.14666666666666,
            98.135,
            98.14833333333333,
            98.18,
            98.165,
            98.245,
            98.14,
            98.20166666666667,
            98.275,
            98.215,
            98.23666666666666
        ],
        "best_test_acc": 92.13,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.3191843032836914,
            0.2758760452270508,
            0.2938704490661621,
            0.31948113441467285,
            0.3483741283416748,
            0.30721235275268555,
            0.3076937198638916,
            0.30464649200439453,
            0.31046175956726074,
            0.30468273162841797,
            0.3090517520904541,
            0.31375551223754883,
            0.30413818359375,
            0.3148503303527832,
            0.3343191146850586,
            0.3282124996185303,
            0.32662463188171387,
            0.31582212448120117,
            0.3163621425628662,
            0.34964442253112793,
            0.31365442276000977,
            0.32841038703918457,
            0.3328835964202881,
            0.2858002185821533,
            0.31454014778137207,
            0.28383493423461914,
            0.3135037422180176,
            0.30953431129455566,
            0.3249051570892334,
            0.32672882080078125,
            0.2834300994873047,
            0.32050466537475586,
            0.3298060894012451,
            0.3266158103942871,
            0.3412306308746338,
            0.34262800216674805,
            0.3239278793334961,
            0.3102259635925293,
            0.32465600967407227,
            0.32605791091918945,
            0.3216085433959961,
            0.3040914535522461,
            0.3154478073120117,
            0.31740498542785645,
            0.29973888397216797,
            0.3236560821533203,
            0.33910131454467773,
            0.3278534412384033,
            0.3200969696044922,
            0.30747032165527344
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 15.843612432479858,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 5900,
        "num_opt_steps": 5900,
        "num_grad_steps": 5899
    }
]