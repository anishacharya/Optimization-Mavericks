[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 512,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 64,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.85,
                        "lr0": 0.04,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            81.33,
            19.28,
            15.280000000000001,
            13.36,
            12.650000000000006,
            11.659999999999997,
            11.340000000000003,
            10.920000000000002,
            10.989999999999995,
            10.329999999999998,
            9.89,
            10.079999999999998,
            10.040000000000006,
            10.120000000000005,
            9.409999999999997,
            9.540000000000006,
            8.989999999999995,
            9.219999999999999,
            9.14,
            8.689999999999998,
            8.379999999999995,
            8.560000000000002,
            8.61,
            8.290000000000006,
            8.489999999999995,
            8.370000000000005,
            8.530000000000001,
            8.379999999999995,
            8.540000000000006,
            8.39,
            8.430000000000007,
            8.510000000000005,
            8.670000000000002,
            8.319999999999993,
            8.459999999999994,
            8.299999999999997,
            8.480000000000004,
            8.510000000000005,
            8.25,
            7.989999999999995,
            8.200000000000003,
            8.530000000000001,
            8.219999999999999,
            8.200000000000003,
            8.060000000000002,
            8.230000000000004,
            8.260000000000005,
            8.150000000000006,
            8.079999999999998,
            8.079999999999998,
            8.280000000000001,
            7.980000000000004,
            8.099999999999994,
            7.930000000000007,
            8.25,
            8.019999999999996,
            8.030000000000001,
            8.040000000000006,
            8.010000000000005,
            8.019999999999996,
            8.040000000000006,
            7.969999999999999,
            8.159999999999997,
            7.930000000000007,
            7.950000000000003,
            8.079999999999998,
            8.090000000000003,
            7.930000000000007,
            8.269999999999996,
            7.959999999999994,
            8.11,
            8.230000000000004,
            7.950000000000003,
            7.890000000000001,
            8.170000000000002,
            7.780000000000001,
            7.909999999999997,
            8.090000000000003,
            7.969999999999999,
            7.8700000000000045,
            8.030000000000001,
            8.14,
            7.989999999999995,
            8.150000000000006,
            7.8799999999999955,
            7.950000000000003,
            8.239999999999995,
            8.14,
            8.010000000000005,
            7.859999999999999,
            8.200000000000003,
            7.969999999999999,
            8.180000000000007
        ],
        "test_loss": [],
        "test_acc": [
            18.67,
            80.72,
            84.72,
            86.64,
            87.35,
            88.34,
            88.66,
            89.08,
            89.01,
            89.67,
            90.11,
            89.92,
            89.96,
            89.88,
            90.59,
            90.46,
            91.01,
            90.78,
            90.86,
            91.31,
            91.62,
            91.44,
            91.39,
            91.71,
            91.51,
            91.63,
            91.47,
            91.62,
            91.46,
            91.61,
            91.57,
            91.49,
            91.33,
            91.68,
            91.54,
            91.7,
            91.52,
            91.49,
            91.75,
            92.01,
            91.8,
            91.47,
            91.78,
            91.8,
            91.94,
            91.77,
            91.74,
            91.85,
            91.92,
            91.92,
            91.72,
            92.02,
            91.9,
            92.07,
            91.75,
            91.98,
            91.97,
            91.96,
            91.99,
            91.98,
            91.96,
            92.03,
            91.84,
            92.07,
            92.05,
            91.92,
            91.91,
            92.07,
            91.73,
            92.04,
            91.89,
            91.77,
            92.05,
            92.11,
            91.83,
            92.22,
            92.09,
            91.91,
            92.03,
            92.13,
            91.97,
            91.86,
            92.01,
            91.85,
            92.12,
            92.05,
            91.76,
            91.86,
            91.99,
            92.14,
            91.8,
            92.03,
            91.82
        ],
        "train_error": [
            81.705,
            18.63333333333334,
            14.466666666666669,
            12.173333333333332,
            11.471666666666664,
            10.566666666666663,
            10.045000000000002,
            9.454999999999998,
            9.125,
            8.323333333333338,
            8.171666666666667,
            7.776666666666671,
            7.608333333333334,
            7.483333333333334,
            6.968333333333334,
            6.808333333333337,
            6.51166666666667,
            6.083333333333329,
            5.961666666666673,
            5.530000000000001,
            5.2933333333333366,
            4.861666666666665,
            4.974999999999994,
            4.698333333333338,
            4.693333333333328,
            4.510000000000005,
            4.716666666666669,
            4.308333333333337,
            4.234999999999999,
            4.224999999999994,
            3.848333333333329,
            4.1783333333333275,
            3.719999999999999,
            3.6700000000000017,
            3.6966666666666725,
            3.450000000000003,
            3.923333333333332,
            3.328333333333333,
            3.0349999999999966,
            2.7549999999999955,
            2.7249999999999943,
            2.771666666666661,
            2.6866666666666674,
            2.5649999999999977,
            2.568333333333328,
            2.4866666666666646,
            2.4666666666666686,
            2.3516666666666737,
            2.4166666666666714,
            2.5066666666666606,
            2.280000000000001,
            2.114999999999995,
            2.194999999999993,
            2.180000000000007,
            2.0733333333333377,
            2.1016666666666737,
            1.9583333333333286,
            1.8133333333333326,
            1.7466666666666697,
            1.7183333333333337,
            1.6766666666666623,
            1.8100000000000023,
            1.6599999999999966,
            1.6550000000000011,
            1.6400000000000006,
            1.6550000000000011,
            1.6116666666666646,
            1.5466666666666669,
            1.5983333333333292,
            1.4533333333333331,
            1.3983333333333263,
            1.5983333333333292,
            1.4849999999999994,
            1.3983333333333263,
            1.3866666666666703,
            1.2516666666666652,
            1.3400000000000034,
            1.3100000000000023,
            1.1899999999999977,
            1.2733333333333263,
            1.3316666666666634,
            1.3416666666666686,
            1.3250000000000028,
            1.2549999999999955,
            1.2266666666666737,
            1.2433333333333394,
            1.2233333333333292,
            1.2483333333333348,
            1.2650000000000006,
            1.2600000000000051,
            1.1883333333333326,
            1.211666666666673,
            1.2150000000000034
        ],
        "train_loss": [
            2.2743262820324657,
            0.4960644351223768,
            0.3923356677010908,
            0.3344261259850809,
            0.3148889532786305,
            0.28899347744250703,
            0.2752818638237856,
            0.25948941442420925,
            0.24906166188292583,
            0.22987408001544113,
            0.22407724064285472,
            0.21374680228152518,
            0.2082302623381049,
            0.2090842367733939,
            0.19329524254899913,
            0.188980683305506,
            0.17787357583894567,
            0.17103586914175647,
            0.1647054556820352,
            0.15297109115931948,
            0.14617401683482073,
            0.13888936502448582,
            0.13969641627144005,
            0.13193258662092483,
            0.13131595630261858,
            0.12482190675149529,
            0.12830256689655578,
            0.11853359143991592,
            0.11748105167584905,
            0.11575872943562976,
            0.10963470293051106,
            0.11345945601746188,
            0.10474952165100535,
            0.1014708423260915,
            0.10329987367583533,
            0.09867264614519426,
            0.10635921687392866,
            0.09386919413582753,
            0.08590416411348319,
            0.08104753159617974,
            0.07949021386014203,
            0.07925980001435441,
            0.07663876935839653,
            0.07485113744387183,
            0.07419790147598516,
            0.07293710308307308,
            0.07124153357314861,
            0.06913957429134239,
            0.070653836416491,
            0.07053816290098731,
            0.06699715586284459,
            0.06375058932955992,
            0.0637505040582964,
            0.06358998268842697,
            0.06217586031278311,
            0.06129213157346693,
            0.05783899785098383,
            0.0557544875448033,
            0.05409265811539302,
            0.05404533774165784,
            0.05305405791406914,
            0.05368986678451805,
            0.05136916529134673,
            0.05133417037205171,
            0.050651168766415726,
            0.05060410843688553,
            0.04964040042990345,
            0.049376324576846625,
            0.04948617439022509,
            0.04805025974509575,
            0.047089143198425484,
            0.04813361941379005,
            0.0478977946785547,
            0.04530803431456877,
            0.04518250323895175,
            0.04243998444181377,
            0.04343151541079505,
            0.04260109371300471,
            0.04154410105893167,
            0.042051707631198025,
            0.04263383480009891,
            0.04224643267501714,
            0.04155064055348857,
            0.04128613962270951,
            0.041418549715209814,
            0.0409361930816608,
            0.04113457817584276,
            0.040928178245864685,
            0.04063321774730743,
            0.04047063671810142,
            0.039002898007126176,
            0.040063682091185604,
            0.03973152753660234
        ],
        "train_acc": [
            18.295,
            81.36666666666666,
            85.53333333333333,
            87.82666666666667,
            88.52833333333334,
            89.43333333333334,
            89.955,
            90.545,
            90.875,
            91.67666666666666,
            91.82833333333333,
            92.22333333333333,
            92.39166666666667,
            92.51666666666667,
            93.03166666666667,
            93.19166666666666,
            93.48833333333333,
            93.91666666666667,
            94.03833333333333,
            94.47,
            94.70666666666666,
            95.13833333333334,
            95.025,
            95.30166666666666,
            95.30666666666667,
            95.49,
            95.28333333333333,
            95.69166666666666,
            95.765,
            95.775,
            96.15166666666667,
            95.82166666666667,
            96.28,
            96.33,
            96.30333333333333,
            96.55,
            96.07666666666667,
            96.67166666666667,
            96.965,
            97.245,
            97.275,
            97.22833333333334,
            97.31333333333333,
            97.435,
            97.43166666666667,
            97.51333333333334,
            97.53333333333333,
            97.64833333333333,
            97.58333333333333,
            97.49333333333334,
            97.72,
            97.885,
            97.805,
            97.82,
            97.92666666666666,
            97.89833333333333,
            98.04166666666667,
            98.18666666666667,
            98.25333333333333,
            98.28166666666667,
            98.32333333333334,
            98.19,
            98.34,
            98.345,
            98.36,
            98.345,
            98.38833333333334,
            98.45333333333333,
            98.40166666666667,
            98.54666666666667,
            98.60166666666667,
            98.40166666666667,
            98.515,
            98.60166666666667,
            98.61333333333333,
            98.74833333333333,
            98.66,
            98.69,
            98.81,
            98.72666666666667,
            98.66833333333334,
            98.65833333333333,
            98.675,
            98.745,
            98.77333333333333,
            98.75666666666666,
            98.77666666666667,
            98.75166666666667,
            98.735,
            98.74,
            98.81166666666667,
            98.78833333333333,
            98.785
        ],
        "best_test_acc": 92.22,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.31211090087890625,
            0.3587503433227539,
            0.324462890625,
            0.3456544876098633,
            0.3512380123138428,
            0.33975887298583984,
            0.30842089653015137,
            0.3327960968017578,
            0.3440730571746826,
            0.3274507522583008,
            0.2888908386230469,
            0.29847097396850586,
            0.31217122077941895,
            0.3133277893066406,
            0.32489442825317383,
            0.31801509857177734,
            0.3555793762207031,
            0.36716222763061523,
            0.35133886337280273,
            0.3385500907897949,
            0.3474700450897217,
            0.34304165840148926,
            0.33502745628356934,
            0.32637739181518555,
            0.3197658061981201,
            0.32326626777648926,
            0.3063673973083496,
            0.3101613521575928,
            0.2890605926513672,
            0.3284592628479004,
            0.30950307846069336,
            0.3013722896575928,
            0.2939753532409668,
            0.3323206901550293,
            0.30382442474365234,
            0.30010390281677246,
            0.2706277370452881,
            0.30518341064453125,
            0.3157966136932373,
            0.3257606029510498,
            0.3198573589324951,
            0.30274105072021484,
            0.31118130683898926,
            0.30863213539123535,
            0.3194763660430908,
            0.2936592102050781,
            0.30394625663757324,
            0.32758259773254395,
            0.3258059024810791,
            0.3077690601348877
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 16.021233797073364,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 5900,
        "num_opt_steps": 5900,
        "num_grad_steps": 5899
    }
]