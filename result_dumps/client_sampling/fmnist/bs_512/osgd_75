[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 512,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 64,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.75,
                        "lr0": 0.04,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            81.13,
            18.78,
            15.019999999999996,
            13.219999999999999,
            12.530000000000001,
            11.5,
            11.180000000000007,
            10.709999999999994,
            10.61,
            10.25,
            9.719999999999999,
            9.909999999999997,
            9.560000000000002,
            9.599999999999994,
            9.700000000000003,
            9.200000000000003,
            8.909999999999997,
            9.230000000000004,
            9.0,
            8.900000000000006,
            8.39,
            8.439999999999998,
            8.689999999999998,
            8.159999999999997,
            8.560000000000002,
            8.430000000000007,
            8.590000000000003,
            8.280000000000001,
            8.519999999999996,
            8.299999999999997,
            8.459999999999994,
            8.799999999999997,
            8.329999999999998,
            8.11,
            8.799999999999997,
            8.25,
            8.599999999999994,
            7.890000000000001,
            8.069999999999993,
            7.969999999999999,
            7.989999999999995,
            8.180000000000007,
            8.290000000000006,
            8.180000000000007,
            8.060000000000002,
            8.170000000000002,
            8.209999999999994,
            8.439999999999998,
            8.060000000000002,
            7.959999999999994,
            8.090000000000003,
            7.799999999999997,
            7.739999999999995,
            8.209999999999994,
            8.060000000000002,
            8.219999999999999,
            7.959999999999994,
            8.010000000000005,
            7.829999999999998,
            7.680000000000007,
            7.989999999999995,
            7.840000000000003,
            7.840000000000003,
            7.739999999999995,
            7.8799999999999955,
            7.950000000000003,
            7.730000000000004,
            7.900000000000006,
            7.969999999999999,
            7.650000000000006,
            8.129999999999995,
            7.939999999999998,
            7.920000000000002,
            7.739999999999995,
            7.819999999999993,
            7.780000000000001,
            7.909999999999997,
            8.0,
            7.650000000000006,
            7.760000000000005,
            7.689999999999998,
            7.920000000000002,
            7.950000000000003,
            8.099999999999994,
            7.689999999999998,
            7.859999999999999,
            7.769999999999996,
            7.670000000000002,
            7.849999999999994,
            7.790000000000006,
            7.739999999999995,
            7.719999999999999,
            7.819999999999993
        ],
        "test_loss": [],
        "test_acc": [
            18.87,
            81.22,
            84.98,
            86.78,
            87.47,
            88.5,
            88.82,
            89.29,
            89.39,
            89.75,
            90.28,
            90.09,
            90.44,
            90.4,
            90.3,
            90.8,
            91.09,
            90.77,
            91.0,
            91.1,
            91.61,
            91.56,
            91.31,
            91.84,
            91.44,
            91.57,
            91.41,
            91.72,
            91.48,
            91.7,
            91.54,
            91.2,
            91.67,
            91.89,
            91.2,
            91.75,
            91.4,
            92.11,
            91.93,
            92.03,
            92.01,
            91.82,
            91.71,
            91.82,
            91.94,
            91.83,
            91.79,
            91.56,
            91.94,
            92.04,
            91.91,
            92.2,
            92.26,
            91.79,
            91.94,
            91.78,
            92.04,
            91.99,
            92.17,
            92.32,
            92.01,
            92.16,
            92.16,
            92.26,
            92.12,
            92.05,
            92.27,
            92.1,
            92.03,
            92.35,
            91.87,
            92.06,
            92.08,
            92.26,
            92.18,
            92.22,
            92.09,
            92.0,
            92.35,
            92.24,
            92.31,
            92.08,
            92.05,
            91.9,
            92.31,
            92.14,
            92.23,
            92.33,
            92.15,
            92.21,
            92.26,
            92.28,
            92.18
        ],
        "train_error": [
            81.41833333333334,
            17.983333333333334,
            14.13333333333334,
            12.084999999999994,
            11.186666666666667,
            10.310000000000002,
            9.588333333333338,
            9.111666666666665,
            8.671666666666667,
            8.200000000000003,
            8.013333333333335,
            7.531666666666666,
            7.435000000000002,
            7.109999999999999,
            6.906666666666666,
            6.599999999999994,
            6.36666666666666,
            5.941666666666663,
            5.756666666666661,
            5.180000000000007,
            5.055000000000007,
            4.698333333333338,
            4.689999999999998,
            4.338333333333338,
            4.519999999999996,
            4.166666666666671,
            4.319999999999993,
            3.924999999999997,
            3.943333333333328,
            3.8716666666666697,
            3.5333333333333314,
            3.8816666666666606,
            3.413333333333327,
            3.2933333333333366,
            3.394999999999996,
            3.2099999999999937,
            3.728333333333339,
            2.8033333333333275,
            2.635000000000005,
            2.4166666666666714,
            2.4399999999999977,
            2.518333333333331,
            2.2333333333333343,
            2.3316666666666634,
            2.174999999999997,
            2.1666666666666714,
            2.058333333333337,
            1.9066666666666663,
            2.125,
            2.0600000000000023,
            1.9083333333333314,
            1.8166666666666629,
            1.7133333333333383,
            1.806666666666672,
            1.7866666666666617,
            1.6599999999999966,
            1.5466666666666669,
            1.4000000000000057,
            1.4116666666666617,
            1.3133333333333326,
            1.3316666666666634,
            1.4399999999999977,
            1.2833333333333314,
            1.3433333333333337,
            1.2900000000000063,
            1.2549999999999955,
            1.1883333333333326,
            1.1749999999999972,
            1.1966666666666725,
            1.1949999999999932,
            1.1433333333333309,
            1.1850000000000023,
            1.1200000000000045,
            1.0716666666666725,
            0.9533333333333331,
            1.0300000000000011,
            1.0150000000000006,
            0.9899999999999949,
            0.923333333333332,
            0.9533333333333331,
            0.9950000000000045,
            0.9399999999999977,
            0.9466666666666725,
            0.9449999999999932,
            1.0049999999999955,
            0.9016666666666708,
            0.9083333333333314,
            0.8566666666666691,
            0.9216666666666669,
            0.8916666666666657,
            0.8199999999999932,
            0.8400000000000034,
            0.8883333333333354
        ],
        "train_loss": [
            2.2755307726940868,
            0.4837283095565893,
            0.38418366848412205,
            0.3301217611563408,
            0.307749699359223,
            0.2838712099750163,
            0.26440749165870375,
            0.24868284645727126,
            0.23701379372406814,
            0.2244114361829677,
            0.21848491617178512,
            0.20860907801632153,
            0.2033375247807826,
            0.19598039062851566,
            0.19009889460216134,
            0.18053258513495074,
            0.17223875243532455,
            0.1643932510988187,
            0.15794689050417834,
            0.14371586445782145,
            0.13837952217308142,
            0.13259077198424582,
            0.12924429073424662,
            0.12131065862663722,
            0.12282808844820928,
            0.11520679433972149,
            0.11818340414408911,
            0.11040791585031202,
            0.1081362097697743,
            0.10641822218894958,
            0.09968305732739174,
            0.1056324270695953,
            0.09521492302291475,
            0.09234157495074354,
            0.09473283374208515,
            0.0904368680223065,
            0.10031958795705084,
            0.07958760024127313,
            0.07523793761886782,
            0.07017915916897483,
            0.07078626906593978,
            0.06870913451884762,
            0.06522672118271812,
            0.06640196787351269,
            0.06292414747304835,
            0.06286592367973368,
            0.062467808156447896,
            0.0587096134421684,
            0.061458651071130216,
            0.060029839465426185,
            0.05633680348805452,
            0.05415019036223322,
            0.05322468020337618,
            0.053563177680312574,
            0.05351588941352852,
            0.05016208392709999,
            0.04813133491108478,
            0.044920041288991096,
            0.04443024717650171,
            0.04350648886697777,
            0.042639260338145794,
            0.04414636756972236,
            0.041105192375637714,
            0.04233607591398186,
            0.04045666700576322,
            0.040483710640189,
            0.03940881717697543,
            0.03862459515616045,
            0.0390420616999016,
            0.03872925928651781,
            0.03874799710209087,
            0.03779816111328743,
            0.036485825333807426,
            0.03667167702026791,
            0.03498982682319011,
            0.034278459768047775,
            0.033820197459752274,
            0.033904345406187794,
            0.03239313642478595,
            0.032766243853306364,
            0.03338383799576658,
            0.0326166929582418,
            0.032653858758888,
            0.03251788523679568,
            0.03347876439092018,
            0.031789972794131705,
            0.032555352620212204,
            0.03110392126491514,
            0.031127575911202673,
            0.0312481503302263,
            0.03002586184164225,
            0.029909315171762037,
            0.030506763433627154
        ],
        "train_acc": [
            18.581666666666667,
            82.01666666666667,
            85.86666666666666,
            87.915,
            88.81333333333333,
            89.69,
            90.41166666666666,
            90.88833333333334,
            91.32833333333333,
            91.8,
            91.98666666666666,
            92.46833333333333,
            92.565,
            92.89,
            93.09333333333333,
            93.4,
            93.63333333333334,
            94.05833333333334,
            94.24333333333334,
            94.82,
            94.945,
            95.30166666666666,
            95.31,
            95.66166666666666,
            95.48,
            95.83333333333333,
            95.68,
            96.075,
            96.05666666666667,
            96.12833333333333,
            96.46666666666667,
            96.11833333333334,
            96.58666666666667,
            96.70666666666666,
            96.605,
            96.79,
            96.27166666666666,
            97.19666666666667,
            97.365,
            97.58333333333333,
            97.56,
            97.48166666666667,
            97.76666666666667,
            97.66833333333334,
            97.825,
            97.83333333333333,
            97.94166666666666,
            98.09333333333333,
            97.875,
            97.94,
            98.09166666666667,
            98.18333333333334,
            98.28666666666666,
            98.19333333333333,
            98.21333333333334,
            98.34,
            98.45333333333333,
            98.6,
            98.58833333333334,
            98.68666666666667,
            98.66833333333334,
            98.56,
            98.71666666666667,
            98.65666666666667,
            98.71,
            98.745,
            98.81166666666667,
            98.825,
            98.80333333333333,
            98.805,
            98.85666666666667,
            98.815,
            98.88,
            98.92833333333333,
            99.04666666666667,
            98.97,
            98.985,
            99.01,
            99.07666666666667,
            99.04666666666667,
            99.005,
            99.06,
            99.05333333333333,
            99.055,
            98.995,
            99.09833333333333,
            99.09166666666667,
            99.14333333333333,
            99.07833333333333,
            99.10833333333333,
            99.18,
            99.16,
            99.11166666666666
        ],
        "best_test_acc": 92.35,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.35834717750549316,
            0.32064270973205566,
            0.3290131092071533,
            0.33492302894592285,
            0.30550289154052734,
            0.3311123847961426,
            0.3309018611907959,
            0.3529322147369385,
            0.34172749519348145,
            0.34903740882873535,
            0.3363077640533447,
            0.3197009563446045,
            0.3318758010864258,
            0.3685743808746338,
            0.33152222633361816,
            0.34688472747802734,
            0.32147645950317383,
            0.3640604019165039,
            0.3244516849517822,
            0.31293416023254395,
            0.30922484397888184,
            0.3478841781616211,
            0.3538029193878174,
            0.3181939125061035,
            0.2954869270324707,
            0.3196086883544922,
            0.32346177101135254,
            0.3031013011932373,
            0.3250129222869873,
            0.31186556816101074,
            0.29897308349609375,
            0.2894430160522461,
            0.3439018726348877,
            0.31819653511047363,
            0.32251429557800293,
            0.3303647041320801,
            0.33880019187927246,
            0.34505128860473633,
            0.343747615814209,
            0.3570137023925781,
            0.32411742210388184,
            0.32413673400878906,
            0.33727121353149414,
            0.33408355712890625,
            0.30901145935058594,
            0.357621431350708,
            0.3279578685760498,
            0.3399848937988281,
            0.35592222213745117,
            0.31580042839050293
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 16.533485412597656,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 5900,
        "num_opt_steps": 5900,
        "num_grad_steps": 5899
    }
]