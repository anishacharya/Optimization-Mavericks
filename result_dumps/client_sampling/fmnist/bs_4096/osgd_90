[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 4096,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 8,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.9,
                        "lr0": 0.11,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            76.63,
            70.87,
            53.27,
            36.74,
            29.069999999999993,
            25.58,
            24.08,
            19.75,
            18.790000000000006,
            16.629999999999995,
            16.28,
            17.010000000000005,
            15.290000000000006,
            16.72,
            14.010000000000005,
            16.099999999999994,
            13.829999999999998,
            13.409999999999997,
            14.030000000000001,
            12.689999999999998,
            12.450000000000003,
            12.400000000000006,
            12.019999999999996,
            11.939999999999998,
            12.099999999999994,
            11.829999999999998,
            11.620000000000005,
            11.810000000000002,
            11.680000000000007,
            11.510000000000005,
            11.680000000000007,
            11.469999999999999,
            11.230000000000004,
            11.519999999999996,
            11.25,
            11.099999999999994,
            11.5,
            11.11,
            10.819999999999993,
            10.900000000000006,
            10.959999999999994,
            11.019999999999996,
            10.810000000000002,
            10.650000000000006,
            10.829999999999998,
            10.980000000000004,
            10.950000000000003,
            10.719999999999999,
            10.819999999999993,
            10.900000000000006,
            10.569999999999993,
            10.980000000000004,
            10.900000000000006,
            10.769999999999996,
            10.400000000000006,
            10.560000000000002,
            10.510000000000005,
            10.469999999999999,
            10.64,
            10.510000000000005,
            10.510000000000005,
            10.590000000000003,
            10.510000000000005,
            10.549999999999997,
            10.530000000000001,
            10.680000000000007,
            10.549999999999997,
            10.379999999999995,
            10.370000000000005,
            10.439999999999998,
            10.239999999999995,
            10.239999999999995,
            10.329999999999998,
            10.310000000000002,
            10.219999999999999,
            9.939999999999998,
            10.200000000000003,
            10.310000000000002,
            10.209999999999994,
            10.030000000000001,
            10.030000000000001,
            10.099999999999994,
            9.930000000000007,
            10.319999999999993,
            10.180000000000007,
            10.170000000000002,
            10.269999999999996,
            10.310000000000002,
            10.39,
            10.219999999999999,
            10.11,
            9.930000000000007,
            10.079999999999998,
            10.11
        ],
        "test_loss": [],
        "test_acc": [
            23.37,
            29.13,
            46.73,
            63.26,
            70.93,
            74.42,
            75.92,
            80.25,
            81.21,
            83.37,
            83.72,
            82.99,
            84.71,
            83.28,
            85.99,
            83.9,
            86.17,
            86.59,
            85.97,
            87.31,
            87.55,
            87.6,
            87.98,
            88.06,
            87.9,
            88.17,
            88.38,
            88.19,
            88.32,
            88.49,
            88.32,
            88.53,
            88.77,
            88.48,
            88.75,
            88.9,
            88.5,
            88.89,
            89.18,
            89.1,
            89.04,
            88.98,
            89.19,
            89.35,
            89.17,
            89.02,
            89.05,
            89.28,
            89.18,
            89.1,
            89.43,
            89.02,
            89.1,
            89.23,
            89.6,
            89.44,
            89.49,
            89.53,
            89.36,
            89.49,
            89.49,
            89.41,
            89.49,
            89.45,
            89.47,
            89.32,
            89.45,
            89.62,
            89.63,
            89.56,
            89.76,
            89.76,
            89.67,
            89.69,
            89.78,
            90.06,
            89.8,
            89.69,
            89.79,
            89.97,
            89.97,
            89.9,
            90.07,
            89.68,
            89.82,
            89.83,
            89.73,
            89.69,
            89.61,
            89.78,
            89.89,
            90.07,
            89.92,
            89.89
        ],
        "train_error": [
            76.85166666666666,
            70.42,
            53.035,
            36.05833333333333,
            28.58833333333334,
            25.678333333333327,
            23.85333333333334,
            19.435000000000002,
            18.318333333333328,
            16.176666666666662,
            15.413333333333327,
            15.966666666666669,
            14.081666666666663,
            15.405000000000001,
            12.885000000000005,
            14.811666666666667,
            12.730000000000004,
            12.299999999999997,
            12.674999999999997,
            11.38666666666667,
            11.086666666666673,
            11.051666666666662,
            10.816666666666663,
            10.668333333333337,
            10.599999999999994,
            10.423333333333332,
            10.413333333333327,
            10.409999999999997,
            10.150000000000006,
            10.135000000000005,
            9.911666666666662,
            9.903333333333336,
            9.74666666666667,
            9.931666666666672,
            9.783333333333331,
            9.516666666666666,
            9.726666666666674,
            9.451666666666668,
            9.174999999999997,
            9.156666666666666,
            9.155000000000001,
            9.329999999999998,
            9.00333333333333,
            9.126666666666665,
            8.983333333333334,
            8.935000000000002,
            8.943333333333328,
            8.790000000000006,
            8.995000000000005,
            8.88666666666667,
            8.706666666666663,
            8.798333333333332,
            8.771666666666661,
            8.546666666666667,
            8.566666666666663,
            8.674999999999997,
            8.533333333333331,
            8.501666666666665,
            8.388333333333335,
            8.428333333333327,
            8.448333333333338,
            8.408333333333331,
            8.299999999999997,
            8.361666666666665,
            8.40166666666667,
            8.24166666666666,
            8.316666666666663,
            8.14333333333333,
            8.281666666666666,
            8.341666666666669,
            8.174999999999997,
            8.25,
            8.314999999999998,
            8.193333333333328,
            8.181666666666672,
            8.209999999999994,
            8.158333333333331,
            8.178333333333327,
            8.066666666666663,
            8.171666666666667,
            8.051666666666662,
            8.163333333333327,
            8.091666666666669,
            8.12833333333333,
            8.056666666666672,
            8.114999999999995,
            7.9183333333333366,
            8.053333333333327,
            8.103333333333339,
            7.976666666666674,
            8.045000000000002,
            7.969999999999999,
            8.075000000000003,
            8.0
        ],
        "train_loss": [
            2.239554770787557,
            2.205275853474935,
            1.5244976997375488,
            0.9637690742810567,
            0.7746921857198079,
            0.7239994168281555,
            0.6166716814041138,
            0.5127991994222005,
            0.47926644881566366,
            0.4337261656920115,
            0.41126078367233276,
            0.4176569143931071,
            0.3795747836430868,
            0.40534721612930297,
            0.34992321928342185,
            0.38843331138292947,
            0.34032805959383644,
            0.3313123007615407,
            0.3345275163650513,
            0.30995153983434043,
            0.3035968800385793,
            0.29971914887428286,
            0.2951219916343689,
            0.2919177075227102,
            0.2880726714928945,
            0.28508683244387306,
            0.28122729857762657,
            0.28102144996325173,
            0.2762937307357788,
            0.27387380798657734,
            0.27030417720476785,
            0.26938721736272175,
            0.2653112510840098,
            0.2675135393937429,
            0.2658758302529653,
            0.2593699753284454,
            0.26336254278818766,
            0.2554788688818614,
            0.2530379394690196,
            0.25033447444438933,
            0.24959118763605753,
            0.25182226300239563,
            0.24678409099578857,
            0.24586358467737834,
            0.24468501806259155,
            0.24329189161459605,
            0.24247957567373912,
            0.24163656731446584,
            0.24192887743314107,
            0.24051032265027364,
            0.23911794821421306,
            0.23842518925666809,
            0.23786338667074838,
            0.23473214010397594,
            0.2341559628645579,
            0.23521811962127687,
            0.23332071503003438,
            0.23240792155265808,
            0.23030992945035297,
            0.23070741792519886,
            0.23072269558906555,
            0.23005352715651195,
            0.228314804037412,
            0.22895125051339468,
            0.22912331521511078,
            0.22678941388924917,
            0.22676555116971334,
            0.2255482167005539,
            0.22629717290401458,
            0.22512895067532857,
            0.2244251827398936,
            0.22511546909809113,
            0.22542739510536194,
            0.22463406721750895,
            0.22234088083108267,
            0.22449510296185812,
            0.2217504660288493,
            0.22271694540977477,
            0.22008451720078787,
            0.2209908425807953,
            0.22100210587183636,
            0.22224208613236746,
            0.22145014305909475,
            0.21944123307863872,
            0.21979907155036926,
            0.2204123596350352,
            0.21824786166350046,
            0.2181361049413681,
            0.21836504141489665,
            0.21889502008756,
            0.21826963424682616,
            0.21875832776228588,
            0.21848472952842712,
            0.2184179385503133
        ],
        "train_acc": [
            23.148333333333333,
            29.58,
            46.965,
            63.94166666666667,
            71.41166666666666,
            74.32166666666667,
            76.14666666666666,
            80.565,
            81.68166666666667,
            83.82333333333334,
            84.58666666666667,
            84.03333333333333,
            85.91833333333334,
            84.595,
            87.115,
            85.18833333333333,
            87.27,
            87.7,
            87.325,
            88.61333333333333,
            88.91333333333333,
            88.94833333333334,
            89.18333333333334,
            89.33166666666666,
            89.4,
            89.57666666666667,
            89.58666666666667,
            89.59,
            89.85,
            89.865,
            90.08833333333334,
            90.09666666666666,
            90.25333333333333,
            90.06833333333333,
            90.21666666666667,
            90.48333333333333,
            90.27333333333333,
            90.54833333333333,
            90.825,
            90.84333333333333,
            90.845,
            90.67,
            90.99666666666667,
            90.87333333333333,
            91.01666666666667,
            91.065,
            91.05666666666667,
            91.21,
            91.005,
            91.11333333333333,
            91.29333333333334,
            91.20166666666667,
            91.22833333333334,
            91.45333333333333,
            91.43333333333334,
            91.325,
            91.46666666666667,
            91.49833333333333,
            91.61166666666666,
            91.57166666666667,
            91.55166666666666,
            91.59166666666667,
            91.7,
            91.63833333333334,
            91.59833333333333,
            91.75833333333334,
            91.68333333333334,
            91.85666666666667,
            91.71833333333333,
            91.65833333333333,
            91.825,
            91.75,
            91.685,
            91.80666666666667,
            91.81833333333333,
            91.79,
            91.84166666666667,
            91.82166666666667,
            91.93333333333334,
            91.82833333333333,
            91.94833333333334,
            91.83666666666667,
            91.90833333333333,
            91.87166666666667,
            91.94333333333333,
            91.885,
            92.08166666666666,
            91.94666666666667,
            91.89666666666666,
            92.02333333333333,
            91.955,
            92.03,
            91.925,
            92.0
        ],
        "best_test_acc": 90.07,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.1635904312133789,
            0.10352611541748047,
            0.10401225090026855,
            0.1338520050048828,
            0.09961438179016113,
            0.09044265747070312,
            0.08904647827148438,
            0.1152658462524414,
            0.13370990753173828,
            0.1225275993347168,
            0.12472271919250488,
            0.12398505210876465,
            0.1117711067199707,
            0.13465619087219238,
            0.12318062782287598,
            0.11873435974121094,
            0.1074373722076416,
            0.09998321533203125,
            0.08290791511535645,
            0.09022402763366699,
            0.08738422393798828,
            0.11137056350708008,
            0.0961463451385498,
            0.09955811500549316,
            0.13010907173156738,
            0.12301015853881836,
            0.11211371421813965,
            0.14782023429870605,
            0.14774513244628906,
            0.14527535438537598,
            0.16617155075073242,
            0.14370512962341309,
            0.13839101791381836,
            0.1372089385986328,
            0.1536557674407959,
            0.14976978302001953,
            0.1268622875213623,
            0.13485336303710938,
            0.15113091468811035,
            0.12893271446228027,
            0.11791825294494629,
            0.13973712921142578,
            0.13179445266723633,
            0.12279605865478516,
            0.1102297306060791,
            0.1253342628479004,
            0.09898519515991211,
            0.10920190811157227,
            0.12057900428771973,
            0.13269710540771484
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 6.113677740097046,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 750,
        "num_opt_steps": 750,
        "num_grad_steps": 749
    }
]