[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 4096,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 8,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.85,
                        "lr0": 0.11,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            76.34,
            68.56,
            53.69,
            45.63,
            33.43000000000001,
            27.03,
            24.709999999999994,
            22.269999999999996,
            20.680000000000007,
            21.989999999999995,
            18.120000000000005,
            17.25,
            16.730000000000004,
            16.92,
            17.25,
            15.459999999999994,
            16.069999999999993,
            15.120000000000005,
            14.14,
            13.530000000000001,
            13.5,
            13.540000000000006,
            13.269999999999996,
            13.0,
            12.959999999999994,
            12.780000000000001,
            12.629999999999995,
            12.450000000000003,
            12.459999999999994,
            12.769999999999996,
            12.469999999999999,
            13.060000000000002,
            12.129999999999995,
            12.159999999999997,
            12.659999999999997,
            12.180000000000007,
            12.299999999999997,
            11.730000000000004,
            11.510000000000005,
            11.400000000000006,
            11.459999999999994,
            11.340000000000003,
            11.549999999999997,
            11.260000000000005,
            11.39,
            11.269999999999996,
            11.409999999999997,
            10.909999999999997,
            11.060000000000002,
            11.269999999999996,
            11.010000000000005,
            11.5,
            11.290000000000006,
            10.959999999999994,
            10.89,
            11.14,
            11.030000000000001,
            10.879999999999995,
            11.0,
            10.879999999999995,
            10.829999999999998,
            10.760000000000005,
            10.579999999999998,
            10.689999999999998,
            10.799999999999997,
            10.700000000000003,
            10.629999999999995,
            10.650000000000006,
            10.469999999999999,
            10.709999999999994,
            10.670000000000002,
            10.459999999999994,
            10.379999999999995,
            10.400000000000006,
            10.39,
            10.540000000000006,
            10.349999999999994,
            10.560000000000002,
            10.420000000000002,
            10.239999999999995,
            10.349999999999994,
            10.349999999999994,
            10.379999999999995,
            10.519999999999996,
            10.459999999999994,
            10.61,
            10.299999999999997,
            10.5,
            10.489999999999995,
            10.280000000000001,
            10.709999999999994,
            10.39,
            10.150000000000006,
            10.319999999999993
        ],
        "test_loss": [],
        "test_acc": [
            23.66,
            31.44,
            46.31,
            54.37,
            66.57,
            72.97,
            75.29,
            77.73,
            79.32,
            78.01,
            81.88,
            82.75,
            83.27,
            83.08,
            82.75,
            84.54,
            83.93,
            84.88,
            85.86,
            86.47,
            86.5,
            86.46,
            86.73,
            87.0,
            87.04,
            87.22,
            87.37,
            87.55,
            87.54,
            87.23,
            87.53,
            86.94,
            87.87,
            87.84,
            87.34,
            87.82,
            87.7,
            88.27,
            88.49,
            88.6,
            88.54,
            88.66,
            88.45,
            88.74,
            88.61,
            88.73,
            88.59,
            89.09,
            88.94,
            88.73,
            88.99,
            88.5,
            88.71,
            89.04,
            89.11,
            88.86,
            88.97,
            89.12,
            89.0,
            89.12,
            89.17,
            89.24,
            89.42,
            89.31,
            89.2,
            89.3,
            89.37,
            89.35,
            89.53,
            89.29,
            89.33,
            89.54,
            89.62,
            89.6,
            89.61,
            89.46,
            89.65,
            89.44,
            89.58,
            89.76,
            89.65,
            89.65,
            89.62,
            89.48,
            89.54,
            89.39,
            89.7,
            89.5,
            89.51,
            89.72,
            89.29,
            89.61,
            89.85,
            89.68
        ],
        "train_error": [
            76.63166666666666,
            68.05,
            52.72833333333333,
            45.565,
            32.489999999999995,
            25.97333333333333,
            24.019999999999996,
            21.558333333333337,
            19.58833333333334,
            21.269999999999996,
            17.298333333333332,
            16.51166666666667,
            15.661666666666662,
            15.588333333333338,
            16.35666666666667,
            14.375,
            14.555000000000007,
            13.841666666666669,
            13.001666666666665,
            12.504999999999995,
            12.224999999999994,
            12.078333333333333,
            11.924999999999997,
            11.578333333333333,
            11.644999999999996,
            11.468333333333334,
            11.284999999999997,
            11.221666666666664,
            11.219999999999999,
            11.39333333333333,
            11.061666666666667,
            11.439999999999998,
            11.045000000000002,
            10.75333333333333,
            11.254999999999995,
            10.62166666666667,
            11.331666666666663,
            10.168333333333337,
            10.088333333333338,
            10.13333333333334,
            9.953333333333333,
            10.034999999999997,
            9.918333333333337,
            9.935000000000002,
            9.908333333333331,
            9.594999999999999,
            9.784999999999997,
            9.581666666666663,
            9.683333333333337,
            9.670000000000002,
            9.553333333333327,
            9.673333333333332,
            9.398333333333326,
            9.423333333333332,
            9.36333333333333,
            9.451666666666668,
            9.293333333333337,
            9.288333333333327,
            9.194999999999993,
            9.071666666666673,
            9.233333333333334,
            9.079999999999998,
            9.088333333333338,
            9.056666666666672,
            9.01166666666667,
            9.025000000000006,
            9.076666666666668,
            8.908333333333331,
            9.010000000000005,
            8.968333333333334,
            8.961666666666673,
            8.951666666666668,
            8.941666666666663,
            8.924999999999997,
            8.931666666666672,
            8.898333333333326,
            8.801666666666662,
            8.851666666666674,
            8.778333333333336,
            8.870000000000005,
            8.766666666666666,
            8.693333333333328,
            8.760000000000005,
            8.681666666666672,
            8.685000000000002,
            8.733333333333334,
            8.788333333333327,
            8.650000000000006,
            8.64333333333333,
            8.769999999999996,
            8.711666666666673,
            8.700000000000003,
            8.765,
            8.608333333333334
        ],
        "train_loss": [
            2.2441092491149903,
            2.2141918659210207,
            1.597694754600525,
            1.350773843129476,
            0.9121664007504781,
            0.7020917852719625,
            0.6205283045768738,
            0.5644050319989522,
            0.5155908246835073,
            0.548751978079478,
            0.4609439035256704,
            0.4408115029335022,
            0.42010518709818523,
            0.4088257690270742,
            0.42896984616915385,
            0.385844620068868,
            0.38654427528381347,
            0.3675679763158162,
            0.3481370766957601,
            0.3391025086243947,
            0.33065555095672605,
            0.3247893790404002,
            0.321283624569575,
            0.3149443487326304,
            0.3146284063657125,
            0.3112183213233948,
            0.30904122193654376,
            0.3043446997801463,
            0.30377734303474424,
            0.3061033050219218,
            0.29887757698694867,
            0.30912212530771893,
            0.29737958709398904,
            0.29286420345306396,
            0.30185532569885254,
            0.2860485851764679,
            0.29928598006566365,
            0.27895713051160176,
            0.2754137853781382,
            0.2743707180023193,
            0.2724200169245402,
            0.272969255844752,
            0.2708396633466085,
            0.26805145740509034,
            0.2680171449979146,
            0.2647050182024638,
            0.2652540187040965,
            0.2638470311959585,
            0.2637154926856359,
            0.2610689530769984,
            0.2615465273459752,
            0.2610657254854838,
            0.25772867202758787,
            0.2574383795261383,
            0.2567644437154134,
            0.2583015610774358,
            0.25432765086491904,
            0.2528933137655258,
            0.25192830959955853,
            0.2494440128405889,
            0.2500594089428584,
            0.2503010759751002,
            0.24977336823940277,
            0.2489729990561803,
            0.24649035731951396,
            0.24718976120154063,
            0.24756001631418864,
            0.2464817653099696,
            0.24563095172246296,
            0.24424804548422496,
            0.2449396848678589,
            0.2450260837872823,
            0.24498069485028584,
            0.2449822336435318,
            0.24294584095478058,
            0.24282693564891816,
            0.2420949399471283,
            0.24134436746438345,
            0.23997632265090943,
            0.24182405571142832,
            0.24115316867828368,
            0.2412361224492391,
            0.24045415123303732,
            0.23890271683533987,
            0.23944736421108245,
            0.23970973889033,
            0.23856127162774404,
            0.23777169187863667,
            0.23812950452168782,
            0.2380791296561559,
            0.23791154325008393,
            0.2383037716150284,
            0.2383814444144567,
            0.23767593900362652
        ],
        "train_acc": [
            23.368333333333332,
            31.95,
            47.27166666666667,
            54.435,
            67.51,
            74.02666666666667,
            75.98,
            78.44166666666666,
            80.41166666666666,
            78.73,
            82.70166666666667,
            83.48833333333333,
            84.33833333333334,
            84.41166666666666,
            83.64333333333333,
            85.625,
            85.445,
            86.15833333333333,
            86.99833333333333,
            87.495,
            87.775,
            87.92166666666667,
            88.075,
            88.42166666666667,
            88.355,
            88.53166666666667,
            88.715,
            88.77833333333334,
            88.78,
            88.60666666666667,
            88.93833333333333,
            88.56,
            88.955,
            89.24666666666667,
            88.745,
            89.37833333333333,
            88.66833333333334,
            89.83166666666666,
            89.91166666666666,
            89.86666666666666,
            90.04666666666667,
            89.965,
            90.08166666666666,
            90.065,
            90.09166666666667,
            90.405,
            90.215,
            90.41833333333334,
            90.31666666666666,
            90.33,
            90.44666666666667,
            90.32666666666667,
            90.60166666666667,
            90.57666666666667,
            90.63666666666667,
            90.54833333333333,
            90.70666666666666,
            90.71166666666667,
            90.805,
            90.92833333333333,
            90.76666666666667,
            90.92,
            90.91166666666666,
            90.94333333333333,
            90.98833333333333,
            90.975,
            90.92333333333333,
            91.09166666666667,
            90.99,
            91.03166666666667,
            91.03833333333333,
            91.04833333333333,
            91.05833333333334,
            91.075,
            91.06833333333333,
            91.10166666666667,
            91.19833333333334,
            91.14833333333333,
            91.22166666666666,
            91.13,
            91.23333333333333,
            91.30666666666667,
            91.24,
            91.31833333333333,
            91.315,
            91.26666666666667,
            91.21166666666667,
            91.35,
            91.35666666666667,
            91.23,
            91.28833333333333,
            91.3,
            91.235,
            91.39166666666667
        ],
        "best_test_acc": 89.85,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.11995172500610352,
            0.13642144203186035,
            0.11509227752685547,
            0.10979795455932617,
            0.09100675582885742,
            0.14019179344177246,
            0.135392427444458,
            0.10393667221069336,
            0.09108304977416992,
            0.11582469940185547,
            0.11116218566894531,
            0.10980987548828125,
            0.11626815795898438,
            0.1277174949645996,
            0.10515451431274414,
            0.11129999160766602,
            0.11802005767822266,
            0.12706637382507324,
            0.14167284965515137,
            0.1523292064666748,
            0.15075898170471191,
            0.1501786708831787,
            0.1532728672027588,
            0.15346264839172363,
            0.1490175724029541,
            0.12061071395874023,
            0.10758519172668457,
            0.12807798385620117,
            0.11805200576782227,
            0.14014577865600586,
            0.12340664863586426,
            0.12316083908081055,
            0.10933232307434082,
            0.12665057182312012,
            0.15798306465148926,
            0.11562752723693848,
            0.13984370231628418,
            0.13715100288391113,
            0.12443780899047852,
            0.1268916130065918,
            0.14543795585632324,
            0.12680959701538086,
            0.11139369010925293,
            0.1337110996246338,
            0.10333633422851562,
            0.11211657524108887,
            0.16023612022399902,
            0.09973955154418945,
            0.08231425285339355,
            0.0822453498840332
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 6.192187547683716,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 750,
        "num_opt_steps": 750,
        "num_grad_steps": 749
    }
]