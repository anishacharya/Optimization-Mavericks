[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 2048,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 16,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.7,
                        "lr0": 0.08,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            79.84,
            54.29,
            24.489999999999995,
            19.22,
            16.92,
            15.25,
            14.879999999999995,
            13.799999999999997,
            12.730000000000004,
            12.299999999999997,
            12.159999999999997,
            11.769999999999996,
            11.64,
            12.030000000000001,
            11.069999999999993,
            11.719999999999999,
            10.840000000000003,
            11.040000000000006,
            10.75,
            10.400000000000006,
            10.290000000000006,
            10.150000000000006,
            9.920000000000002,
            9.89,
            9.549999999999997,
            10.019999999999996,
            9.739999999999995,
            9.819999999999993,
            9.25,
            9.670000000000002,
            9.650000000000006,
            9.409999999999997,
            9.379999999999995,
            9.370000000000005,
            9.540000000000006,
            9.129999999999995,
            9.260000000000005,
            9.239999999999995,
            9.019999999999996,
            9.030000000000001,
            8.920000000000002,
            9.170000000000002,
            8.969999999999999,
            9.11,
            8.980000000000004,
            8.75,
            9.14,
            9.019999999999996,
            9.010000000000005,
            9.010000000000005,
            8.89,
            9.129999999999995,
            9.0,
            8.689999999999998,
            8.89,
            9.079999999999998,
            8.810000000000002,
            8.599999999999994,
            8.650000000000006,
            8.849999999999994,
            8.849999999999994,
            8.730000000000004,
            8.459999999999994,
            8.790000000000006,
            8.590000000000003,
            8.700000000000003,
            8.930000000000007,
            8.590000000000003,
            8.61,
            8.560000000000002,
            8.579999999999998,
            8.790000000000006,
            8.409999999999997,
            8.920000000000002,
            8.909999999999997,
            8.790000000000006,
            8.920000000000002,
            8.469999999999999,
            8.569999999999993,
            8.810000000000002,
            8.579999999999998,
            8.269999999999996,
            8.620000000000005,
            8.469999999999999,
            8.700000000000003,
            8.739999999999995,
            8.700000000000003,
            8.680000000000007,
            8.620000000000005,
            8.540000000000006,
            8.709999999999994,
            8.819999999999993,
            8.459999999999994,
            8.790000000000006
        ],
        "test_loss": [],
        "test_acc": [
            20.16,
            45.71,
            75.51,
            80.78,
            83.08,
            84.75,
            85.12,
            86.2,
            87.27,
            87.7,
            87.84,
            88.23,
            88.36,
            87.97,
            88.93,
            88.28,
            89.16,
            88.96,
            89.25,
            89.6,
            89.71,
            89.85,
            90.08,
            90.11,
            90.45,
            89.98,
            90.26,
            90.18,
            90.75,
            90.33,
            90.35,
            90.59,
            90.62,
            90.63,
            90.46,
            90.87,
            90.74,
            90.76,
            90.98,
            90.97,
            91.08,
            90.83,
            91.03,
            90.89,
            91.02,
            91.25,
            90.86,
            90.98,
            90.99,
            90.99,
            91.11,
            90.87,
            91.0,
            91.31,
            91.11,
            90.92,
            91.19,
            91.4,
            91.35,
            91.15,
            91.15,
            91.27,
            91.54,
            91.21,
            91.41,
            91.3,
            91.07,
            91.41,
            91.39,
            91.44,
            91.42,
            91.21,
            91.59,
            91.08,
            91.09,
            91.21,
            91.08,
            91.53,
            91.43,
            91.19,
            91.42,
            91.73,
            91.38,
            91.53,
            91.3,
            91.26,
            91.3,
            91.32,
            91.38,
            91.46,
            91.29,
            91.18,
            91.54,
            91.21
        ],
        "train_error": [
            79.51333333333334,
            53.78333333333333,
            24.0,
            18.546666666666667,
            16.076666666666668,
            14.046666666666667,
            13.888333333333335,
            12.760000000000005,
            11.75,
            11.431666666666672,
            11.091666666666669,
            10.485,
            10.39333333333333,
            10.611666666666665,
            9.89333333333333,
            10.25333333333333,
            9.438333333333333,
            9.49333333333334,
            9.11833333333334,
            8.64,
            8.265,
            8.168333333333337,
            7.87833333333333,
            8.0,
            7.743333333333339,
            7.890000000000001,
            7.549999999999997,
            7.541666666666671,
            7.393333333333331,
            7.311666666666667,
            7.343333333333334,
            7.155000000000001,
            7.219999999999999,
            6.966666666666669,
            6.86333333333333,
            6.780000000000001,
            6.743333333333339,
            6.601666666666674,
            6.336666666666673,
            6.398333333333326,
            6.439999999999998,
            6.329999999999998,
            6.1783333333333275,
            6.019999999999996,
            6.006666666666661,
            5.961666666666673,
            6.060000000000002,
            6.066666666666663,
            5.9183333333333366,
            5.935000000000002,
            5.920000000000002,
            5.88333333333334,
            5.796666666666667,
            5.781666666666666,
            5.713333333333338,
            5.61333333333333,
            5.694999999999993,
            5.541666666666671,
            5.493333333333339,
            5.453333333333333,
            5.409999999999997,
            5.406666666666666,
            5.334999999999994,
            5.405000000000001,
            5.390000000000001,
            5.310000000000002,
            5.326666666666668,
            5.186666666666667,
            5.143333333333331,
            5.265000000000001,
            5.181666666666672,
            5.166666666666671,
            5.155000000000001,
            5.12166666666667,
            5.12166666666667,
            5.031666666666666,
            4.969999999999999,
            5.105000000000004,
            5.00833333333334,
            5.006666666666661,
            5.040000000000006,
            4.851666666666674,
            4.86333333333333,
            4.931666666666672,
            4.891666666666666,
            4.841666666666669,
            4.885000000000005,
            4.888333333333335,
            4.825000000000003,
            4.875,
            4.936666666666667,
            4.926666666666662,
            4.948333333333338,
            4.851666666666674
        ],
        "train_loss": [
            2.2617342789967854,
            1.6111360351244608,
            0.6129763106505076,
            0.49297747015953064,
            0.43476536870002747,
            0.3821506122748057,
            0.3674055814743042,
            0.3455811550219854,
            0.3194241593281428,
            0.3092536648114522,
            0.30193943679332735,
            0.28480013211568195,
            0.2837766309579213,
            0.2830188125371933,
            0.2667606691519419,
            0.2773854012290637,
            0.25489623099565506,
            0.254514346520106,
            0.2474717105428378,
            0.2327030782898267,
            0.22533976684014004,
            0.22202465931574503,
            0.21733022232850394,
            0.21695979138215382,
            0.2123040775458018,
            0.21364602992932002,
            0.20524190564950306,
            0.20522384295860926,
            0.2015417481462161,
            0.19866519272327424,
            0.19906754344701766,
            0.19646477550268174,
            0.1954451248049736,
            0.1893448342879613,
            0.19012745022773742,
            0.184293728073438,
            0.18512789656718573,
            0.18113885819911957,
            0.17625469366709393,
            0.17542963673671086,
            0.1728712573647499,
            0.17243397335211436,
            0.16989664485057196,
            0.1685452863574028,
            0.1671473373969396,
            0.16690968523422878,
            0.16631763378779094,
            0.16829840540885926,
            0.16303926159938176,
            0.16373902161916096,
            0.16083299418290456,
            0.16225642214218775,
            0.15939966241518658,
            0.15957428266604742,
            0.15826412985722224,
            0.15635963728030522,
            0.1545008311669032,
            0.15385659237702687,
            0.15158990770578384,
            0.15177785257498425,
            0.1495461960633596,
            0.14922013729810715,
            0.14859328617652257,
            0.14931856840848923,
            0.1492587109406789,
            0.14771893868843713,
            0.14805718859036762,
            0.14576948980490367,
            0.14384375810623168,
            0.14614215021332105,
            0.14530699849128723,
            0.14426033496856688,
            0.14300687313079835,
            0.1438997656106949,
            0.1428117980559667,
            0.14065307304263114,
            0.14043942764401435,
            0.14144165019194285,
            0.13909470165769258,
            0.13863916496435802,
            0.13986493945121764,
            0.1372103991607825,
            0.13889288182059925,
            0.13707303578654925,
            0.13823616454998652,
            0.13844946150978407,
            0.13688530350724856,
            0.136824702223142,
            0.13614275256792704,
            0.13640582834680876,
            0.1371427377065023,
            0.1361381304760774,
            0.13656477481126786,
            0.1362628718217214
        ],
        "train_acc": [
            20.486666666666668,
            46.21666666666667,
            76.0,
            81.45333333333333,
            83.92333333333333,
            85.95333333333333,
            86.11166666666666,
            87.24,
            88.25,
            88.56833333333333,
            88.90833333333333,
            89.515,
            89.60666666666667,
            89.38833333333334,
            90.10666666666667,
            89.74666666666667,
            90.56166666666667,
            90.50666666666666,
            90.88166666666666,
            91.36,
            91.735,
            91.83166666666666,
            92.12166666666667,
            92.0,
            92.25666666666666,
            92.11,
            92.45,
            92.45833333333333,
            92.60666666666667,
            92.68833333333333,
            92.65666666666667,
            92.845,
            92.78,
            93.03333333333333,
            93.13666666666667,
            93.22,
            93.25666666666666,
            93.39833333333333,
            93.66333333333333,
            93.60166666666667,
            93.56,
            93.67,
            93.82166666666667,
            93.98,
            93.99333333333334,
            94.03833333333333,
            93.94,
            93.93333333333334,
            94.08166666666666,
            94.065,
            94.08,
            94.11666666666666,
            94.20333333333333,
            94.21833333333333,
            94.28666666666666,
            94.38666666666667,
            94.305,
            94.45833333333333,
            94.50666666666666,
            94.54666666666667,
            94.59,
            94.59333333333333,
            94.665,
            94.595,
            94.61,
            94.69,
            94.67333333333333,
            94.81333333333333,
            94.85666666666667,
            94.735,
            94.81833333333333,
            94.83333333333333,
            94.845,
            94.87833333333333,
            94.87833333333333,
            94.96833333333333,
            95.03,
            94.895,
            94.99166666666666,
            94.99333333333334,
            94.96,
            95.14833333333333,
            95.13666666666667,
            95.06833333333333,
            95.10833333333333,
            95.15833333333333,
            95.115,
            95.11166666666666,
            95.175,
            95.125,
            95.06333333333333,
            95.07333333333334,
            95.05166666666666,
            95.14833333333333
        ],
        "best_test_acc": 91.73,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.1596057415008545,
            0.14278817176818848,
            0.13666892051696777,
            0.1556873321533203,
            0.17219996452331543,
            0.12915682792663574,
            0.11801385879516602,
            0.11504602432250977,
            0.17437529563903809,
            0.16486501693725586,
            0.13796567916870117,
            0.1195981502532959,
            0.14696955680847168,
            0.1423816680908203,
            0.13836216926574707,
            0.1297299861907959,
            0.13151884078979492,
            0.12398982048034668,
            0.14041686058044434,
            0.12513351440429688,
            0.1354668140411377,
            0.1434946060180664,
            0.12722182273864746,
            0.1401522159576416,
            0.13647127151489258,
            0.13573741912841797,
            0.15337038040161133,
            0.13895130157470703,
            0.12696146965026855,
            0.1471116542816162,
            0.16075396537780762,
            0.13632678985595703,
            0.13689947128295898,
            0.15797114372253418,
            0.14968299865722656,
            0.14840054512023926,
            0.14662623405456543,
            0.1384892463684082,
            0.14156866073608398,
            0.13947367668151855,
            0.16933155059814453,
            0.13309192657470703,
            0.15099740028381348,
            0.13885021209716797,
            0.1434309482574463,
            0.12314677238464355,
            0.10562658309936523,
            0.10500454902648926,
            0.10728049278259277,
            0.10576558113098145
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 6.928131103515625,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 1500,
        "num_opt_steps": 1500,
        "num_grad_steps": 1499
    }
]