[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 1024,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 32,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.75,
                        "lr0": 0.057,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            82.78,
            23.680000000000007,
            16.560000000000002,
            14.299999999999997,
            13.549999999999997,
            12.299999999999997,
            11.780000000000001,
            11.670000000000002,
            11.280000000000001,
            11.019999999999996,
            10.670000000000002,
            10.620000000000005,
            10.439999999999998,
            10.049999999999997,
            10.310000000000002,
            9.780000000000001,
            9.75,
            9.780000000000001,
            9.540000000000006,
            8.969999999999999,
            8.939999999999998,
            8.909999999999997,
            8.959999999999994,
            8.86,
            8.840000000000003,
            8.709999999999994,
            9.11,
            8.900000000000006,
            8.879999999999995,
            8.549999999999997,
            8.599999999999994,
            8.810000000000002,
            8.519999999999996,
            8.450000000000003,
            8.549999999999997,
            8.700000000000003,
            8.400000000000006,
            8.439999999999998,
            8.25,
            8.329999999999998,
            8.469999999999999,
            8.219999999999999,
            8.430000000000007,
            8.25,
            8.25,
            8.579999999999998,
            8.25,
            8.200000000000003,
            8.340000000000003,
            8.150000000000006,
            8.459999999999994,
            8.480000000000004,
            8.299999999999997,
            8.379999999999995,
            8.079999999999998,
            8.219999999999999,
            8.299999999999997,
            7.959999999999994,
            8.489999999999995,
            8.14,
            8.25,
            8.010000000000005,
            8.159999999999997,
            7.890000000000001,
            8.36,
            8.090000000000003,
            8.14,
            7.819999999999993,
            8.170000000000002,
            8.090000000000003,
            8.150000000000006,
            8.230000000000004,
            8.299999999999997,
            8.319999999999993,
            8.329999999999998,
            8.069999999999993,
            8.019999999999996,
            7.920000000000002,
            8.329999999999998,
            7.989999999999995,
            8.340000000000003,
            8.030000000000001,
            8.150000000000006,
            8.079999999999998,
            8.060000000000002,
            8.11,
            8.170000000000002,
            8.0,
            8.129999999999995,
            8.150000000000006,
            7.969999999999999,
            7.969999999999999,
            7.780000000000001
        ],
        "test_loss": [],
        "test_acc": [
            17.22,
            76.32,
            83.44,
            85.7,
            86.45,
            87.7,
            88.22,
            88.33,
            88.72,
            88.98,
            89.33,
            89.38,
            89.56,
            89.95,
            89.69,
            90.22,
            90.25,
            90.22,
            90.46,
            91.03,
            91.06,
            91.09,
            91.04,
            91.14,
            91.16,
            91.29,
            90.89,
            91.1,
            91.12,
            91.45,
            91.4,
            91.19,
            91.48,
            91.55,
            91.45,
            91.3,
            91.6,
            91.56,
            91.75,
            91.67,
            91.53,
            91.78,
            91.57,
            91.75,
            91.75,
            91.42,
            91.75,
            91.8,
            91.66,
            91.85,
            91.54,
            91.52,
            91.7,
            91.62,
            91.92,
            91.78,
            91.7,
            92.04,
            91.51,
            91.86,
            91.75,
            91.99,
            91.84,
            92.11,
            91.64,
            91.91,
            91.86,
            92.18,
            91.83,
            91.91,
            91.85,
            91.77,
            91.7,
            91.68,
            91.67,
            91.93,
            91.98,
            92.08,
            91.67,
            92.01,
            91.66,
            91.97,
            91.85,
            91.92,
            91.94,
            91.89,
            91.83,
            92.0,
            91.87,
            91.85,
            92.03,
            92.03,
            92.22
        ],
        "train_error": [
            82.30333333333334,
            22.680000000000007,
            15.861666666666665,
            13.454999999999998,
            12.644999999999996,
            11.351666666666674,
            10.646666666666661,
            10.010000000000005,
            9.716666666666669,
            9.341666666666669,
            8.701666666666668,
            8.555000000000007,
            8.26166666666667,
            8.01166666666667,
            8.025000000000006,
            7.483333333333334,
            7.204999999999998,
            7.155000000000001,
            6.984999999999999,
            6.2933333333333366,
            6.12833333333333,
            5.851666666666674,
            5.713333333333338,
            5.573333333333338,
            5.471666666666664,
            5.525000000000006,
            5.5716666666666725,
            5.231666666666669,
            5.1200000000000045,
            5.135000000000005,
            5.058333333333337,
            5.046666666666667,
            4.525000000000006,
            4.75,
            4.625,
            4.530000000000001,
            4.461666666666673,
            4.105000000000004,
            3.9950000000000045,
            3.951666666666668,
            3.924999999999997,
            3.7383333333333297,
            3.6566666666666663,
            3.6583333333333314,
            3.558333333333337,
            3.5066666666666606,
            3.510000000000005,
            3.3333333333333286,
            3.356666666666669,
            3.3433333333333337,
            3.3683333333333394,
            3.2150000000000034,
            3.2150000000000034,
            3.1116666666666646,
            3.0133333333333354,
            2.9183333333333366,
            2.9399999999999977,
            2.8133333333333326,
            2.873333333333335,
            2.896666666666661,
            2.7333333333333343,
            2.7366666666666646,
            2.626666666666665,
            2.6299999999999955,
            2.6966666666666725,
            2.644999999999996,
            2.549999999999997,
            2.569999999999993,
            2.6083333333333343,
            2.5799999999999983,
            2.521666666666661,
            2.4183333333333366,
            2.4583333333333286,
            2.4833333333333343,
            2.3516666666666737,
            2.3216666666666725,
            2.299999999999997,
            2.2816666666666663,
            2.271666666666661,
            2.25,
            2.2249999999999943,
            2.260000000000005,
            2.239999999999995,
            2.2933333333333366,
            2.2249999999999943,
            2.078333333333333,
            2.1850000000000023,
            2.223333333333329,
            2.2333333333333343,
            2.086666666666673,
            2.151666666666671,
            2.1299999999999955,
            2.1016666666666737
        ],
        "train_loss": [
            2.2676224425687628,
            0.5820079486248857,
            0.4389254587181544,
            0.3698009990029416,
            0.3432678696462664,
            0.31143434269953585,
            0.293921214544167,
            0.27845698494022175,
            0.2692020871376587,
            0.2551010437941147,
            0.24265832618131475,
            0.23655346919924525,
            0.22560940101995305,
            0.2228308585235628,
            0.2198659378593251,
            0.20823411441455453,
            0.19944348299907425,
            0.19431749339831078,
            0.1934266522274179,
            0.1761989727363748,
            0.170374413162975,
            0.16231895023483342,
            0.16026291554257022,
            0.15479527691663322,
            0.1531691466600208,
            0.1521992531873412,
            0.1501919490806127,
            0.14594555734577824,
            0.14022282574136377,
            0.139799905656758,
            0.1403962878857629,
            0.13836062446994296,
            0.12963300400366218,
            0.13045838298433918,
            0.1267752585522199,
            0.12618903436903225,
            0.12423175535464691,
            0.11520879879846412,
            0.11115706446817365,
            0.1088046441643925,
            0.10975367146528374,
            0.1037726990752301,
            0.10411698712130725,
            0.10513288805545387,
            0.1011285358818911,
            0.10059948341321137,
            0.09931132007958525,
            0.09683480795662282,
            0.09504262181156772,
            0.09539176586825969,
            0.09458366794101263,
            0.09178564596479222,
            0.09314610670178623,
            0.0891890352812864,
            0.08749546476845015,
            0.08547499434927762,
            0.08367161073927153,
            0.0816833277122449,
            0.08294409260911456,
            0.08239730005547152,
            0.07984659555604902,
            0.08025939004906153,
            0.0778491310143875,
            0.076211100854611,
            0.07769324169573137,
            0.07753684157032077,
            0.0748570162360951,
            0.07581780105829239,
            0.07509967937307843,
            0.075003452030784,
            0.07415788147156521,
            0.07255955154107789,
            0.07213895868951992,
            0.07360487999552387,
            0.06995813927407991,
            0.06983908827779657,
            0.06904721512632855,
            0.06778495537780099,
            0.06782203041395898,
            0.06794888772449251,
            0.06768277622127937,
            0.06787220293940124,
            0.06647483328894033,
            0.06768225461749708,
            0.06787632134253696,
            0.0649480673216157,
            0.0653418798189042,
            0.06665405719462088,
            0.06588485054040359,
            0.063088220370523,
            0.06402017352944714,
            0.06432856398366266,
            0.06328369677066803
        ],
        "train_acc": [
            17.696666666666665,
            77.32,
            84.13833333333334,
            86.545,
            87.355,
            88.64833333333333,
            89.35333333333334,
            89.99,
            90.28333333333333,
            90.65833333333333,
            91.29833333333333,
            91.445,
            91.73833333333333,
            91.98833333333333,
            91.975,
            92.51666666666667,
            92.795,
            92.845,
            93.015,
            93.70666666666666,
            93.87166666666667,
            94.14833333333333,
            94.28666666666666,
            94.42666666666666,
            94.52833333333334,
            94.475,
            94.42833333333333,
            94.76833333333333,
            94.88,
            94.865,
            94.94166666666666,
            94.95333333333333,
            95.475,
            95.25,
            95.375,
            95.47,
            95.53833333333333,
            95.895,
            96.005,
            96.04833333333333,
            96.075,
            96.26166666666667,
            96.34333333333333,
            96.34166666666667,
            96.44166666666666,
            96.49333333333334,
            96.49,
            96.66666666666667,
            96.64333333333333,
            96.65666666666667,
            96.63166666666666,
            96.785,
            96.785,
            96.88833333333334,
            96.98666666666666,
            97.08166666666666,
            97.06,
            97.18666666666667,
            97.12666666666667,
            97.10333333333334,
            97.26666666666667,
            97.26333333333334,
            97.37333333333333,
            97.37,
            97.30333333333333,
            97.355,
            97.45,
            97.43,
            97.39166666666667,
            97.42,
            97.47833333333334,
            97.58166666666666,
            97.54166666666667,
            97.51666666666667,
            97.64833333333333,
            97.67833333333333,
            97.7,
            97.71833333333333,
            97.72833333333334,
            97.75,
            97.775,
            97.74,
            97.76,
            97.70666666666666,
            97.775,
            97.92166666666667,
            97.815,
            97.77666666666667,
            97.76666666666667,
            97.91333333333333,
            97.84833333333333,
            97.87,
            97.89833333333333
        ],
        "best_test_acc": 92.22,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.19984102249145508,
            0.20154809951782227,
            0.21309375762939453,
            0.22624444961547852,
            0.22483372688293457,
            0.24129867553710938,
            0.21658539772033691,
            0.2294619083404541,
            0.2339315414428711,
            0.21182608604431152,
            0.21481013298034668,
            0.21152853965759277,
            0.22230172157287598,
            0.23338627815246582,
            0.22969269752502441,
            0.22212624549865723,
            0.2285163402557373,
            0.23760080337524414,
            0.20302104949951172,
            0.15528154373168945,
            0.1729280948638916,
            0.1797633171081543,
            0.2097611427307129,
            0.1967334747314453,
            0.19256973266601562,
            0.18691229820251465,
            0.1718153953552246,
            0.1649458408355713,
            0.20040559768676758,
            0.19005656242370605,
            0.18317174911499023,
            0.18614912033081055,
            0.17218542098999023,
            0.16906976699829102,
            0.1828165054321289,
            0.19146466255187988,
            0.18360495567321777,
            0.1814279556274414,
            0.16464543342590332,
            0.17489099502563477,
            0.16330695152282715,
            0.16061162948608398,
            0.1618518829345703,
            0.17633914947509766,
            0.15520668029785156,
            0.15639925003051758,
            0.1848461627960205,
            0.18755221366882324,
            0.17414283752441406,
            0.2216353416442871
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 9.754140138626099,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 2950,
        "num_opt_steps": 2950,
        "num_grad_steps": 2949
    }
]