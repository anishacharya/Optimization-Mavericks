[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 1024,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 32,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.95,
                        "lr0": 0.057,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            82.12,
            28.709999999999994,
            18.959999999999994,
            15.739999999999995,
            14.170000000000002,
            13.650000000000006,
            12.760000000000005,
            12.329999999999998,
            12.069999999999993,
            11.579999999999998,
            11.400000000000006,
            11.040000000000006,
            10.849999999999994,
            10.540000000000006,
            10.39,
            10.489999999999995,
            10.510000000000005,
            10.11,
            10.090000000000003,
            9.519999999999996,
            9.459999999999994,
            9.379999999999995,
            9.409999999999997,
            8.959999999999994,
            9.420000000000002,
            9.290000000000006,
            9.370000000000005,
            9.549999999999997,
            9.079999999999998,
            8.810000000000002,
            9.200000000000003,
            9.510000000000005,
            8.989999999999995,
            9.25,
            8.969999999999999,
            8.950000000000003,
            8.680000000000007,
            8.64,
            8.730000000000004,
            8.239999999999995,
            8.61,
            8.650000000000006,
            8.579999999999998,
            8.64,
            8.450000000000003,
            8.560000000000002,
            8.239999999999995,
            8.260000000000005,
            8.39,
            8.319999999999993,
            8.519999999999996,
            8.489999999999995,
            8.290000000000006,
            8.319999999999993,
            8.269999999999996,
            8.200000000000003,
            8.280000000000001,
            8.280000000000001,
            8.14,
            8.290000000000006,
            8.36,
            8.379999999999995,
            8.430000000000007,
            8.319999999999993,
            8.349999999999994,
            8.400000000000006,
            8.36,
            8.290000000000006,
            8.120000000000005,
            8.150000000000006,
            8.480000000000004,
            8.370000000000005,
            8.450000000000003,
            8.430000000000007,
            8.099999999999994,
            8.230000000000004,
            8.260000000000005,
            8.400000000000006,
            8.159999999999997,
            8.299999999999997,
            8.379999999999995,
            8.209999999999994,
            8.290000000000006,
            8.349999999999994,
            8.079999999999998,
            8.409999999999997,
            8.459999999999994,
            8.379999999999995,
            8.439999999999998,
            8.129999999999995,
            8.030000000000001,
            8.14,
            8.310000000000002
        ],
        "test_loss": [],
        "test_acc": [
            17.88,
            71.29,
            81.04,
            84.26,
            85.83,
            86.35,
            87.24,
            87.67,
            87.93,
            88.42,
            88.6,
            88.96,
            89.15,
            89.46,
            89.61,
            89.51,
            89.49,
            89.89,
            89.91,
            90.48,
            90.54,
            90.62,
            90.59,
            91.04,
            90.58,
            90.71,
            90.63,
            90.45,
            90.92,
            91.19,
            90.8,
            90.49,
            91.01,
            90.75,
            91.03,
            91.05,
            91.32,
            91.36,
            91.27,
            91.76,
            91.39,
            91.35,
            91.42,
            91.36,
            91.55,
            91.44,
            91.76,
            91.74,
            91.61,
            91.68,
            91.48,
            91.51,
            91.71,
            91.68,
            91.73,
            91.8,
            91.72,
            91.72,
            91.86,
            91.71,
            91.64,
            91.62,
            91.57,
            91.68,
            91.65,
            91.6,
            91.64,
            91.71,
            91.88,
            91.85,
            91.52,
            91.63,
            91.55,
            91.57,
            91.9,
            91.77,
            91.74,
            91.6,
            91.84,
            91.7,
            91.62,
            91.79,
            91.71,
            91.65,
            91.92,
            91.59,
            91.54,
            91.62,
            91.56,
            91.87,
            91.97,
            91.86,
            91.69
        ],
        "train_error": [
            81.45333333333333,
            28.53,
            18.056666666666672,
            14.678333333333327,
            13.269999999999996,
            12.11333333333333,
            11.608333333333334,
            10.879999999999995,
            10.718333333333334,
            9.908333333333331,
            9.894999999999996,
            9.428333333333327,
            9.108333333333334,
            9.023333333333326,
            8.724999999999994,
            8.448333333333338,
            8.411666666666662,
            8.061666666666667,
            7.896666666666661,
            7.3700000000000045,
            7.1299999999999955,
            6.924999999999997,
            6.971666666666664,
            6.651666666666671,
            6.558333333333337,
            6.658333333333331,
            6.61333333333333,
            6.541666666666671,
            6.3216666666666725,
            6.131666666666661,
            5.943333333333328,
            6.575000000000003,
            5.924999999999997,
            5.916666666666671,
            5.87166666666667,
            5.926666666666662,
            5.501666666666665,
            5.358333333333334,
            5.36333333333333,
            5.161666666666662,
            5.228333333333339,
            4.909999999999997,
            4.983333333333334,
            4.943333333333328,
            4.849999999999994,
            4.805000000000007,
            4.788333333333327,
            4.731666666666669,
            4.798333333333332,
            4.776666666666671,
            4.680000000000007,
            4.584999999999994,
            4.548333333333332,
            4.566666666666663,
            4.38666666666667,
            4.403333333333336,
            4.283333333333331,
            4.215000000000003,
            4.161666666666662,
            4.273333333333326,
            4.161666666666662,
            4.25,
            4.0816666666666634,
            4.0433333333333366,
            4.040000000000006,
            4.083333333333329,
            4.069999999999993,
            4.006666666666661,
            4.051666666666662,
            4.013333333333335,
            3.9650000000000034,
            3.8983333333333263,
            3.9000000000000057,
            3.788333333333327,
            3.8516666666666737,
            3.7933333333333366,
            3.819999999999993,
            3.8433333333333337,
            3.74166666666666,
            3.6883333333333326,
            3.7099999999999937,
            3.7450000000000045,
            3.703333333333333,
            3.6383333333333354,
            3.5933333333333337,
            3.643333333333331,
            3.681666666666672,
            3.8033333333333275,
            3.598333333333329,
            3.5799999999999983,
            3.5600000000000023,
            3.5900000000000034,
            3.6500000000000057
        ],
        "train_loss": [
            2.262522293349444,
            0.7312678765442412,
            0.4742860541505329,
            0.4036134011664633,
            0.35837947362560335,
            0.3346899904436984,
            0.31896095609260816,
            0.30014787387039704,
            0.29167244141384707,
            0.27294833250975203,
            0.2696803138922837,
            0.26022219733666563,
            0.24982985955173687,
            0.24489174227593308,
            0.23850110122712992,
            0.23532216478202303,
            0.2304950563584344,
            0.21989074324147176,
            0.21644364171108957,
            0.20327376814211828,
            0.19609396235417512,
            0.19132476287373043,
            0.19115243321758205,
            0.18306163660550523,
            0.18141099633806843,
            0.1821887553748438,
            0.17916415758052115,
            0.17942916917598853,
            0.17194899108450293,
            0.1696885132183463,
            0.16768909258357548,
            0.17731103477841717,
            0.1636921950316025,
            0.16406951465849148,
            0.16027955332044827,
            0.161647477644985,
            0.15411294718920174,
            0.14958391288074396,
            0.1472997971005359,
            0.1429476667258699,
            0.14524789167157673,
            0.13908283526109436,
            0.1395210614901478,
            0.1382133480855974,
            0.13659453000557625,
            0.13518850416955303,
            0.134475943521928,
            0.13305550573740976,
            0.13281715055138377,
            0.13290621315018605,
            0.12981679947194408,
            0.12772145425364123,
            0.12875883697958315,
            0.12594806870161476,
            0.124638645957082,
            0.1237227425484334,
            0.12068261029356617,
            0.11985303613088899,
            0.11910551243414313,
            0.11925636749651472,
            0.11693091665284108,
            0.11873121483851287,
            0.11558568704936464,
            0.11544736045396935,
            0.1149464259713383,
            0.11488112504199399,
            0.11492252918118137,
            0.11374168148485281,
            0.11420624943102821,
            0.11249164239329806,
            0.1119470136650538,
            0.10973581962161146,
            0.11162958723508705,
            0.10954437493267706,
            0.10913853107367531,
            0.10746505679720539,
            0.10812291364043446,
            0.10733065110141948,
            0.1062992232835899,
            0.10693381095336656,
            0.10760769601595604,
            0.10584392272314783,
            0.10563329922950875,
            0.10517503030724444,
            0.10432698565014338,
            0.10515588976569094,
            0.10519475931838407,
            0.10572007664684523,
            0.10353257949069394,
            0.10334641145447553,
            0.10293808718354015,
            0.10383115481522123,
            0.10253296274754961
        ],
        "train_acc": [
            18.546666666666667,
            71.47,
            81.94333333333333,
            85.32166666666667,
            86.73,
            87.88666666666667,
            88.39166666666667,
            89.12,
            89.28166666666667,
            90.09166666666667,
            90.105,
            90.57166666666667,
            90.89166666666667,
            90.97666666666667,
            91.275,
            91.55166666666666,
            91.58833333333334,
            91.93833333333333,
            92.10333333333334,
            92.63,
            92.87,
            93.075,
            93.02833333333334,
            93.34833333333333,
            93.44166666666666,
            93.34166666666667,
            93.38666666666667,
            93.45833333333333,
            93.67833333333333,
            93.86833333333334,
            94.05666666666667,
            93.425,
            94.075,
            94.08333333333333,
            94.12833333333333,
            94.07333333333334,
            94.49833333333333,
            94.64166666666667,
            94.63666666666667,
            94.83833333333334,
            94.77166666666666,
            95.09,
            95.01666666666667,
            95.05666666666667,
            95.15,
            95.195,
            95.21166666666667,
            95.26833333333333,
            95.20166666666667,
            95.22333333333333,
            95.32,
            95.415,
            95.45166666666667,
            95.43333333333334,
            95.61333333333333,
            95.59666666666666,
            95.71666666666667,
            95.785,
            95.83833333333334,
            95.72666666666667,
            95.83833333333334,
            95.75,
            95.91833333333334,
            95.95666666666666,
            95.96,
            95.91666666666667,
            95.93,
            95.99333333333334,
            95.94833333333334,
            95.98666666666666,
            96.035,
            96.10166666666667,
            96.1,
            96.21166666666667,
            96.14833333333333,
            96.20666666666666,
            96.18,
            96.15666666666667,
            96.25833333333334,
            96.31166666666667,
            96.29,
            96.255,
            96.29666666666667,
            96.36166666666666,
            96.40666666666667,
            96.35666666666667,
            96.31833333333333,
            96.19666666666667,
            96.40166666666667,
            96.42,
            96.44,
            96.41,
            96.35
        ],
        "best_test_acc": 91.97,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.22836852073669434,
            0.24155783653259277,
            0.23288607597351074,
            0.20589232444763184,
            0.19951391220092773,
            0.19878458976745605,
            0.19552040100097656,
            0.21734380722045898,
            0.19426441192626953,
            0.20137810707092285,
            0.19842743873596191,
            0.19968128204345703,
            0.2040722370147705,
            0.21848392486572266,
            0.23194098472595215,
            0.2058405876159668,
            0.20747661590576172,
            0.20462822914123535,
            0.19877290725708008,
            0.20024657249450684,
            0.20345187187194824,
            0.2035660743713379,
            0.20364117622375488,
            0.20165729522705078,
            0.20078396797180176,
            0.20411062240600586,
            0.2052783966064453,
            0.2046804428100586,
            0.22730731964111328,
            0.19882988929748535,
            0.20986151695251465,
            0.222764253616333,
            0.2362217903137207,
            0.22178030014038086,
            0.22188806533813477,
            0.21638822555541992,
            0.2019367218017578,
            0.2159590721130371,
            0.21575284004211426,
            0.22274422645568848,
            0.2131366729736328,
            0.20524835586547852,
            0.22265625,
            0.2238013744354248,
            0.21477460861206055,
            0.19968795776367188,
            0.15327095985412598,
            0.1532273292541504,
            0.1533031463623047,
            0.1529088020324707
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 10.31570029258728,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 2950,
        "num_opt_steps": 2950,
        "num_grad_steps": 2949
    }
]