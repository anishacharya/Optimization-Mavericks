[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 1024,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 32,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.8,
                        "lr0": 0.057,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            83.87,
            26.64,
            16.64,
            14.25,
            13.439999999999998,
            12.409999999999997,
            11.829999999999998,
            11.680000000000007,
            11.689999999999998,
            10.900000000000006,
            10.780000000000001,
            10.629999999999995,
            10.659999999999997,
            9.959999999999994,
            10.019999999999996,
            9.930000000000007,
            9.840000000000003,
            9.730000000000004,
            9.819999999999993,
            9.170000000000002,
            9.230000000000004,
            9.040000000000006,
            9.310000000000002,
            8.549999999999997,
            8.950000000000003,
            8.75,
            9.049999999999997,
            8.700000000000003,
            8.799999999999997,
            8.209999999999994,
            8.689999999999998,
            9.159999999999997,
            8.540000000000006,
            8.409999999999997,
            8.969999999999999,
            8.61,
            8.629999999999995,
            8.420000000000002,
            8.239999999999995,
            8.420000000000002,
            8.650000000000006,
            8.310000000000002,
            8.459999999999994,
            8.489999999999995,
            8.349999999999994,
            8.480000000000004,
            8.39,
            8.200000000000003,
            8.569999999999993,
            8.480000000000004,
            8.290000000000006,
            8.260000000000005,
            8.170000000000002,
            8.370000000000005,
            8.219999999999999,
            8.219999999999999,
            8.299999999999997,
            8.030000000000001,
            8.409999999999997,
            8.230000000000004,
            8.159999999999997,
            8.230000000000004,
            8.370000000000005,
            8.14,
            8.269999999999996,
            8.200000000000003,
            8.409999999999997,
            8.299999999999997,
            8.329999999999998,
            8.180000000000007,
            8.25,
            8.299999999999997,
            8.170000000000002,
            8.060000000000002,
            8.040000000000006,
            8.209999999999994,
            8.11,
            8.11,
            8.269999999999996,
            8.200000000000003,
            8.170000000000002,
            8.150000000000006,
            8.219999999999999,
            8.030000000000001,
            8.209999999999994,
            8.170000000000002,
            8.090000000000003,
            8.329999999999998,
            8.319999999999993,
            7.989999999999995,
            8.150000000000006,
            7.989999999999995,
            7.939999999999998
        ],
        "test_loss": [],
        "test_acc": [
            16.13,
            73.36,
            83.36,
            85.75,
            86.56,
            87.59,
            88.17,
            88.32,
            88.31,
            89.1,
            89.22,
            89.37,
            89.34,
            90.04,
            89.98,
            90.07,
            90.16,
            90.27,
            90.18,
            90.83,
            90.77,
            90.96,
            90.69,
            91.45,
            91.05,
            91.25,
            90.95,
            91.3,
            91.2,
            91.79,
            91.31,
            90.84,
            91.46,
            91.59,
            91.03,
            91.39,
            91.37,
            91.58,
            91.76,
            91.58,
            91.35,
            91.69,
            91.54,
            91.51,
            91.65,
            91.52,
            91.61,
            91.8,
            91.43,
            91.52,
            91.71,
            91.74,
            91.83,
            91.63,
            91.78,
            91.78,
            91.7,
            91.97,
            91.59,
            91.77,
            91.84,
            91.77,
            91.63,
            91.86,
            91.73,
            91.8,
            91.59,
            91.7,
            91.67,
            91.82,
            91.75,
            91.7,
            91.83,
            91.94,
            91.96,
            91.79,
            91.89,
            91.89,
            91.73,
            91.8,
            91.83,
            91.85,
            91.78,
            91.97,
            91.79,
            91.83,
            91.91,
            91.67,
            91.68,
            92.01,
            91.85,
            92.01,
            92.06
        ],
        "train_error": [
            83.28999999999999,
            26.36333333333333,
            15.84833333333333,
            13.474999999999994,
            12.519999999999996,
            11.26166666666667,
            10.739999999999995,
            10.23166666666667,
            9.858333333333334,
            9.433333333333337,
            8.888333333333335,
            8.671666666666667,
            8.439999999999998,
            8.075000000000003,
            8.108333333333334,
            7.609999999999999,
            7.3700000000000045,
            7.093333333333334,
            7.3799999999999955,
            6.411666666666662,
            6.296666666666667,
            5.984999999999999,
            5.861666666666665,
            5.704999999999998,
            5.683333333333337,
            5.583333333333329,
            5.606666666666669,
            5.341666666666669,
            5.228333333333339,
            5.151666666666671,
            5.034999999999997,
            5.435000000000002,
            4.75333333333333,
            4.819999999999993,
            4.844999999999999,
            4.481666666666669,
            4.493333333333339,
            4.26166666666667,
            4.045000000000002,
            3.8983333333333263,
            4.189999999999998,
            3.8700000000000045,
            3.748333333333335,
            3.739999999999995,
            3.655000000000001,
            3.683333333333337,
            3.6616666666666617,
            3.614999999999995,
            3.6883333333333326,
            3.50833333333334,
            3.471666666666664,
            3.3433333333333337,
            3.288333333333327,
            3.153333333333336,
            3.239999999999995,
            3.056666666666672,
            2.99166666666666,
            2.969999999999999,
            2.885000000000005,
            2.9883333333333297,
            2.8400000000000034,
            2.8900000000000006,
            2.8216666666666725,
            2.7849999999999966,
            2.7150000000000034,
            2.7650000000000006,
            2.603333333333339,
            2.673333333333332,
            2.719999999999999,
            2.680000000000007,
            2.603333333333339,
            2.501666666666665,
            2.555000000000007,
            2.481666666666669,
            2.473333333333329,
            2.5600000000000023,
            2.3683333333333394,
            2.4283333333333275,
            2.3633333333333297,
            2.3866666666666703,
            2.4099999999999966,
            2.3900000000000006,
            2.4366666666666674,
            2.385000000000005,
            2.318333333333328,
            2.319999999999993,
            2.353333333333339,
            2.306666666666672,
            2.3400000000000034,
            2.25,
            2.2950000000000017,
            2.2533333333333303,
            2.2049999999999983
        ],
        "train_loss": [
            2.266241178674213,
            0.6552988533246316,
            0.43491105558508536,
            0.36826287891905185,
            0.3399606821900707,
            0.31170731075739455,
            0.29640408289634573,
            0.2810138100284641,
            0.2722801073627957,
            0.2571348057965101,
            0.24568504322383364,
            0.23788845160249936,
            0.2304493845519373,
            0.2222490394014423,
            0.2188700543621839,
            0.2104124889030295,
            0.20005231716875302,
            0.19509558379650116,
            0.2009060632879451,
            0.17854770007780044,
            0.17085788260071966,
            0.16514473926212828,
            0.16334326337959806,
            0.15778853491706363,
            0.1555282655408827,
            0.153520806613615,
            0.15150935644820585,
            0.14742684086500588,
            0.14384396601531466,
            0.141100796097416,
            0.13970880513474093,
            0.14468203952251854,
            0.13232921531139794,
            0.13409107140565324,
            0.13360822756411667,
            0.12398309525796923,
            0.12420720632298518,
            0.11847361707586353,
            0.11400737120943555,
            0.11023925080642862,
            0.11265910353700993,
            0.1075289431264845,
            0.10730522757364531,
            0.10674260834516106,
            0.10269580629922576,
            0.10379520248053438,
            0.10308518513279447,
            0.10018103607630326,
            0.10153176572363255,
            0.09884900801767738,
            0.09693228971149961,
            0.09466956972570742,
            0.09426249980421389,
            0.09142419234928438,
            0.09192819224070695,
            0.08895211540541406,
            0.08603789455304711,
            0.08484478017031136,
            0.08436070717239784,
            0.08427330548480405,
            0.08240233993126174,
            0.08302501911076449,
            0.08133949453042726,
            0.07981558756555542,
            0.07997305501820677,
            0.08041378880961467,
            0.07789995729670686,
            0.07772616208609888,
            0.0780966855206732,
            0.07723437994718552,
            0.0768278709028737,
            0.07437906805741584,
            0.07538737179869312,
            0.0749320868339579,
            0.07315321329791667,
            0.07283517705687022,
            0.07191657477011115,
            0.07062883902404268,
            0.07094251396039784,
            0.07115421134789111,
            0.07078684910626734,
            0.06983318609201301,
            0.07040875733403837,
            0.07004756013215599,
            0.06863098591566086,
            0.06839059590030525,
            0.06888004341873072,
            0.06988013706217377,
            0.0674457274124784,
            0.06690144974548938,
            0.06734999098767669,
            0.06754230013338186,
            0.0665758896808503
        ],
        "train_acc": [
            16.71,
            73.63666666666667,
            84.15166666666667,
            86.525,
            87.48,
            88.73833333333333,
            89.26,
            89.76833333333333,
            90.14166666666667,
            90.56666666666666,
            91.11166666666666,
            91.32833333333333,
            91.56,
            91.925,
            91.89166666666667,
            92.39,
            92.63,
            92.90666666666667,
            92.62,
            93.58833333333334,
            93.70333333333333,
            94.015,
            94.13833333333334,
            94.295,
            94.31666666666666,
            94.41666666666667,
            94.39333333333333,
            94.65833333333333,
            94.77166666666666,
            94.84833333333333,
            94.965,
            94.565,
            95.24666666666667,
            95.18,
            95.155,
            95.51833333333333,
            95.50666666666666,
            95.73833333333333,
            95.955,
            96.10166666666667,
            95.81,
            96.13,
            96.25166666666667,
            96.26,
            96.345,
            96.31666666666666,
            96.33833333333334,
            96.385,
            96.31166666666667,
            96.49166666666666,
            96.52833333333334,
            96.65666666666667,
            96.71166666666667,
            96.84666666666666,
            96.76,
            96.94333333333333,
            97.00833333333334,
            97.03,
            97.115,
            97.01166666666667,
            97.16,
            97.11,
            97.17833333333333,
            97.215,
            97.285,
            97.235,
            97.39666666666666,
            97.32666666666667,
            97.28,
            97.32,
            97.39666666666666,
            97.49833333333333,
            97.445,
            97.51833333333333,
            97.52666666666667,
            97.44,
            97.63166666666666,
            97.57166666666667,
            97.63666666666667,
            97.61333333333333,
            97.59,
            97.61,
            97.56333333333333,
            97.615,
            97.68166666666667,
            97.68,
            97.64666666666666,
            97.69333333333333,
            97.66,
            97.75,
            97.705,
            97.74666666666667,
            97.795
        ],
        "best_test_acc": 92.06,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.2012484073638916,
            0.20538330078125,
            0.18624567985534668,
            0.20506501197814941,
            0.2128615379333496,
            0.20390772819519043,
            0.19112539291381836,
            0.18625283241271973,
            0.19657397270202637,
            0.2035355567932129,
            0.19020724296569824,
            0.19555187225341797,
            0.20875096321105957,
            0.21281909942626953,
            0.21453332901000977,
            0.20589041709899902,
            0.2092421054840088,
            0.19659829139709473,
            0.18579697608947754,
            0.18951869010925293,
            0.21543478965759277,
            0.18835902214050293,
            0.19751214981079102,
            0.20184683799743652,
            0.2138986587524414,
            0.2060413360595703,
            0.20498085021972656,
            0.18227815628051758,
            0.17956018447875977,
            0.17838835716247559,
            0.20017433166503906,
            0.18638014793395996,
            0.1895580291748047,
            0.18953895568847656,
            0.19453692436218262,
            0.19129157066345215,
            0.1983788013458252,
            0.21041417121887207,
            0.21438169479370117,
            0.20220661163330078,
            0.18420791625976562,
            0.20696568489074707,
            0.20690059661865234,
            0.20151114463806152,
            0.19700312614440918,
            0.20512723922729492,
            0.22495698928833008,
            0.19764399528503418,
            0.16656732559204102,
            0.15662240982055664
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 9.893776416778564,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 2950,
        "num_opt_steps": 2950,
        "num_grad_steps": 2949
    }
]