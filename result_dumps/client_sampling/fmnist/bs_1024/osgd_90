[
    {
        "config": {
            "seed": 1,
            "data_config": {
                "data_set": "fashion_mnist",
                "shape": [
                    28,
                    28
                ],
                "val_frac": 0,
                "num_labels": 10,
                "num_channels": 1,
                "data_sampling_strategy": "iid",
                "num_shards": 80,
                "train_batch_size": 1024,
                "test_batch_size": 2048,
                "feature_attack_config": {
                    "noise_model": null,
                    "frac_adv": 0.2,
                    "sev": 5,
                    "target_label": 8
                }
            },
            "training_config": {
                "num_clients": 1,
                "client_fraction": 1,
                "global_epochs": 50,
                "local_epochs": 1,
                "eval_freq": 32,
                "optimizer_config": {
                    "client_optimizer_config": {
                        "optimizer": "SGD",
                        "loss": "ce",
                        "loss_sampling": "top_loss",
                        "initial_loss_sampling_fraction": 0.9,
                        "lr0": 0.057,
                        "momentum": 0.9,
                        "reg": 0.0001,
                        "nesterov": true,
                        "amsgrad": false
                    },
                    "client_lrs_config": {
                        "lrs": "step",
                        "milestones": [
                            1,
                            5,
                            10
                        ],
                        "step_size": 10,
                        "gamma": 0.5
                    },
                    "server_optimizer_config": {
                        "optimizer": "SGD",
                        "lr0": 1
                    }
                },
                "learner_config": {
                    "net": "lenet",
                    "mlp_config": {
                        "h1": 30,
                        "h2": 30
                    }
                },
                "aggregation_config": {
                    "gar": "mean",
                    "geo_med_config": {
                        "alg": "vardi",
                        "eps": 1e-05,
                        "max_iter": 100
                    },
                    "trimmed_mean_config": {
                        "proportion": 0.3
                    },
                    "krum_config": {
                        "krum_frac": 0.3
                    },
                    "norm_clip_config": {
                        "alpha": 0.5
                    },
                    "grad_attack_config": {
                        "attack_model": null,
                        "attack_mode": "un_coordinated",
                        "frac_adv": 0.4,
                        "rand_additive_attack_conf": {
                            "noise_dist": "gaussian",
                            "mean_shift": 0,
                            "attack_std": 10,
                            "noise_range": [
                                -1,
                                0
                            ]
                        },
                        "sign_flip_conf": {
                            "flip_prob": 0.7,
                            "flip_scale": 5
                        },
                        "attack_n_std": 1
                    },
                    "compression_config": {
                        "rule": null,
                        "axis": "n",
                        "sampling_fraction": 0.9,
                        "mG": false,
                        "mg": false
                    }
                }
            }
        },
        "num_param": 0,
        "test_error": [
            82.01,
            25.730000000000004,
            18.700000000000003,
            15.61,
            14.280000000000001,
            13.420000000000002,
            12.599999999999994,
            12.5,
            11.870000000000005,
            11.530000000000001,
            11.069999999999993,
            11.230000000000004,
            10.489999999999995,
            10.760000000000005,
            10.670000000000002,
            9.909999999999997,
            9.870000000000005,
            10.11,
            10.349999999999994,
            9.530000000000001,
            9.299999999999997,
            9.200000000000003,
            9.11,
            9.049999999999997,
            8.939999999999998,
            9.239999999999995,
            9.189999999999998,
            9.219999999999999,
            9.0,
            8.530000000000001,
            8.939999999999998,
            9.379999999999995,
            9.090000000000003,
            8.920000000000002,
            8.879999999999995,
            8.959999999999994,
            8.829999999999998,
            8.620000000000005,
            8.370000000000005,
            8.659999999999997,
            8.709999999999994,
            8.540000000000006,
            8.480000000000004,
            8.469999999999999,
            8.489999999999995,
            8.530000000000001,
            8.319999999999993,
            8.510000000000005,
            8.269999999999996,
            8.519999999999996,
            8.510000000000005,
            8.439999999999998,
            8.280000000000001,
            8.459999999999994,
            8.319999999999993,
            8.370000000000005,
            8.310000000000002,
            8.329999999999998,
            8.280000000000001,
            8.349999999999994,
            7.989999999999995,
            8.310000000000002,
            8.060000000000002,
            8.299999999999997,
            8.310000000000002,
            8.299999999999997,
            8.099999999999994,
            8.409999999999997,
            8.200000000000003,
            8.349999999999994,
            8.299999999999997,
            8.269999999999996,
            8.099999999999994,
            8.39,
            8.400000000000006,
            8.280000000000001,
            8.090000000000003,
            8.439999999999998,
            8.010000000000005,
            8.25,
            8.159999999999997,
            8.129999999999995,
            8.25,
            8.189999999999998,
            8.400000000000006,
            8.170000000000002,
            8.340000000000003,
            8.519999999999996,
            8.230000000000004,
            8.25,
            8.209999999999994,
            8.209999999999994,
            8.040000000000006
        ],
        "test_loss": [],
        "test_acc": [
            17.99,
            74.27,
            81.3,
            84.39,
            85.72,
            86.58,
            87.4,
            87.5,
            88.13,
            88.47,
            88.93,
            88.77,
            89.51,
            89.24,
            89.33,
            90.09,
            90.13,
            89.89,
            89.65,
            90.47,
            90.7,
            90.8,
            90.89,
            90.95,
            91.06,
            90.76,
            90.81,
            90.78,
            91.0,
            91.47,
            91.06,
            90.62,
            90.91,
            91.08,
            91.12,
            91.04,
            91.17,
            91.38,
            91.63,
            91.34,
            91.29,
            91.46,
            91.52,
            91.53,
            91.51,
            91.47,
            91.68,
            91.49,
            91.73,
            91.48,
            91.49,
            91.56,
            91.72,
            91.54,
            91.68,
            91.63,
            91.69,
            91.67,
            91.72,
            91.65,
            92.01,
            91.69,
            91.94,
            91.7,
            91.69,
            91.7,
            91.9,
            91.59,
            91.8,
            91.65,
            91.7,
            91.73,
            91.9,
            91.61,
            91.6,
            91.72,
            91.91,
            91.56,
            91.99,
            91.75,
            91.84,
            91.87,
            91.75,
            91.81,
            91.6,
            91.83,
            91.66,
            91.48,
            91.77,
            91.75,
            91.79,
            91.79,
            91.96
        ],
        "train_error": [
            81.63,
            25.123333333333335,
            18.034999999999997,
            14.870000000000005,
            13.108333333333334,
            12.25666666666666,
            11.523333333333326,
            10.876666666666665,
            10.581666666666663,
            9.819999999999993,
            9.533333333333331,
            9.561666666666667,
            8.876666666666665,
            8.915000000000006,
            8.74333333333334,
            8.063333333333333,
            7.921666666666667,
            7.670000000000002,
            7.775000000000006,
            7.051666666666662,
            6.799999999999997,
            6.763333333333335,
            6.523333333333326,
            6.355000000000004,
            6.189999999999998,
            6.271666666666661,
            6.276666666666671,
            6.111666666666665,
            5.868333333333339,
            5.903333333333336,
            5.908333333333331,
            6.0433333333333366,
            5.521666666666661,
            5.525000000000006,
            5.611666666666665,
            5.423333333333332,
            5.319999999999993,
            5.098333333333329,
            4.935000000000002,
            4.75833333333334,
            4.971666666666664,
            4.709999999999994,
            4.666666666666671,
            4.623333333333335,
            4.635000000000005,
            4.526666666666671,
            4.444999999999993,
            4.415000000000006,
            4.424999999999997,
            4.609999999999999,
            4.37833333333333,
            4.268333333333331,
            4.319999999999993,
            4.2549999999999955,
            4.170000000000002,
            4.163333333333327,
            3.8799999999999955,
            3.9950000000000045,
            3.8983333333333263,
            3.969999999999999,
            3.8100000000000023,
            3.9200000000000017,
            3.7549999999999955,
            3.8799999999999955,
            3.7450000000000045,
            3.703333333333333,
            3.7066666666666634,
            3.6366666666666703,
            3.805000000000007,
            3.671666666666667,
            3.6016666666666737,
            3.598333333333329,
            3.603333333333339,
            3.5433333333333366,
            3.4950000000000045,
            3.424999999999997,
            3.4466666666666725,
            3.4150000000000063,
            3.3633333333333297,
            3.450000000000003,
            3.385000000000005,
            3.2866666666666617,
            3.403333333333336,
            3.433333333333337,
            3.4383333333333326,
            3.3683333333333394,
            3.4549999999999983,
            3.3216666666666725,
            3.319999999999993,
            3.2833333333333314,
            3.223333333333329,
            3.2349999999999994,
            3.2549999999999955
        ],
        "train_loss": [
            2.2633538811893787,
            0.6563104300175683,
            0.48128356923491267,
            0.406780462648909,
            0.35784841947636364,
            0.3346551515288272,
            0.3110344046253269,
            0.2993257914559316,
            0.2858760902437113,
            0.2684978928606389,
            0.26117613911628723,
            0.25763145594273584,
            0.24235392046176782,
            0.24316293026431132,
            0.23750605623600846,
            0.22342585961697464,
            0.2160350897554624,
            0.20945796597812136,
            0.21233131420814386,
            0.19380026020235935,
            0.1878222345800723,
            0.18460480464717088,
            0.18245768319752256,
            0.17647547413737086,
            0.17224543023917635,
            0.17292088775311487,
            0.17187636459277847,
            0.16875269377635696,
            0.1633277257620278,
            0.16162278515807652,
            0.16067854643373167,
            0.16557600134510106,
            0.15345234171313754,
            0.1520734443250349,
            0.15488869330640567,
            0.15008457005023956,
            0.14775128776239135,
            0.14133056152169987,
            0.13798186498678336,
            0.1334067206766646,
            0.13686124361672644,
            0.1305203200396845,
            0.1306980093151836,
            0.1294231597902411,
            0.12851958620851323,
            0.12673653535923715,
            0.1265087319632708,
            0.12417721167459327,
            0.12313151119624154,
            0.12437199788578486,
            0.122655600561934,
            0.11937213032427481,
            0.12029044595310244,
            0.11698798835277557,
            0.11619772610522933,
            0.11599588899289147,
            0.11232405446343503,
            0.11144172955872649,
            0.11083691819744595,
            0.11094219742690102,
            0.10866343823529906,
            0.10886258480407424,
            0.10840418215020228,
            0.10790623194080289,
            0.10542963003203021,
            0.10627883862135774,
            0.10587255505181975,
            0.10437083446373374,
            0.1057601035651514,
            0.10394102019273628,
            0.10246734245348785,
            0.102448190925485,
            0.10328169773190708,
            0.10060504899691727,
            0.09991681575775146,
            0.09880533713405415,
            0.09807567323668528,
            0.09701989288047208,
            0.09706482707949007,
            0.0986927942199222,
            0.09799069734448093,
            0.09589503276146065,
            0.09721866111129017,
            0.09677919871726279,
            0.09620237022133196,
            0.09537467789852012,
            0.0974166998166149,
            0.09530746507442604,
            0.09474479912196175,
            0.09438822128004946,
            0.09463213699854027,
            0.09431553733045772,
            0.09321029799974571
        ],
        "train_acc": [
            18.37,
            74.87666666666667,
            81.965,
            85.13,
            86.89166666666667,
            87.74333333333334,
            88.47666666666667,
            89.12333333333333,
            89.41833333333334,
            90.18,
            90.46666666666667,
            90.43833333333333,
            91.12333333333333,
            91.085,
            91.25666666666666,
            91.93666666666667,
            92.07833333333333,
            92.33,
            92.225,
            92.94833333333334,
            93.2,
            93.23666666666666,
            93.47666666666667,
            93.645,
            93.81,
            93.72833333333334,
            93.72333333333333,
            93.88833333333334,
            94.13166666666666,
            94.09666666666666,
            94.09166666666667,
            93.95666666666666,
            94.47833333333334,
            94.475,
            94.38833333333334,
            94.57666666666667,
            94.68,
            94.90166666666667,
            95.065,
            95.24166666666666,
            95.02833333333334,
            95.29,
            95.33333333333333,
            95.37666666666667,
            95.365,
            95.47333333333333,
            95.555,
            95.585,
            95.575,
            95.39,
            95.62166666666667,
            95.73166666666667,
            95.68,
            95.745,
            95.83,
            95.83666666666667,
            96.12,
            96.005,
            96.10166666666667,
            96.03,
            96.19,
            96.08,
            96.245,
            96.12,
            96.255,
            96.29666666666667,
            96.29333333333334,
            96.36333333333333,
            96.195,
            96.32833333333333,
            96.39833333333333,
            96.40166666666667,
            96.39666666666666,
            96.45666666666666,
            96.505,
            96.575,
            96.55333333333333,
            96.585,
            96.63666666666667,
            96.55,
            96.615,
            96.71333333333334,
            96.59666666666666,
            96.56666666666666,
            96.56166666666667,
            96.63166666666666,
            96.545,
            96.67833333333333,
            96.68,
            96.71666666666667,
            96.77666666666667,
            96.765,
            96.745
        ],
        "best_test_acc": 92.01,
        "gradient_residual": [],
        "jacobian_residual": [],
        "epoch_compression_cost": [],
        "epoch_grad_cost": [
            0.18796563148498535,
            0.17795562744140625,
            0.1598341464996338,
            0.15759873390197754,
            0.1546010971069336,
            0.15596342086791992,
            0.15662288665771484,
            0.15970253944396973,
            0.1566762924194336,
            0.16068458557128906,
            0.15193629264831543,
            0.15713715553283691,
            0.15712523460388184,
            0.15875840187072754,
            0.15381646156311035,
            0.17054343223571777,
            0.18039584159851074,
            0.16045212745666504,
            0.15097355842590332,
            0.15094757080078125,
            0.14798855781555176,
            0.14869427680969238,
            0.14972329139709473,
            0.15091633796691895,
            0.14870619773864746,
            0.14947748184204102,
            0.15501737594604492,
            0.14825677871704102,
            0.15506696701049805,
            0.15340185165405273,
            0.16592884063720703,
            0.1513357162475586,
            0.1535475254058838,
            0.16195368766784668,
            0.16120648384094238,
            0.15213251113891602,
            0.15224766731262207,
            0.1548011302947998,
            0.15270185470581055,
            0.15566086769104004,
            0.15882492065429688,
            0.15129828453063965,
            0.1516711711883545,
            0.15362286567687988,
            0.15158438682556152,
            0.15291261672973633,
            0.1529219150543213,
            0.15452122688293457,
            0.15409016609191895,
            0.15224337577819824
        ],
        "epoch_agg_cost": [],
        "epoch_gm_iter": [],
        "total_cost": 7.822147369384766,
        "total_grad_cost": 0,
        "total_agg_cost": 0,
        "total_compression_cost": 0,
        "total_gm_iter": 0,
        "avg_gm_cost": 0,
        "num_iter": 2950,
        "num_opt_steps": 2950,
        "num_grad_steps": 2949
    }
]